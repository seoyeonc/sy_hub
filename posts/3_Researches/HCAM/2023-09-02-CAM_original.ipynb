{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b8a18c36-7705-4cf3-a9a5-358a4a93c041",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"**[CAM]**Original CAM\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2023-08-28\"\n",
    "categories:\n",
    "  - CAM\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd2c1b-3d3f-4114-ad2d-75cdb068f397",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7d86f6-a5c9-4aef-90bb-a5514b9b4b47",
   "metadata": {},
   "source": [
    "https://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d83b071-7964-4407-ab86-95162852c56e",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52b518da-7b1f-47c3-b5af-c578ca1a7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from fastai.vision.all import *\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageFile\n",
    "from PIL import Image\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from torchvision.utils import save_image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f3a7f48-cd9c-4643-9f84-640bcb38422b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "import rpy2.robjects as ro \n",
    "from rpy2.robjects.vectors import FloatVector \n",
    "from rpy2.robjects.packages import importr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a884697-3fc8-4552-bc54-a74366aab5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(f):\n",
    "    if f[0].isupper():\n",
    "        return 'cat' \n",
    "    else: \n",
    "        return 'dog' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535d051f-ba1c-42ac-a68e-4a4fc4359e2c",
   "metadata": {},
   "source": [
    "# 원본 CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d964a0-9942-4334-ae0c-e0d3f71d3d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.mkdir(\"original_pet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e2b139-b9e8-4ef0-bd97-b59c7ee82335",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(path.ls())) :\n",
    "    img = PILImage.create(get_image_files(path)[i])\n",
    "    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n",
    "    (w, h) = (img.shape[0], img.shape[1])\n",
    "    # a = random.uniform(0, w*0.7)\n",
    "    # b = random.uniform(0, h*0.9)\n",
    "    shape = [(a, b), (a+100, b+50)]\n",
    "    # font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.08))\n",
    "    name = str(list(path.ls())[i]).split('/')[-1]\n",
    "    fname = name.split('.')[-1]\n",
    "    if name[0].isupper() == True :\n",
    "        img1 = ImageDraw.Draw(img)  \n",
    "        # img1.rectangle(shape, fill =\"white\", outline =\"black\")\n",
    "        # ImageDraw.Draw(img).text((a, b), 'CAT', (0,0,0), font=font)\n",
    "        img.save(\"original_pet/\"+name)\n",
    "    else: \n",
    "        img1 = ImageDraw.Draw(img)  \n",
    "        # img1.rectangle(shape, fill =\"black\", outline =\"black\")\n",
    "        # ImageDraw.Draw(img).text((a, b), 'DOG', (255,255,255), font=font)\n",
    "        img.save(\"original_pet/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960f4398-d135-4207-912b-2b8ffd533e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_o=Path('original_pet')   #랜덤박스넣은사진"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd1a160-f447-4611-beba-f0ec9da19ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_o=get_image_files(path_o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c77f02-7fe4-410d-ad22-2287b53a7486",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_o=ImageDataLoaders.from_name_func(path_o,files_o,label_func,item_tfms=Resize(512)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7d5bcd-8d84-4019-b348-99f062e9305d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_o1=cnn_learner(dls_o,resnet34,metrics=error_rate)\n",
    "lrnr_o1.fine_tune(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c119b8d-a7fc-4f8b-96d7-f72080efd5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_o1=lrnr_o1.model[0]\n",
    "net_o2=lrnr_o1.model[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae980b6e-e1b5-4821-8665-bb4065e044c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_o2 = torch.nn.Sequential(\n",
    "    torch.nn.AdaptiveAvgPool2d(output_size=1), \n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512,out_features=2,bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b94d6-edc1-4638-b672-c397d5d08f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_o=torch.nn.Sequential(net_o1,net_o2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e99345-5b9a-4c75-9586-91eba8711498",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_o2=Learner(dls_o,net_o,metrics=accuracy) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb994cde-42b8-43e1-9712-1879de29426f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrnr_o2.fine_tune(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa00a083-8e5e-4316-a006-84871359bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_o = ClassificationInterpretation.from_learner(lrnr_o2)\n",
    "interp_o.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f167908-2c98-48cd-9d44-261bcf91420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[7389])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94cdebf-943b-4b0a-aca5-106538b5e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "camimg_o = torch.einsum('ij,jkl -> ikl', net_o2[2].weight, net_o1(x).squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a476ee42-fdf8-4353-b8fe-3c7a717b4388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 서연 수정 code\n",
    "fig, (ax1,ax2) = plt.subplots(1,2) \n",
    "# \n",
    "dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax1)\n",
    "ax1.imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\n",
    "#\n",
    "dls_r.train.decode((x_o,))[0].squeeze().show(ax=ax2)\n",
    "ax2.imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\n",
    "fig.set_figwidth(8)            \n",
    "fig.set_figheight(8)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0ce733-3353-4f6a-8eb1-6cd8199115c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n",
    "        camimg_o = torch.einsum('ij,jkl -> ikl', net_o2[2].weight, net_o1(x_o).squeeze())\n",
    "        a_o,b_o = net_r(x_o).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o)) \n",
    "        if catprob>dogprob: \n",
    "            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731f3aa7-4932-49e4-9fa8-ba791cd5afdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(5,5) \n",
    "k=0 \n",
    "for i in range(5):\n",
    "    for j in range(5): \n",
    "        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n",
    "        camimg_o = torch.einsum('ij,jkl -> ikl', net_o2[2].weight, net_o1(x).squeeze())\n",
    "        a_o,b_o = net_o(x_o).tolist()[0]\n",
    "        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\n",
    "        if catprob>dogprob: \n",
    "            test=camimg_o[0]-torch.min(camimg_o[0])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n",
    "        else: \n",
    "            test=camimg_o[1]-torch.min(camimg_o[1])\n",
    "            A1=torch.exp(-0.1*test)\n",
    "            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n",
    "            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n",
    "            (x1*0.25).squeeze().show(ax=ax[i][j])\n",
    "            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n",
    "        k=k+1 \n",
    "fig.set_figwidth(16)            \n",
    "fig.set_figheight(16)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664dfc2b-7bfa-4a43-93ae-3a5605b5a1ec",
   "metadata": {},
   "source": [
    "- `.mat`파일 있나 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151075d8-943f-4021-828a-ce372a9d0e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(path_o.ls())) :\n",
    "    img = PILImage.create(get_image_files(path_o)[i])\n",
    "    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n",
    "    name = str(list(path_o.ls())[i]).split('/')[-1]\n",
    "    fname = name.split('.')[-1]\n",
    "    if fname!=\"jpg\" : \n",
    "        print(name)\n",
    "    else : pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b8ab9-7b89-4565-8e66-b187ee28aaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[1])]))\n",
    "camimg_o = torch.einsum('ij,jkl -> ikl', net_o2[2].weight, net_o1(x).squeeze())\n",
    "a_o,b_o = net_o(x_o).tolist()[0]\n",
    "catprob_o, dogprob_o = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\n",
    "if catprob_o>dogprob_o: \n",
    "    test_o=camimg_o[0]-torch.min(camimg_o[0])\n",
    "    A1_o=torch.exp(-0.01*test_o)\n",
    "    X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n",
    "    Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "    x1_o=x_o.squeeze().to('cpu')*Y1_o-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n",
    "    (x1_o*0.25).squeeze().show()\n",
    "else: \n",
    "        test_o=camimg_o[1]-torch.min(camimg_o[1])\n",
    "        A1_o=torch.exp(-0.01*test_o)\n",
    "        X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n",
    "        Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n",
    "        x1_o=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n",
    "        (x1_o*0.25).squeeze().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0cce8-7b17-4f9d-ac92-e31d0c1118c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #저장 참고\n",
    "# np_arr = np.array(tensor, dtype=np.uint8)\n",
    "# img = PIL.Image.fromarray(np_arr)\n",
    "# img.save('path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ed3765-0bac-4637-9f6e-90e1716ab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# name = str(list(path.ls())[1]).split('/')[-1]\n",
    "# res1=(x1*0.35).squeeze()\n",
    "# res1.show()\n",
    "# save_image(res1, \"pet3_mode1_res/\"+name)\n",
    "#res1.save(\"pet3_mode1_res/\"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880fd85e-28d1-4726-aa4d-f5d05c727acd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
