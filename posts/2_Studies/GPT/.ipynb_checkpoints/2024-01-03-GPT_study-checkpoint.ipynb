{
 "cells": [
  {
   "cell_type": "raw",
   "id": "cdf5a848-ef50-4248-98f3-c36c2cb60b26",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"**[GPT]** Models\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"03/01/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "405f594e-761b-416d-a142-28485ad764df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bibliography: ref.bib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56724fee-113b-4ba9-8c9e-fbe78cff8d3e",
   "metadata": {},
   "source": [
    "# flowchart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a77c52-837d-402b-9c76-2c8c74393fcc",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "flowchart LR\n",
    "    Aid1([Real\\nData]):::base --> B[Experiment 1]:::ex1\n",
    "    Cid1([Real\\nData]):::base & Eid1([Synthetic\\nData]):::base --> D[Experiment 2]:::ex2\n",
    "    Fid1([Synthetic\\nData]):::base --> G[Experiment 3]:::ex3\n",
    "    classDef ex1 fill:#34cceb\n",
    "    classDef ex2 fill:#34eb64\n",
    "    classDef ex3 fill:#eb9e34\n",
    "    classDef base fill:#faf9f7\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d6fdc7-6c2d-4a2c-84de-a3211a8e6b13",
   "metadata": {},
   "source": [
    "# Improt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b2301e6-57e5-4c25-9f93-3d27d1d85935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a730aa-f3f5-468c-beec-fd762f4fb41f",
   "metadata": {},
   "source": [
    "# WeightedEnsembleModel[@caruana2004ensemble]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fa7ea2-6865-4964-ab75-6da46037ffa4",
   "metadata": {},
   "source": [
    "Weighted ensemble meta-model that implements Ensemble Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd0da7-2c49-4611-b203-d067c2b4044d",
   "metadata": {},
   "source": [
    "https://auto.gluon.ai/0.8.1/tutorials/multimodal/text_prediction/beginner_text.html#other-examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "826532fa-d478-4089-ae80-77789cc82917",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2918832e-0270-484d-afc1-fdb6b355f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet | Columns = 2 / 2 | Rows = 67349 -> 67349\n",
      "Loaded data from: https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet | Columns = 2 / 2 | Rows = 872 -> 872\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43787</th>\n",
       "      <td>very pleasing at its best moments</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16159</th>\n",
       "      <td>, american chai is enough to make you put away the guitar , sell the amp , and apply to medical school .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59015</th>\n",
       "      <td>too much like an infomercial for ram dass 's latest book aimed at the boomer</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5108</th>\n",
       "      <td>a stirring visual sequence</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67052</th>\n",
       "      <td>cool visual backmasking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35938</th>\n",
       "      <td>hard ground</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49879</th>\n",
       "      <td>the striking , quietly vulnerable personality of ms. ambrose</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51591</th>\n",
       "      <td>pan nalin 's exposition is beautiful and mysterious , and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56780</th>\n",
       "      <td>wonderfully loopy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>most beautiful , evocative</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                        sentence  \\\n",
       "43787                                                                         very pleasing at its best moments    \n",
       "16159  , american chai is enough to make you put away the guitar , sell the amp , and apply to medical school .    \n",
       "59015                              too much like an infomercial for ram dass 's latest book aimed at the boomer    \n",
       "5108                                                                                 a stirring visual sequence    \n",
       "67052                                                                                   cool visual backmasking    \n",
       "35938                                                                                               hard ground    \n",
       "49879                                              the striking , quietly vulnerable personality of ms. ambrose    \n",
       "51591                                                 pan nalin 's exposition is beautiful and mysterious , and    \n",
       "56780                                                                                         wonderfully loopy    \n",
       "28518                                                                                most beautiful , evocative    \n",
       "\n",
       "       label  \n",
       "43787      1  \n",
       "16159      0  \n",
       "59015      0  \n",
       "5108       1  \n",
       "67052      1  \n",
       "35938      0  \n",
       "49879      1  \n",
       "51591      1  \n",
       "56780      1  \n",
       "28518      1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.core.utils.loaders import load_pd\n",
    "train_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/train.parquet')\n",
    "test_data = load_pd.load('https://autogluon-text.s3-accelerate.amazonaws.com/glue/sst/dev.parquet')\n",
    "subsample_size = 1000  # subsample data for faster demo, try setting this to larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0)\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "77100a23-f38a-4a6d-b4c8-94b8d1cbf361",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.11.5\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #86~20.04.2-Ubuntu SMP Mon Jul 17 23:27:17 UTC 2023\n",
      "CPU Count:          28\n",
      "Pytorch Version:    2.0.1+cu117\n",
      "CUDA Version:       11.7\n",
      "Memory Avail:       139.10 GB / 251.39 GB (55.3%)\n",
      "Disk Space Avail:   457.17 GB / 915.32 GB (49.9%)\n",
      "===================================================\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1, 0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "\n",
      "AutoMM starts to create your model. ✨✨✨\n",
      "\n",
      "To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir /home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst\n",
      "    ```\n",
      "\n",
      "INFO: Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bd942ed8304cc7932fc82c6d6a5217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618169550a8642daa486955b7176c5a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2a1050f537f47b7bd21f3862454dcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75a66ab8ab3f4f2e8e7ee5196c678088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ab50e007b7492394ffd67640b2b377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU Count: 1\n",
      "GPU Count to be Used: 1\n",
      "GPU 0 Name: NVIDIA GeForce RTX 3090\n",
      "GPU 0 Memory: 0.0GB/23.69GB (Used/Total)\n",
      "\n",
      "INFO: Using 16bit Automatic Mixed Precision (AMP)\n",
      "INFO: GPU available: True (cuda), used: True\n",
      "INFO: TPU available: False, using: 0 TPU cores\n",
      "INFO: IPU available: False, using: 0 IPUs\n",
      "INFO: HPU available: False, using: 0 HPUs\n",
      "INFO: You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "INFO: LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "INFO: \n",
      "  | Name              | Type                         | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 108 M \n",
      "1 | validation_metric | MulticlassAccuracy           | 0     \n",
      "2 | loss_func         | CrossEntropyLoss             | 0     \n",
      "-------------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.573   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eea161097344a0820a23dcf444dd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 3: 'val_acc' reached 0.54000 (best 0.54000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=0-step=3.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 0, global step 7: 'val_acc' reached 0.64500 (best 0.64500), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=0-step=7.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 1, global step 10: 'val_acc' reached 0.73000 (best 0.73000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=1-step=10.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 1, global step 14: 'val_acc' reached 0.89000 (best 0.89000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=1-step=14.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 2, global step 17: 'val_acc' reached 0.89000 (best 0.89000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=2-step=17.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 2, global step 21: 'val_acc' reached 0.88500 (best 0.89000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=2-step=21.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 3, global step 24: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 3, global step 28: 'val_acc' reached 0.91000 (best 0.91000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=3-step=28.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 4, global step 31: 'val_acc' reached 0.90500 (best 0.91000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=4-step=31.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 4, global step 35: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 5, global step 38: 'val_acc' reached 0.90000 (best 0.91000), saving model to '/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst/epoch=5-step=38.ckpt' as top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 5, global step 42: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 6, global step 45: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 6, global step 49: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 7, global step 52: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 7, global step 56: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 8, global step 59: 'val_acc' was not in top 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Epoch 8, global step 63: 'val_acc' was not in top 3\n",
      "Start to fuse 3 checkpoints via the greedy soup algorithm.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e19e0b01ad24ae195ec4a7f9cc931cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350aece6889c40db9b55d6840df98412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd60a961dfd24683ba4b95555ebed29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model. 🎉🎉🎉\n",
      "\n",
      "To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"/home/csy/Dropbox/sy_hub/posts/2_Studies/GPT/tmp/6e8112a4b9be49ada3aab9f73a63cb61-automm_sst\")\n",
      "    ```\n",
      "\n",
      "If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub (https://github.com/autogluon/autogluon/issues).\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x7f186bb7cb50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import uuid\n",
    "model_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\n",
    "predictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\n",
    "predictor.fit(train_data, time_limit=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49308840-3794-4d56-b659-bd6b51ce924b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5af96a18ea42d992a4b475864638e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8922018348623854}\n"
     ]
    }
   ],
   "source": [
    "test_score = predictor.evaluate(test_data)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75623065-8769-4a14-8d29-093aa7f3bdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a98993d8ff5424996e8b098b21d81ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8922018348623854, 'f1': 0.8929384965831435}\n"
     ]
    }
   ],
   "source": [
    "test_score = predictor.evaluate(test_data, metrics=['acc', 'f1'])\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f861ce1-b677-4ddb-85ac-ba8f39d6ad98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e63e8a0c6644b4be789eb8c2f645c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n",
      "\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"it's a charming and often affecting journey.\"\n",
    "sentence2 = \"It's slow, very, very, very slow.\"\n",
    "predictions = predictor.predict({'sentence': [sentence1, sentence2]})\n",
    "print('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\n",
    "print('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e6b16e6-4734-4010-aa5f-30f01e58aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047f2bf1f89448282a4e028d534775e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentence\": it's a charming and often affecting journey. \"Predicted Class-Probabilities\": [5.8611616e-04 9.9941385e-01]\n",
      "\"Sentence\": It's slow, very, very, very slow. \"Predicted Class-Probabilities\": [0.98935777 0.01064222]\n"
     ]
    }
   ],
   "source": [
    "probs = predictor.predict_proba({'sentence': [sentence1, sentence2]})\n",
    "print('\"Sentence\":', sentence1, '\"Predicted Class-Probabilities\":', probs[0])\n",
    "print('\"Sentence\":', sentence2, '\"Predicted Class-Probabilities\":', probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f1760e3-294c-47da-896c-2d7f0733ae16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef78e1e064c4a03a6b5168076644104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = predictor.predict(test_data)\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ebcc50a-2f11-446a-a18c-9222250b76b7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "449be839-22a6-4ced-886a-7c2c574c0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.core.models import WeightedEnsembleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d6f7660-43e5-44c3-ab03-7648da8c47a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BaggedEnsembleModel.__init__() missing 1 required positional argument: 'model_base'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./tmp/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muuid\u001b[38;5;241m.\u001b[39muuid4()\u001b[38;5;241m.\u001b[39mhex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-automm_sst\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m WeightedEnsembleModel(label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124macc\u001b[39m\u001b[38;5;124m'\u001b[39m, path\u001b[38;5;241m=\u001b[39mmodel_path)\n\u001b[1;32m      3\u001b[0m predictor\u001b[38;5;241m.\u001b[39mfit(train_data, time_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m180\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.11/site-packages/autogluon/core/models/ensemble/weighted_ensemble_model.py:23\u001b[0m, in \u001b[0;36mWeightedEnsembleModel.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/gpt/lib/python3.11/site-packages/autogluon/core/models/ensemble/stacker_ensemble_model.py:46\u001b[0m, in \u001b[0;36mStackerEnsembleModel.__init__\u001b[0;34m(self, base_model_names, base_models_dict, base_model_paths_dict, base_model_types_dict, base_model_types_inner_dict, base_model_performances_dict, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     38\u001b[0m     base_model_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m     45\u001b[0m ):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m base_model_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         base_model_names \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: BaggedEnsembleModel.__init__() missing 1 required positional argument: 'model_base'"
     ]
    }
   ],
   "source": [
    "model_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\n",
    "predictor = WeightedEnsembleModel(label='label', eval_metric='acc', path=model_path)\n",
    "predictor.fit(train_data, time_limit=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "61a52e5a-8b9e-4f1a-99bb-74c8977f1d11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5af96a18ea42d992a4b475864638e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8922018348623854}\n"
     ]
    }
   ],
   "source": [
    "test_score = predictor.evaluate(test_data)\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2811dd5-8ffe-4b1d-9f45-6d4a7f03d700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a98993d8ff5424996e8b098b21d81ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'acc': 0.8922018348623854, 'f1': 0.8929384965831435}\n"
     ]
    }
   ],
   "source": [
    "test_score = predictor.evaluate(test_data, metrics=['acc', 'f1'])\n",
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec36c246-9515-47c5-affe-e80f8d9914d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e63e8a0c6644b4be789eb8c2f645c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentence\": it's a charming and often affecting journey. \"Predicted Sentiment\": 1\n",
      "\"Sentence\": It's slow, very, very, very slow. \"Predicted Sentiment\": 0\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"it's a charming and often affecting journey.\"\n",
    "sentence2 = \"It's slow, very, very, very slow.\"\n",
    "predictions = predictor.predict({'sentence': [sentence1, sentence2]})\n",
    "print('\"Sentence\":', sentence1, '\"Predicted Sentiment\":', predictions[0])\n",
    "print('\"Sentence\":', sentence2, '\"Predicted Sentiment\":', predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ee26c2ec-4c7e-41b5-9884-185f4a86857c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8047f2bf1f89448282a4e028d534775e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Sentence\": it's a charming and often affecting journey. \"Predicted Class-Probabilities\": [5.8611616e-04 9.9941385e-01]\n",
      "\"Sentence\": It's slow, very, very, very slow. \"Predicted Class-Probabilities\": [0.98935777 0.01064222]\n"
     ]
    }
   ],
   "source": [
    "probs = predictor.predict_proba({'sentence': [sentence1, sentence2]})\n",
    "print('\"Sentence\":', sentence1, '\"Predicted Class-Probabilities\":', probs[0])\n",
    "print('\"Sentence\":', sentence2, '\"Predicted Class-Probabilities\":', probs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53e66d18-e840-449e-baab-578b03449264",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ef78e1e064c4a03a6b5168076644104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions = predictor.predict(test_data)\n",
    "test_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e330c11-3447-4577-a908-8188d2fd8046",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
