{
 "cells": [
  {
   "cell_type": "raw",
   "id": "78032aae-cbe0-4cc0-b5a3-b2554eb62675",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Review: Self-Consistency: A Fundamental Concept in Statistics\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2024-02-05\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08abbf-ea9e-46cf-89f3-e76698dfe1b2",
   "metadata": {},
   "source": [
    "**Y = Observed Data, X = Completed Data** 로 이해하며 읽을 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f498f-60a1-42b3-b56c-224802b3e4db",
   "metadata": {},
   "source": [
    "[Paper link](https://projecteuclid.org/journals/statistical-science/volume-11/issue-3/Self-consistency-a-fundamental-concept-in-statistics/10.1214/ss/1032280215.full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a2393-f697-4445-8eac-a1651ee00bf3",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "664c2de6-42ed-4a7f-bab6-e1a2e9e05a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d792ae-946f-4432-9124-d5dd36d72e12",
   "metadata": {},
   "source": [
    "# 2. Self-Consistent Random Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3501f-3d8d-465d-bc5f-2f8c2b4a5907",
   "metadata": {},
   "source": [
    "Suppose we want to represent or approximate the distribution of a random vector $\\bf{X}$ by a random vector $\\bf{Y}$ whose structure is less complex.\n",
    "\n",
    "구조가 간단한(?) 확률벡터 Y로 확률벡터 X의 분포를 근사하거나 나타내려 한다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128de7c-bec0-4949-96bc-a1506759346b",
   "metadata": {},
   "source": [
    "One measure of how well $\\bf{Y}$ approximates $\\bf{X}$ is the mean squared error $\\cal{E}||\\bf{X}-\\bf{Y}||^2$.\n",
    "\n",
    "Y로 X의 근사값을 잘 찾는 한 측정치는 평균제곱오차를 구하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3a45a-f194-4ef5-8b82-f76b365ce411",
   "metadata": {},
   "source": [
    "In terms of mean squarred error, the approximation of $\\bf{X}$ by $\\bf{Y}$ can always be improved using $\\cal{E} [\\bf{X}|\\bf{Y}]$ since, for any function $g$, $\\cal{E} ||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-g(\\bf{Y})||^2$.\n",
    "\n",
    "평균제곱오차에 관해 말하자면, Y에 의해 X의 근사치는 항상 Y 가 주어졌을때 X의 기대값으로 개선될 수 있는데, 어느 함수 g에 대해서나 위의 식이 성립한다.\n",
    "\n",
    "- $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ 이게 최솟값이라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba3f77-77d9-4b2f-afc2-37f7f6b81ea4",
   "metadata": {},
   "source": [
    "Taking $g$ to be the identity gives $\\cal{E} || \\bf{X} - \\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-\\bf{Y}||^2$.\n",
    "\n",
    "함수 g에 Y를 주면, 위의 식이 된다.\n",
    "\n",
    "- E[X|Y] =Y일때 Y가 X에 대해 self-cosistent 하다고 했으니까 함수 g(Y) = Y라 한다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb132a1-1f39-439b-80cf-080e3ac6a4cc",
   "metadata": {},
   "source": [
    "Thus the random vector $Y$ is locally optimal for approximating $\\bf{X}$ if $\\bf{Y} = \\cal{E} [\\bf{X}|\\bf{Y}]$, in which case we call $Y$ self-consistent for $\\bf{X}$.\n",
    "\n",
    "만일 Y가 Y가 주어졌을때 X의 기댓값과 같다면, 확률벡터 Y는 X에 근사하는데 있어 locally optimal 하다. 이때, Y를 X에 대해 self-consistent 하다고 부른다.\n",
    "\n",
    "- $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ 계산할때에 대해(locally) E(X|Y) = Y라면, 최적의 값(최소의 값, optimal)하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98eb38-2ba4-4837-bad1-2099d81a78d6",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#CCCCFF\"> **DEFINITION 2.1.** </span> For two jointly distributed random vectors $\\bf{X}$ and $\\bf{Y}$, we say that $\\bf{Y}$ is self-consistent for $\\bf{X}$ if $\\cal{E} (\\bf{X}|\\bf{Y}) = \\bf{Y}$ almost surely.\n",
    "\n",
    "두 결합 분포된 확률벡터 X와 Y에 대해 Y가 주어졌을때 X의 기댓값이 Y와 동일하다면 Y를 X에 대해 self-consistent 하다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55a3c1b-a3eb-4a2e-83ae-7218140f2713",
   "metadata": {},
   "source": [
    "`-` 회귀에서 X를 추정하려 할 때, $E(X|Y) = \\hat{X}$로 나타낼 수 있는데, $E(X|Y) = \\hat{X} = Y$라면, Y는 X에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964fb31-c8f2-470d-a0b2-bd0f9292f6fb",
   "metadata": {},
   "source": [
    "`1` $\\bf{Y} = \\bf{X} + \\epsilon$ $(\\epsilon \\sim i.i.d.)$이라면, $E(X|Y) = Y$ $Y$는 $X$에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc3995-6ebe-44da-b7c8-bd7f8c237395",
   "metadata": {},
   "source": [
    "`2` $\\bar{X} = \\frac{1}{3}(X_1+X_2+X_3)$, $\\tilde{X} = \\frac{1}{2}(X_2+X_3)$,\n",
    "\n",
    "$E(\\bar{X}|\\tilde{X}) = E(\\frac{1}{3}X_1 + \\frac{1}{3}\\frac{1}{2}X_2 + \\frac{1}{3}\\frac{1}{2}X_3 | \\tilde{X}) = E(\\frac{1}{3}X_1|\\tilde{X}) + E(\\frac{1}{3}\\frac{1}{2}X_2 + \\frac{1}{3}\\frac{1}{2}X_3 | \\tilde{X})$\n",
    "\n",
    "- self-consistent 되기 위한 조건\n",
    "\n",
    "1. $E(\\frac{1}{3} X_1|\\tilde{X})= E(\\frac{1}{3} X_1)$ 이 $\\frac{1}{3} \\tilde{X}$이어야 한다.\n",
    "2. $E(X_1 | \\tilde{X}) = E(X_1) = \\tilde{X}$ 이어야 한다.\n",
    "3. $\\mu = \\tilde{X}$이어야 한다.\n",
    "\n",
    "$\\tilde{X}$는 $\\bar{X}$에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca950aef-6022-4953-bf2d-41743167b241",
   "metadata": {},
   "source": [
    "We will assume implicitly that moments exist as required.\n",
    "\n",
    "필요에 따라 이런 moment가 존재한다고 암묵적으로 가정할 것이다.\n",
    "\n",
    "- definition의 경우가 존재한다고 가정한다..?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2929c-9ce9-4c9c-813f-ca6cebbf21d2",
   "metadata": {},
   "source": [
    "The notion of self-consistency is not vacuous, as the two extreme cases demonstrate.\n",
    "\n",
    "두 극단적인 경우에서 나타나는 듯이, self-consistency는 모호한 개념이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e50f67-bd54-4e7e-bcfb-4d82f70d2ad4",
   "metadata": {},
   "source": [
    "The random vector $\\bf{X}$ is self-consistent for $\\bf{X}$ and represents no loss of information.\n",
    "\n",
    "확률 벡터 X는 X에 대해 self-consistent 하며, information의 손실이 전혀 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370cfbb-3a0b-471a-b8d5-d5c6aaec5bb3",
   "metadata": {},
   "source": [
    "$\\bf{Y} = \\cal{E} [\\bf{X}]$ is also self-consistent for $\\bf{X}$ and represents a total loss of information except for the location of the distribution.\n",
    "\n",
    "Y=E(X)는 X에 대해 self-consistent 하며, 분포의 위치를 제외하고 information이 전체적으로 손실된다.\n",
    "\n",
    "total loss of information은 만약 $Y = \\{Y_1,Y_2,... \\}$ 있을때 값 신경 쓰지 않고 그냥 평균으로 사용할때이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af73dd-8877-4522-9d1f-f34763212354",
   "metadata": {},
   "source": [
    "Interesting self-consistent distributions range in between these two extremes.\n",
    "\n",
    "이 두 극단적인 경우 사이에 self-consistent 분포들이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dcce0f-b52d-487c-8be0-353bd66c45b4",
   "metadata": {},
   "source": [
    "**보류**\n",
    "\n",
    "loss of information 정의 정확히 짚기\n",
    "\n",
    "`1` $\\bf{X}$는 information 손실이 없지만, $\\bf{Y}=E(X)$는 $\\epsilon$을 잃어서 information 손실이 생긴다.\n",
    "\n",
    "`2` $\\bar{X}$는 information 손실이 없지만, $\\tilde{X} = E(\\bar{X})$는 $x_1$이 $\\mu$로 바뀌어 information 손실이 생긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fea488-6850-401f-b78b-8f1e6edcbcc9",
   "metadata": {},
   "source": [
    "Many relevant cases of self-consistency are obtained by taking conditional means over subsets of the sample space of $\\bf{X}$.\n",
    "\n",
    "self-consistency의 많은 관련된 경우는 집합 𝐗의 표본 공간의 부분집합에 대한 조건부 평균을 취함으로써 구해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07b4bd-2127-4aeb-8ad3-dcbc2a4c6faa",
   "metadata": {},
   "source": [
    "Another simple example of self-consistency is the following:\n",
    "\n",
    "또다른 self-consistency의 단순한 예제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c2b98-eb10-4951-8c42-85c80b174ed5",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.1.** </span> *Partial sums.* Let $\\{X_n\\}$ denote a sequence of independent, mean-zero random variables, and let $S_n = \\sum^n_{i=1} X_i$.\n",
    "\n",
    "부분합, x_n을 독립이고, 평균이 0인 확률 변수라고 할 때, x의 합을 Sn이라 두자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a088e69-2dfc-4bfa-8c00-c82a3bb1ab86",
   "metadata": {},
   "source": [
    "Then $\\cal{E}$$[S_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] = S_n$.\n",
    "\n",
    "그러면 이 식이 성립함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306fb59-91f8-4324-84f0-2d7bbfd0179b",
   "metadata": {},
   "source": [
    "`-` 증명 $\\cal{E}$$[S_{n+k}|S_n]=$$\\cal{E}$$[S_n + X_{n+1} + \\dots + X_{n+k}|S_n]=$$\\cal{E}$$[X_{1} + \\dots + X_n + X_{n+1} + \\dots +X_{n+k}|S_n]=$$\\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] + S_n=S_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7da5e3-2df3-432f-950f-96c51cd2de93",
   "metadata": {},
   "source": [
    "Thus, $S_n$ is self-consistent for $S_{n+k}, k > 1$.\n",
    "\n",
    "그려면 sn은 sn+k에 대해 self-consistent하다고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f9b94-fa1f-4cb0-b0bb-a8fb3353fa51",
   "metadata": {},
   "source": [
    "The same property holds more generally if $\\{S_n\\}_{n\\ge1}$ represents a martingale process.\n",
    "\n",
    "만일 저 식이 마틴게일 프로세스를 나타낸다면 동일한 특성이 유지된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32cc52-9e34-43db-b65c-6327275abf24",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "martingale process 의 특징\n",
    "\n",
    "- 기댓값의 일정성\n",
    "- 확률변수의 분포 고정\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a4dc4-f84b-4c7c-b052-e467033ae5db",
   "metadata": {},
   "source": [
    "For a given $\\bf{X}$, a self-consistent approximation $\\bf{Y}$ can be generated by partitioning the sample space of $\\bf{X}$ and defining $\\bf{Y}$ as a random variable taking as values the conditional means, of subsets in the partition.\n",
    "\n",
    "주어진 확률 변수 $\\bf{X}$에 대한 self-consistent approximation $\\bf{Y}$는 $\\bf{X}$의 표본 공간을 분할하여 각 분할된 부분집합에 대한 조건부 평균을 값으로 가지는 랜덤 변수로 정의될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc98ca-dba9-4f5b-be4c-8f49766a8354",
   "metadata": {},
   "source": [
    "This is illustrated by our next example, in which the support of $\\bf{X}$ is partitioned into two half-planes.\n",
    "\n",
    "다음 예제에서 확률 변수 $\\bf{X}$의 support(모든 값?)가 두 개의 반 평면으로 나뉜다.(x1>=0,x1<0인듯?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b9171-5175-4f58-85cb-6c4ca7a72da3",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.2.** </span> *Two principal points.* Let $\\bf{X} = (X_1, X_2)' \\sim  N_2(0, I_2)$. Note that $\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{2/\\pi}$. Let $\\bf{Y} = (-\\sqrt{2/\\pi}, 0)'$ if $X_1 < 0$ and $\\bf{Y} = (\\sqrt{2/\\pi}, 0)'$ if $X_1 \\ge 0$. Then $\\bf{Y}$ is self-consistent for $\\bf{X}$.\n",
    "\n",
    "$\\bf{Y} = \\begin{cases}(-\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 < 0 \\\\ (\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 \\ge 0 \\end{cases}$\n",
    "\n",
    "$\\cal{E}$$[X_1|X_1 \\ge 0] = \\bf{Y} = \\sqrt{\\frac{2}{\\pi}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5f6342-28b5-4e55-a559-f1d2152ae1fe",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"Example 2.2 Uniform 버전\"}\n",
    "$X_1 \\sim U(0,1), X_2 \\sim U(0,1)$ $(X_1,X_2)$는 독립이라면, $\\cal{E}$$[X_1|X_1 \\ge 0.5] = 0.75$\n",
    "\n",
    "$Y = \\begin{cases}(0.25, 0)' & if X_1 < 0.5 \\\\ (0.75, 0)' & if X_1 \\ge 0.5 \\end{cases}$\n",
    "\n",
    "$Y$는 $X_1$이 0.5보다 클 때 0.75로, $\\cal{E}$$[X_1|X_1 \\ge 0.5]$와 같다. 따라서 $Y$는 $X$에 대해 self-consistent하다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e160676-1c74-470c-9bef-713f10a7e389",
   "metadata": {},
   "source": [
    "See Section 6 for a definition of principal points, and see Figure 7 for a generalization of this example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8e3950-7e0f-4831-9a08-7f708020d186",
   "metadata": {},
   "source": [
    "The preceding example illustrates the purpose of self-consistency quite well.\n",
    "\n",
    "다음 예제는 self-consistency의 목적을 잘 나타낸다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5110c4-aa99-4d70-8885-a6e1b52c7d1f",
   "metadata": {},
   "source": [
    "It is actually an application of our first lemma.\n",
    "\n",
    "첫번째 lemma를 응용한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb40a8-ffbb-4d00-bfdb-a602d1ef2a78",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#E0CCEF\"> **Lemma 2.1.** </span> *For a $p$-variate random vector* $\\bf{X}$, *suppose* $\\mathcal{S} \\subset \\mathbb{R}^p$ *is a measurable set such that* $\\forall \\bf{y} \\in \\mathcal{S}, \\bf{y} = \\cal{E}$$[\\bf{X} | \\bf{X} \\in \\mathbb{D_y}]$, *where* $\\mathbb{D}_y$ *is the domain of attraction of* $\\bf{y}$, *that is,* $\\mathbb{D}_y = \\{\\bf{x} \\in \\mathbb{R}^p: ||\\bf{x} - \\bf{y}|| < ||\\bf{x} - \\bf{y}^*||, \\forall \\bf{y}^* \\in \\mathcal{S} \\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba16b6cd-f20d-4b5b-9fa2-dad3ea4e3ac5",
   "metadata": {},
   "source": [
    "p변량 랜덤 벡터 X에 대해 p차원의 실수 집합의 부분 집합인 S가 측정 가능한 집합이고, 모든 y가 S에 속할때, y는 y에 수렴하는 도메인 Dy에 X가 속하는 조건에서 X의 기댓값과 같다.\n",
    "\n",
    "Dy(the domain of attraction) = x는 p차원의 실수 집합(R^p)에 속하는 값이고, p차원의 실수 집합(R^p)의 부분 집합(S)에 속하는 모든 y * 에 대해 x,y 의 거리가 x,y * 의 거리보다 짧은 값들의 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb71d8d-83ae-41d0-9d60-711402910a42",
   "metadata": {},
   "source": [
    "Defne $\\bf{Y} = \\bf{y}$ if $\\bf{X} \\in \\mathbb{D}_y$: Then $\\bf{Y}$ is self-consistent for $\\bf{X}$.\n",
    "\n",
    "X가 y의 domain of attration에 속한다면, Y=y라고 정의하며, Y는 X에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41106db-9454-4d50-8310-595972e75fe7",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#F5F1F8\"> **Proof.** </span> $\\cal{E}$$[\\bf{X} | \\bf{Y}=\\bf{y}] =$$\\cal{E}$$[\\bf{X}|\\bf{X} \\in \\mathbb{D}_y] = \\bf{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85844297-5883-402d-9ee6-b570443a17a1",
   "metadata": {},
   "source": [
    "In Example 2.2, $\\cal{S}$ consists of only two points, and the associated domains of attraction are the half-planes given by $x_1 < 0$ and $x_1 > 0$.\n",
    "\n",
    "예제 2.2에서 S는 두 점으로 구성되어 있고, associated domain of attraction은 x_1<0이거나 x_1>0인 half-plane이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e762e4cc-130b-454f-9561-5d39f05289cd",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"예제 2.2에서 lemma2.1 찾기\"}\n",
    "- $p = 2$, p 변량 확률 벡터 $\\bf{X} = (X_1, X_2)' \\sim  N_2(0, I_2)$ 에 대해\n",
    "- p차원 실수 집합의 부분 집합인 $S = \\{ (-\\sqrt{2/\\pi}, 0)', (\\sqrt{2/\\pi}, 0)' \\}$가 모든 y가 S에 속한다는 조건 아래 측정 가능한 집합일때,\n",
    "- $y = \\cal{E}$$[\\bf{X} | \\bf{X} \\in \\mathbb{D_y}]$ 이다.\n",
    "- The domain of attraction은 $X_1 \\ge 0$, $X_1 < 0$인 half-plane\n",
    "\n",
    "`-` $X$가 $\\mathbb{D}_y$에 속한다면, $\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{2/\\pi}$ 여기서 $X_1 \\ge 0$ 조건이 $X\\in \\mathbb{D}_y$와 동등한 개념으로 보인다.\n",
    "\n",
    "::: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2eadb4-fc5a-4613-a63b-85f31c6f75d0",
   "metadata": {},
   "source": [
    "The following three lemmas give elementary properties of self-consistent random vectors.\n",
    "\n",
    "다음 세 개의 lemma는 self-consistent한 랜덤 벡터의 기본적인 특성을 제시한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06c32f-c577-4678-816e-2996ab4a5af4",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#E0CCEF\"> **Lemma 2.2.** </span> If $\\bf{Y}$ is self-consistent for $\\bf{X}$, then $\\cal{E}$ $[\\bf{Y}]=$$\\cal{E}$$[\\bf{X}]$.\n",
    "\n",
    "Y가 X에 대해 self-consistent하다면, Y의 기댓값은 X의 기댓값과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c44ea-6a7d-4628-bf5e-ed0a2a22d3a2",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#F5F1F8\"> **Proof.** </span> The lemma follows from $\\cal{E}$$[\\cal{E}$$[\\bf{X}|\\bf{Y}]]=$$\\cal{E}$$[\\bf{X}]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff43c739-4a99-4653-bd89-4d0081c81163",
   "metadata": {},
   "source": [
    "We now introduce notation for the mean squared error (MSE) of a random vector $\\bf{Y}$ for $\\bf{X}$,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be4dfeb1-5fd6-414e-9259-41f5b5828af0",
   "metadata": {},
   "source": [
    "$MSE(\\bf{Y};\\bf{X})=\\cal{E}$$||\\bf{X}-\\bf{Y}||^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fee89f-cc6b-440e-8973-a97efb751545",
   "metadata": {},
   "source": [
    "The next lemma relates the MSE of a selfconsistent Y for X in terms of their respective covariance matrices.\n",
    "\n",
    "다음 lemma는 X에 대해 self-consistent한 Y의 MSE와 관련있는데, 이를 공분산 행렬로 각각 나타낼 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f051bbcd-0f55-4f9f-9b36-5af814d62b4c",
   "metadata": {},
   "source": [
    "Here, $\\Psi_\\bf{X}$ and $\\Psi_\\bf{Y}$ denote the covariance matrices of $\\bf{X}$ and $\\bf{Y}$, respectively.\n",
    "\n",
    "공분산 X,Y를 쓰는 법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3861442f-aab4-48cf-9bf9-3c378b01c115",
   "metadata": {},
   "source": [
    "$\\Psi_{X} = \\text{Cov}(X) = \n",
    "\\begin{bmatrix}\n",
    "\\text{Cov}(X_1, X_1) & \\text{Cov}(X_1, X_2) & \\cdots & \\text{Cov}(X_1, X_p) \\\\\n",
    "\\text{Cov}(X_2, X_1) & \\text{Cov}(X_2, X_2) & \\cdots & \\text{Cov}(X_2, X_p) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(X_p, X_1) & \\text{Cov}(X_p, X_2) & \\cdots & \\text{Cov}(X_p, X_p) \\\\\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$\\Psi_{Y} = \\text{Cov}(Y) = \n",
    "\\begin{bmatrix}\n",
    "\\text{Cov}(Y_1, Y_1) & \\text{Cov}(Y_1, Y_2) & \\cdots & \\text{Cov}(Y_1, Y_p) \\\\\n",
    "\\text{Cov}(Y_2, Y_1) & \\text{Cov}(Y_2, Y_2) & \\cdots & \\text{Cov}(Y_2, Y_p) \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\text{Cov}(Y_p, Y_1) & \\text{Cov}(Y_p, Y_2) & \\cdots & \\text{Cov}(Y_p, Y_p) \\\\\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f79a0-66bb-4a52-8fab-fa564087e0bd",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#E0CCEF\"> **Lemma 2.3.** </span> If $\\bf{Y}$ is self-consistent for $\\bf{X}$, then the following hold: (i) $\\Psi_\\bf{X}$ $\\ge \\Psi_\\bf{Y}$, that is, $\\Psi_{\\bf{X}} - \\Psi_{\\bf{Y}}$ is positive semidenite; (ii) $MSE(\\bf{Y};\\bf{X})= tr(\\Psi_{\\bf{X}}) - tr(\\Psi_\\bf{Y})$:^[결국 $tr(\\Psi_{\\bf{X}}) - tr(\\Psi_\\bf{Y})$를 계산하면 분산이 같은 값의 부분은 0이 되고, 값이 다른 부분만 남겠지]\n",
    "\n",
    "Y가 X에 대해 self-consistent하다면, X의 공분산행렬은 Y의 공분산행렬보다 크다. MSE는 X의 공분상행렬의 대각행렬에서 Y의 공분산 행렬의 대각 행렬을 뺀 것과 같다.(X의 분산 - Y의 분산 과 같다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba874294-2c45-4f1c-a13f-fb74615ecb1d",
   "metadata": {},
   "source": [
    "::: {.callout-important}\n",
    "예를 들어 x,y가 아래와 같이 있을때,($E(x)=0, x_1$이 결측이라 평균인 0으로 대체)\n",
    "\n",
    "$x = {0.2,-0.3,0.5}, y = {0,-0.3,0.5}$ (단, x는 completed data, y는 observed data라고 이해할때)\n",
    "\n",
    "평균으로 바꾼 y가 x의 분산보다 작다. 변동이 작아져서\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ca4f92-22d0-4489-914c-808dc55b60ca",
   "metadata": {},
   "source": [
    "$\\text{tr}(\\Psi_{X}) = \\text{Cov}(X_1, X_1) + \\text{Cov}(X_2, X_2) + \\cdots + \\text{Cov}(X_p, X_p) = Var(X)$\n",
    "\n",
    "$\\text{tr}(\\Psi_{Y}) = \\text{Cov}(Y_1, Y_1) + \\text{Cov}(Y_2, Y_2) + \\cdots + \\text{Cov}(Y_p, Y_p) = Var(Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf9d8ca-22d4-4550-ace2-a46ce690a5e5",
   "metadata": {},
   "source": [
    "See the Appendix for a proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1f2f99-272a-4849-8867-9a5b6441f289",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#F5F05E\"> *appendix* </span> Proof of Lemma 2.3. Without loss of generality assume $\\cal{E}$$[\\bf{X}] = 0$. For part (i), by self-consistency of $\\bf{Y}$ for $\\bf{X}$ and using the conditional variance formula $Cov[\\bf{X}] = Cov[\\cal{E}$$[\\bf{X}|\\bf{Y}]]+ \\cal{E}$$[Cov[\\bf{X}|\\bf{Y}]]$, we have $Cov[\\bf{X}] =$$Cov[\\bf{Y}] + \\cal{E}$$[Cov[\\bf{X}|\\bf{Y}]]$. But $Cov[\\bf{X}|\\bf{Y}]$ is positive semidefinite almost surely, and hence (i) follows. For part (ii) we have\n",
    "\n",
    "$\\cal{E}$$||\\bf{X}-\\bf{Y}||^2 =$ $\\cal{E}$$[\\bf{X}'\\bf{X}] -$ $2\\cal{E}$$[\\bf{Y'X}] +$ $\\cal{E}$$[\\bf{Y'Y}]$\n",
    "\n",
    "$= tr(\\Psi_\\bf{X})-$ $2\\cal{E}[\\cal{E}$$[\\bf{Y'X|Y}]]+$ $tr(\\Psi_\\bf{Y})$.\n",
    "\n",
    "$= tr(\\Psi_\\bf{X})-$ $2\\cal{E}$$[\\bf{Y'}\\cal{E}$$[\\bf{X|Y}]]+$ $tr(\\Psi_\\bf{Y})$.\n",
    "\n",
    "$= tr(\\Psi_\\bf{X})-$ $2\\cal{E}$$[\\bf{Y'Y}]+$ $tr(\\Psi_\\bf{Y})$.\n",
    "\n",
    "$= tr(\\Psi_\\bf{X})-$$tr(\\Psi_\\bf{Y})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62e0def-c272-4a76-969f-3ed07c53a755",
   "metadata": {},
   "source": [
    "*다시 써보기*\n",
    "\n",
    "$E||X - Y||^2 = E(XX' - X'Y - Y'X + YY')$\n",
    "\n",
    "$= E(X^2 - 2Y'X + Y^2)$\n",
    "\n",
    "$= tr(\\Psi_X) - 2 E(E(Y'X|Y)) + tr(\\Psi_Y)$ \n",
    "\n",
    "$= tr(\\Psi_X) - 2 E(Y'E(X|Y)) + tr(\\Psi_Y)$\n",
    "\n",
    "$= tr(\\Psi_X) - 2 E(Y'Y) + tr(\\Psi_Y)$\n",
    "\n",
    "$= tr(\\Psi_X) - 2tr(\\Psi_Y)  + tr(\\Psi_Y)$\n",
    "\n",
    "$= tr(\\Psi_X) - tr(\\Psi_Y)$\n",
    "\n",
    "`-` $E(Y'X) =  E(E(Y'X|Y))$ $\\to$ 전체 기댓값의 법칙"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d747f56-d4be-4641-b270-0ea825fb3659",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"전체 기댓값의 법칙 증명(이산확률변수에서)\"}\n",
    "$E(E(X|Y)) = E(X)$ 일때, \n",
    "\n",
    "$E(E(X|Y))$\n",
    "\n",
    "$= \\sum_{y \\in Y} p(y)E(X|Y)$\n",
    "\n",
    "$= \\sum_{y \\in Y} p(y) \\sum_{x \\in X} p(x|y) x$\n",
    "\n",
    "$= \\sum_{y \\in Y} \\sum_{x \\in X} p(y) p(x|y) x$\n",
    "\n",
    "$= \\sum_{y \\in Y} \\sum_{x \\in X} p(x,y) x$\n",
    "\n",
    "$= \\sum_{x \\in X} p(x) x = E(X)$\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e615e0b7-2654-4101-9184-c2d4ec4d6862",
   "metadata": {},
   "source": [
    "It follows from Lemma 2.3 that $Cov[\\bf{Y}] =$$Cov[\\bf{X}]$ exactly if $Cov[\\bf{X}|\\bf{Y}] = 0$ a.s., that is, if $\\bf{Y} = \\bf{X}$ a.s.\n",
    "\n",
    "lemma 2.3의 $Cov[\\bf{X}] = Cov[\\cal{E}$$[\\bf{X}|\\bf{Y}]]+ \\cal{E}$$[Cov[\\bf{X}|\\bf{Y}]]$ 여기서 $Cov[\\bf{X}|\\bf{Y}]$이 0이 된다면,\n",
    "\n",
    "$Cov[\\bf{X}] = Cov[\\cal{E}$$[\\bf{X}|\\bf{Y}]]$, 근데 Y가 X에 대해 self-consistent할 때 $\\cal{E}$$[\\bf{X}|\\bf{Y}] = Y$,\n",
    "\n",
    "따라서 $Cov[{X}] = Cov[Y]$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557b3641-57fd-4e48-b4da-c49ec65a04d9",
   "metadata": {},
   "source": [
    "For one-dimensional random variables $\\bf{X}$ and $\\bf{Y}$, if $\\bf{Y}$ is self-consistent for $\\bf{X}$, then $var[\\bf{Y}]$ $\\le var[\\bf{X}]$, with equality exactly if $\\bf{Y}$$=\\bf{X}$ a.s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60023c8c-f899-4c5a-8722-ff848dbf91e6",
   "metadata": {},
   "source": [
    "There is a similarity between the two preceding lemmas and the Rao{Blackwell theorem (Casella and Berger, 1990, page 316), which in a simplied version states the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb24d2d-6eb1-4e5e-8540-83dcbbb7a417",
   "metadata": {},
   "source": [
    "If $\\bf{X}$ is an unbiased estimator of a parameter $\\theta$, and if $\\bf{Y}$ is a sufcient statistic for $\\theta$, then $\\cal{E}$$[\\bf{X}|\\bf{Y}]$ is an unbiased estimator of $\\theta$, and $var[\\cal{E}$$[\\bf{X}|\\bf{Y}]$$\\le var[\\bf{X}]$. If $\\cal{E}$$[\\bf{X}|\\bf{Y}$$] = \\bf{Y}$, then Lemma 2.2 gives $\\cal{E}$$[\\bf{Y}$$] = \\cal{E}$$[\\bf{X}]$, and part (i) of Lemma 2.3 gives $var[\\bf{Y}]\\le var[\\bf{X}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6115b7fe-2095-4ab6-908e-5fb2511c4a38",
   "metadata": {},
   "source": [
    "- 1차원 확률 벡터 X,Y에 대해 Y가 X에 대해 self-consistent하다면, Y의 분산은 X의 분산보다 작거나 같다.(단, Y=X로 정확히 일치할때만??)\n",
    "\n",
    "1. 만일 X가 세타에 대한 비편향 추정량이고($E(X)=\\theta$, That is,$X=\\hat{\\theta}$,X의 기댓값이 세타와 같다면),\n",
    "2. 만일 Y가 세타에 대한 충분 통계량이라면(Y가 세타에 대한 충분한 정보가 있어서 세타를 효율적으로 표현할 수 있다면)\n",
    "\n",
    "- Y가 주어졌을때 X의 기댓값은 세타에 대한 비편향 추정량이고(Y가 주어졌을때 X의 기댓값이 세타와 같고),\n",
    "- Y가 주어졌을때 X의 기댓값의 분산은 X의 분산보다 작거나 같다. \n",
    "\n",
    "`-` 만일 Y가 주어졌을때 X의 기댓값이 Y라면(Y가 X에 대해 self-consistent 하다면)\n",
    "\n",
    "- lemma 2.2에서 X의 기댓값이 Y의 기댓값과 같다고 할 수 있고, \n",
    "- lemma 2.3에서 Y의 분산이 X의 분산보다 작거나 같다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea36f3d-8cad-4fad-87b1-1ce0e00dba6e",
   "metadata": {},
   "source": [
    "The next lemma demonstrates a dimensionality reducing property of self-consistent random variables.\n",
    "\n",
    "다음 lemma는 self-consistent 확률 변수의 차원적으로 감소하는 특징에 대해 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b27c94b-972d-4781-b7bb-9e6ee2b3fe53",
   "metadata": {},
   "source": [
    "Here, $\\cal{S}$$(\\bf{Y})$ denotes the support of $\\bf{Y}$.\n",
    "\n",
    "S(Y)는 Y의 support를 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea9da31-2568-4d6b-a75f-6a7b851f4f0c",
   "metadata": {},
   "source": [
    "> Y의 support = Y의 집합?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645f429a-6937-4344-bfd9-4a4e22c88177",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#E0CCEF\"> **Lemma 2.4.** </span> Suppose $\\bf{Y}$ is self-consistent for a $p$-variate random vector $\\bf{X}$ with $\\cal{E}$$[\\bf{X}] = 0$, and $\\cal{S}$$(\\bf{Y})$ is contained in a linear subspace spanned by $q$ orthonormal column vectors in the $p \\times q$ matrix A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7b063-4358-4010-b443-f05637ba64b0",
   "metadata": {},
   "source": [
    "p 변량 확률 벡터 X에 대해 X의 기댓값이 0일때 Y가 이 X에 대해 self-consistent 하다고 가정하면, S(Y) 는 p행 q열인 행렬 A에서 q열이 직교한 열벡터애 의해 생성된 선형 부분 공간에 포함된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92212df9-6996-46b2-b652-910d6f65c0d1",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "$\\to$ q열이 직교한다 $\\to$ q열끼리 곱하면 0이 된다. $\\to$ q열은 서로 독립이다.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e20f23-6666-48d7-878c-6b5df7791a8a",
   "metadata": {},
   "source": [
    "> 선형 공간 linear space = 벡터 공간 vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263adbc-5f6e-4d5d-b706-f556b7bd44b0",
   "metadata": {},
   "source": [
    "Let $P = AA'$ denote the associated projection matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e6c700-89ee-47fd-99c4-15dd657b429f",
   "metadata": {},
   "source": [
    "Then $\\bf{Y}$ and $\\bf{A'Y}$ are self-consistent for $\\bf{PX}$ and $\\bf{A'X}$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0eecb3-f8cf-4f53-a81d-9f14da9872c7",
   "metadata": {},
   "source": [
    "::: {.callout-tip title=\"Projection Matrix 투영행렬\"}\n",
    "투영행렬의 정의\n",
    "\n",
    "- 어떤 벡터를 다른 어떤 공간으로 투영시키는 것\n",
    "\n",
    "투영행렬의 특징\n",
    "\n",
    "- $P =P^\\top$ 대칭이고,\n",
    "- $P^2 = P$ 두 번 투영시켜도 결과는 그대로다.\n",
    "- ex) 단위행렬 $\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n",
    "- ex) 0행렬 $\\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\end{bmatrix}$\n",
    "- ex) 2차원을 1차원으로 축소하는 $P=\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$ $\\to$ 하나의 축에 투영하는 법\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c1969-6613-483e-a4a1-8fdca715edbd",
   "metadata": {},
   "source": [
    "`-` PCA로 이해해보자..$X = n \\times d$ matrix , $P = d \\times k$ matrix\n",
    "\n",
    "- $X$의 공분산 행렬 C를 이용한 고유값 분해 $C = V \\Lambda V^T$\n",
    "- 차원 축소하면 $Y = XP$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7633b3-dd2c-4fff-8f10-8d43c7599aff",
   "metadata": {},
   "source": [
    "`-` 특이값 분해로 이해해보자.. $A = U \\sum V^T$\n",
    "\n",
    "- 여기서 U,V는 직교 행렬으로 $I = U^T U$, $I = V^V V$을 만족\n",
    "    - $U = m \\times m$, $\\sum=m \\times n$, $V = n \\times n$\n",
    "    - U, V는 P 투영 행랼?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09831ad3-1b97-472f-8528-8ba76804c423",
   "metadata": {},
   "source": [
    "See the Appendix for a proof."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c00d60-7759-47e7-9bf0-445deac3574c",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#F5F05E\"> *appendix* </span>  Proof of Lemma 2.4. Since $\\bf{Y}$ is self-consistent for $\\bf{X}$, $\\cal{E}$$[\\bf{PX|Y}] = \\bf{P}\\cal{E}$$[\\bf{X|Y}] = \\bf{PY} = \\bf{Y}$ a.s. \n",
    "\n",
    "For a given $\\bf{y} \\in \\mathbb{R}^p$, let $\\bf{w = A^{'}_{1} y}$.\n",
    "\n",
    "Then $\\{ \\bf{Y} = \\bf{y} \\} = \\{A^{'}_{1} Y = w\\}$.\n",
    "\n",
    "Multiplying both sides of the equation $\\cal{E}$$[\\bf{X|Y = y] = y}$ on the left by $A^{'}_{1}$ gives $\\cal{E}$$[\\bf{A^{'}_{1} X|A^{'}_{1} Y} = w] = w$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924671ae-a66b-4451-915e-7b2aed55e5d5",
   "metadata": {},
   "source": [
    "Lemma 2.4 means that the marginal distribution of a self-consistent $\\bf{Y}$ in the linear subspace spanned by its support is self-consistent for the marginal distribution of $\\bf{X}$ in the same subspace.\n",
    "\n",
    "lemma 2.4가 의미하는 것은 그 support에 의해 생성된 선형 부분 공간에서 self-consistent한 Y의 주변 분포는 같은 부분공간에서 X의 주변 분포에 대해 self-consistent한 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ea7d1-6074-45d9-835d-9378334783fe",
   "metadata": {},
   "source": [
    "For example, a self-consistent distribution for $\\bf{X}$ whose support consists of a circle (see Section 6) is determined by the bivariate marginal distribution of $\\bf{X}$ in the subspace containing the circle.\n",
    "\n",
    "예를 들어, support가 원으로 구성된 X에 대해 self-consistent한 분포는 원을 포함한 부분 공간에서 X의 이변량 주변 분포에 의해 결정된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28e63fc-4034-4537-bc9f-c7177330a053",
   "metadata": {},
   "source": [
    "In Example 2.2, the linear subspace spanned by the support of $\\bf{Y}$ is the $x_1$-axis, the marginal distribution of $\\bf{X}$ in this subspace is standard normal, and the random variable $\\bf{Y}_1 = sgn(\\bf{X}_1)\\sqrt{2/\\pi}$ is self-consistent for $\\bf{X}_1$.\n",
    "\n",
    "예제 2.2에서 Y의 support에 의해 생성된 선형 부분 공간은 x1축이고, 부분 공간에서 X의 주변 분포는 표준정규분포이고, X1의 값에 따라 바뀌는 확률변수 Y1은 X1에 대해 self-consistent하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f272f9d-5021-4335-8c95-468bcc918500",
   "metadata": {},
   "source": [
    "::: {.callout-note title=\"Sign Function 부호 함수\"}\n",
    "기호는 **sgn**로 표현, 수의 부호 판별하는 함수\n",
    "\n",
    "example 2.2처럼 y를 x를 기준으로 나눠서 함수 쓸 때 사용할 수 있음.\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a28a6599-1ba3-478a-8ab7-502ad9705bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x 값의 범위 설정\n",
    "x = np.linspace(-5, 5, 100)\n",
    "\n",
    "# 부호 함수 정의\n",
    "def sgn(x):\n",
    "    if x > 0 :\n",
    "        y = 1\n",
    "    elif x < 0 :\n",
    "        y = -1\n",
    "    elif x == 0 :\n",
    "        y = 0\n",
    "    return y\n",
    "\n",
    "# 그래프 그리기\n",
    "plt.plot(x, [sgn(x[i]) for i in range(len(x))], label='sgn(x)')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('sgn(x)')\n",
    "plt.ylim(-1.5,1.5)\n",
    "plt.xlim(-4,4)\n",
    "plt.title('Sign Function')\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffea6251-4f44-4c01-9a48-7335f7daa52f",
   "metadata": {},
   "source": [
    "We conclude this section with a general method of finding self-consistent random variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545b016-8ce2-4376-8368-9ffad1dd0945",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#E0CCEF\"> **Lemma 2.5.** </span> Let $\\bf{X}$ and $\\bf{Y}$ denote two jointly distributed random vectors, not necessarily of the same dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41f80ca-8306-44ea-8fcf-52343a6bfc41",
   "metadata": {},
   "source": [
    "Then $\\cal{E}$$[\\bf{X}|\\bf{Y}]$ is self-consistent for $\\bf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9fb9ea-df9a-4737-b0b8-c0f6ee49b7cb",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#F5F1F8\"> **Proof.** </span> Let $\\bf{Z} = \\cal{E}$$[\\bf{X}|\\bf{Y}]$. Then $\\cal{E}$$[\\bf{X}|\\bf{Z}] = \\cal{E}[\\cal{E}$$[\\bf{X}|\\bf{Y}]|\\bf{Z}] = \\cal{E}[\\bf{Z}|\\bf{Z}] =\\bf{Z}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f96087-799f-4f87-9125-6f57b2a90474",
   "metadata": {},
   "source": [
    "In particular, setting $\\bf{Y} = \\bf{X}$ in Lemma 2.5 gives again self-consistency of $\\bf{X}$ for itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dcdef8-7b16-4ed3-90ff-a4f8a6b41174",
   "metadata": {},
   "source": [
    "If $\\bf{Y}$ is independent of $\\bf{X}$, then it follows that $\\cal{E}$$[\\bf{X}]$ is self-consistent for $\\bf{X}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb81117f-5833-4619-ab9a-338af0218878",
   "metadata": {},
   "source": [
    "X와 Y가 결합 확률 벡터일때, Y를 고려한 X의 기댓값은 X에 대해 self-consistent 하며, 특히 Y가 X와 같을 때 lemma 2.5에 나온 E(X|Y)는 X에 대해 self-consistent하다는 것에 의해 X는 자기 자신에 대해 self-consistency하다는 것을 얻을 수 있다.\n",
    "\n",
    "만약 Y가 X에 대해 독립이라면 X의 기댓값은 X에 대해 self-consistent하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4789e2-0505-4dd7-a4c2-c0b9228859ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
