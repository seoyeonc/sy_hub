{
 "cells": [
  {
   "cell_type": "raw",
   "id": "78032aae-cbe0-4cc0-b5a3-b2554eb62675",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Review: Self-Consistency: A Fundamental Concept in Statistics\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2024-02-05\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eadbfb-8e2a-4155-8e59-e98a91e00e5c",
   "metadata": {},
   "source": [
    "**Y = Observed Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94ef67d-c3bd-47c4-b0a2-4a1f2f7ee9ac",
   "metadata": {},
   "source": [
    "**X = Completed Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d792ae-946f-4432-9124-d5dd36d72e12",
   "metadata": {},
   "source": [
    "# 2. Self-Consistent Random Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae3501f-3d8d-465d-bc5f-2f8c2b4a5907",
   "metadata": {},
   "source": [
    "Suppose we want to represent or approximate the distribution of a random vector $\\bf{X}$ by a random vector $\\bf{Y}$ whose structure is less complex.\n",
    "\n",
    "구조가 간단한(?) 확률벡터 Y로 확률벡터 X의 분포를 근사하거나 나타내려 한다고 하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128de7c-bec0-4949-96bc-a1506759346b",
   "metadata": {},
   "source": [
    "One measure of how well $\\bf{Y}$ approximates $\\bf{X}$ is the mean squared error $\\cal{E}||\\bf{X}-\\bf{Y}||^2$.\n",
    "\n",
    "Y로 X의 근사값을 잘 찾는 한 측정치는 평균제곱오차를 구하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a3a45a-f194-4ef5-8b82-f76b365ce411",
   "metadata": {},
   "source": [
    "In terms of mean squarred error, the approximation of $\\bf{X}$ by $\\bf{Y}$ can always be improved using $\\cal{E} [\\bf{X}|\\bf{Y}]$ since, for any function $g$, $\\cal{E} ||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-g(\\bf{Y})||^2$.\n",
    "\n",
    "평균제곱오차에 관해 말하자면, Y에 의해 X의 근사치는 항상 Y 가 주어졌을때 X의 기대값으로 개선될 수 있는데, 어느 함수 g에 대해서나 위의 식이 성립한다.\n",
    "\n",
    "- $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ 이게 최솟값이라는 뜻"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ba3f77-77d9-4b2f-afc2-37f7f6b81ea4",
   "metadata": {},
   "source": [
    "Taking $g$ to be the identity gives $\\cal{E} || \\bf{X} - \\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-\\bf{Y}||^2$.\n",
    "\n",
    "함수 g에 Y를 주면, 위의 식이 된다.\n",
    "\n",
    "- E[X|Y] =Y일때 Y가 X에 대해 self-cosistent 하다고 헀으니까 함수 g(Y) = Y라 한다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb132a1-1f39-439b-80cf-080e3ac6a4cc",
   "metadata": {},
   "source": [
    "Thus the random vector $Y$ is locally optimal for approximating $\\bf{X}$ if $\\bf{Y} = \\cal{E} [\\bf{X}|\\bf{Y}]$, in which case we call $Y$ self-consistent for $\\bf{X}$.\n",
    "\n",
    "만일 Y가 Y가 주어졌을때 X의 기댓값과 같다면, 확률벡터 Y는 X에 근사하는데 있어 locally optimal 하다. 이때, Y를 X에 대해 self-consistent 하다고 부른다.\n",
    "\n",
    "- $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ 계산할때에 대해(locally) E(X|Y) = Y라면, 최적의 값(최소의 값, optimal)하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a98eb38-2ba4-4837-bad1-2099d81a78d6",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#CCCCFF\"> **DEFINITION 2.1.** </span> For two jointly distributed random vectors $\\bf{X}$ and $\\bf{Y}$, we say that $\\bf{Y}$ is self-consistent for $\\bf{X}$ if $\\cal{E} (\\bf{X}|\\bf{Y}) = \\bf{Y}$ almost surely.\n",
    "\n",
    "두 결합 분포된 확률벡터 X와 Y에 대해 Y가 주어졌을때 X의 기댓값이 Y와 동일하다면 Y를 X에 대해 self-consistent 하다고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e964fb31-c8f2-470d-a0b2-bd0f9292f6fb",
   "metadata": {},
   "source": [
    "`1` $\\bf{Y} = \\bf{X} + \\epsilon$ $(\\epsilon \\sim i.i.d.)$이라면, $E(X|Y) = Y$ $Y$는 $X$에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edc3995-6ebe-44da-b7c8-bd7f8c237395",
   "metadata": {},
   "source": [
    "`2` $\\bar{X} = \\frac{1}{3}(x_1+x_2+x_3)$, $\\tilde{X} = \\frac{1}{3}(\\mu +x_2+x_3)$, $E(\\bar{X}|\\tilde{X}) = \\frac{1}{3}E(x_1) + \\tilde{X} - \\frac{1}{3}\\mu \\tilde{X} = \\tilde{X}$ $\\tilde{X}$는 $\\bar{X}$에 대해 self-consistent 하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca950aef-6022-4953-bf2d-41743167b241",
   "metadata": {},
   "source": [
    "We will assume implicitly that moments exist as required.\n",
    "\n",
    "필요에 따라 이런 moment가 존재한다고 암묵적으로 가정할 것이다.\n",
    "\n",
    "- definition의 경우가 존재한다고 가정한다..?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f2929c-9ce9-4c9c-813f-ca6cebbf21d2",
   "metadata": {},
   "source": [
    "The notion of self-consistency is not vacuous, as the two extreme cases demonstrate.\n",
    "\n",
    "두 극단적인 경우에서 나타나는 듯이, self-consistency는 모호한 개념이 아니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e50f67-bd54-4e7e-bcfb-4d82f70d2ad4",
   "metadata": {},
   "source": [
    "The random vector $\\bf{X}$ is self-consistent for $\\bf{X}$ and represents no loss of information.\n",
    "\n",
    "확률 벡터 X는 X에 대해 self-consistent 하며, information의 손실이 전혀 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e370cfbb-3a0b-471a-b8d5-d5c6aaec5bb3",
   "metadata": {},
   "source": [
    "$\\bf{Y} = \\cal{E} [\\bf{X}]$ is also self-consistent for $\\bf{X}$ and represents a total loss of information except for the location of the distribution.\n",
    "\n",
    "Y=E(X)는 X에 대해 self-consistent 하며, 분포의 위치를 제외하고 information이 전체적으로 손실된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1af73dd-8877-4522-9d1f-f34763212354",
   "metadata": {},
   "source": [
    "Interesting self-consistent distributions range in between these two extremes.\n",
    "\n",
    "이 두 극단적인 경우 사이에 self-consistent 분포들이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e3792f-7f5d-4100-aa68-fa1458924c28",
   "metadata": {},
   "source": [
    "`1` $\\bf{X}$는 information 손실이 없지만, $\\bf{Y}=E(X)$는 $\\epsilon$을 잃어서 information 손실이 생긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5b7d1a-2486-463b-8b1e-8bef9d2b98da",
   "metadata": {},
   "source": [
    "`2` $\\bar{X}$는 information 손실이 없지만, $\\tilde{X} = E(\\bar{X})$는 $x_1$이 $\\mu$로 바뀌어 information 손실이 생긴다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fea488-6850-401f-b78b-8f1e6edcbcc9",
   "metadata": {},
   "source": [
    "Many relevant cases of self-consistency are obtained by taking conditional means over subsets of the sample space of $\\bf{X}$.\n",
    "\n",
    "self-consistency의 많은 관련된 경우는 집합 𝐗의 표본 공간의 부분집합에 대한 조건부 평균을 취함으로써 구해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07b4bd-2127-4aeb-8ad3-dcbc2a4c6faa",
   "metadata": {},
   "source": [
    "Another simple example of self-consistency is the following:\n",
    "\n",
    "또다른 self-consistency의 단순한 예제이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c2b98-eb10-4951-8c42-85c80b174ed5",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.1.** </span> *Partial sums.* Let $\\{X_n\\}$ denote a sequence of independent, mean-zero random variables, and let $S_n = \\sum^n_{i=1} X_i$.\n",
    "\n",
    "부분합, x_n을 독립이고, 평균이 0인 확률 변수라고 할 때, x의 합을 Sn이라 두자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a088e69-2dfc-4bfa-8c00-c82a3bb1ab86",
   "metadata": {},
   "source": [
    "Then $\\cal{E}$$[S_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] = S_n$.\n",
    "\n",
    "그러면 이 식이 성립함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0306fb59-91f8-4324-84f0-2d7bbfd0179b",
   "metadata": {},
   "source": [
    "`-` 증명 $\\cal{E}$$[S_{n+k}|S_n]=$$\\cal{E}$$[S_n + X_{n+1} + \\dots + X_{n+k}|S_n]=$$\\cal{E}$$[X_{1} + \\dots + X_n + X_{n+1} + \\dots +X_{n+k}|S_n]=$$\\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] + S_n=S_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7da5e3-2df3-432f-950f-96c51cd2de93",
   "metadata": {},
   "source": [
    "Thus, $S_n$ is self-consistent for $S_{n+k}, k > 1$.\n",
    "\n",
    "그려면 sn은 sn+k에 대해 self-consistent하다고 함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5f9b94-fa1f-4cb0-b0bb-a8fb3353fa51",
   "metadata": {},
   "source": [
    "The same property holds more generally if $\\{S_n\\}_{n\\ge1}$ represents a martingale process.\n",
    "\n",
    "만일 저 식이 마틴게일 프로세스를 나타낸다면 동일한 특성이 유지된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e32cc52-9e34-43db-b65c-6327275abf24",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "martingale process 의 특징\n",
    "\n",
    "- 기댓값의 일정성\n",
    "- 확률변수의 분포 고정\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1a4dc4-f84b-4c7c-b052-e467033ae5db",
   "metadata": {},
   "source": [
    "For a given $\\bf{X}$, a self-consistent approximation $\\bf{Y}$ can be generated by partitioning the sample space of $\\bf{X}$ and defining $\\bf{Y}$ as a random variable taking as values the conditional means, of subsets in the partition.\n",
    "\n",
    "주어진 확률 변수 $\\bf{X}$에 대한 self-consistent approximation $\\bf{Y}$는 $\\bf{X}$의 표본 공간을 분할하여 각 분할된 부분집합에 대한 조건부 평균을 값으로 가지는 랜덤 변수로 정의될 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc98ca-dba9-4f5b-be4c-8f49766a8354",
   "metadata": {},
   "source": [
    "This is illustrated by our next example, in which the support of $\\bf{X}$ is partitioned into two half-planes.\n",
    "\n",
    "다음 예제에서 확률 변수 $\\bf{X}$의 support(모든 값?)가 두 개의 반 평면으로 나뉜다.(x1>0,x1<=0인듯?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0b9171-5175-4f58-85cb-6c4ca7a72da3",
   "metadata": {},
   "source": [
    "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.2.** </span> *Two principal points.* Let $\\bf{X} = (X_1, X_2)' \\sim  N_2(0, I_2)$. Note that $\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{2/\\pi}$. Let $\\bf{Y} = (-\\sqrt{2/\\pi}, 0)'$ if $X_1 < 0$ and $\\bf{Y} = (\\sqrt{2/\\pi}, 0)'$ if $X_1 > 0$. Then $\\bf{Y}$ is self-consistent for $\\bf{X}$.\n",
    "\n",
    "$\\bf{Y} = \\begin{cases}(-\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 < 0 \\\\ (\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 \\ge 0 \\end{cases}$, $\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{\\frac{2}{\\pi}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e160676-1c74-470c-9bef-713f10a7e389",
   "metadata": {},
   "source": [
    "See Section 6 for a definition of principal points, and see Figure 7 for a generalization of this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0385748b-bddb-4fcd-9f68-7027fef0e1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f4efb6-8e08-41c6-b288-1a955074f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "<span style=\"background-color:#9966FF\"> </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff036d02-4623-4911-b16f-4652f7b997b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "<span style=\"background-color:#9966FF\"> </span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
