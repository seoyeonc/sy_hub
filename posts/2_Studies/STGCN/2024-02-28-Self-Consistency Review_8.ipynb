{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7b47b2b1-1e39-4922-9267-e5fad8d63e93",
   "metadata": {
    "id": "cac470df-29e7-4148-9bbd-d8b9a32fa570",
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"Review: Self-Consistency: A Fundamental Concept in Statistics(8)\"\n",
    "author: \"SEOYEON CHOI\"\n",
    "date: \"2024-02-29\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dd99f4-9ff4-41be-b468-6e6614f9ef3b",
   "metadata": {},
   "source": [
    "# 8. Self-consistency and the EM algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6180ad-5dce-4ba2-b3b4-d6cfb1046592",
   "metadata": {},
   "source": [
    "The term self-consistency was, to our knowledge, first used by Efron (1967) to describe a class of estimators of a distribution function $F(t)$ in the presence of censored data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a922a0-cf94-45a5-b2be-874653586ed1",
   "metadata": {},
   "source": [
    "self-consistency는 Efrom이 처음 썼고, censored data가 있을때 distribution finction의 estimator로 설명되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e376260b-fa6d-45be-808d-13a069b9b612",
   "metadata": {},
   "source": [
    "If $x_1, \\dots , x_N$ are observed data from a distribution $F$, the nonparametric maximum likelihood estimate of $F$ is $\\hat{F}(t) = \\sum_{i=1}^N I[x_i \\le t]/N$, where $I[\\dot]$ is the indicator function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310256be-886f-4e0b-a54e-834119601969",
   "metadata": {},
   "source": [
    "만약 x1-xn이 F 분포의 observed data라면, F의 비모수 최대 우도 추정량은 f hat이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c58802c-52c4-4551-9910-7efe165baa48",
   "metadata": {},
   "source": [
    "::: {.callout-note}\n",
    "Indicator Function: 조건에 맞으면 1을 반환, 아니면 0을 반환\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fa7062-6b0a-4a92-9b6f-3250edb1716b",
   "metadata": {},
   "source": [
    "For all censored observations the function $I[x_i < t]$ cannot be evaluated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2b8f8f-6150-4198-90a7-55345febaf3c",
   "metadata": {},
   "source": [
    "모든 censored 관찰값에서 I는 evaluate될 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda2b00-1b36-4837-87b3-e4cc7d92a11c",
   "metadata": {},
   "source": [
    "If $y$ denotes the observed data, including censoring times for the censored observations, and $F*$ denotes a distribution function, then $\\cal{P}$ $(x_i \\le t | y, F * ) = E(I[ x_i \\le t ] | y, F * )$ may be used to estimate $I[x_i \\le t]$ for all censored observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37ac07f-e4f5-4968-8ef8-2d3d1cb760fe",
   "metadata": {},
   "source": [
    "만약 y를 중단된 관찰값(결측값)에 대한 중단된 시간을 포함한 관찰값이라고 놓고, F * 를 distribution function 으로 보면, p=E는 *모든 censored 관찰값에 대한 추정치로 사용*될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ea2bc-a825-4b1c-bfa4-715c980b97a6",
   "metadata": {},
   "source": [
    "A distribution function $F *(t)$ is called a self-consistent estimate of the unknown distribution function $F(t)$ if $F * (t) = \\frac{1}{N} \\sum^N_{i=1} \\cal{P}$ $(x_i \\le t | y, F * )$ for all $t$ (Efron, 1967; Laird, 1988)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439164e3-5135-483d-8566-81996965e805",
   "metadata": {},
   "source": [
    "distribution function F * 는 만약 F * 가 모든 t에 대해서 조건을 만족할때, 알려지지 않은 distribution function F의 self-consistent 추정값이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71640d0-2426-4215-ad60-0263d91ef5cf",
   "metadata": {},
   "source": [
    "That is, if we substitute the estimate $F *$ in the calculation of the expected values, we obtain the same estimate $F *$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca5339-2de1-4289-a5fc-c085080bd44d",
   "metadata": {},
   "source": [
    "**즉, 만약 기댓값으로 F * 의 추정값을 대체한다면, F * 의 같은 추정치를 얻을 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc01607-91e7-41bb-9d64-6be41bdcfd0c",
   "metadata": {},
   "source": [
    "In other words, the estimate $F *$ **\"confirms itself.\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab63ac98-a87f-4959-a208-6bc5711e002a",
   "metadata": {},
   "source": [
    "다시 말해서, 추정치 F * 는 F * 스스로 confirm한다(comfirms itself)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb9b222-5e5c-45aa-8131-9e9710d4a0ce",
   "metadata": {},
   "source": [
    "- 기댓값으로 자기 자신의 값을 구할 수 있다는 말인듯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89af7175-d924-4703-a99d-1f5b3d47db3f",
   "metadata": {},
   "source": [
    "In an iterative algorithm $F *$ corresponds to a fixed point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fd0def-8634-4f82-b444-42d1268e409d",
   "metadata": {},
   "source": [
    "반복적인 알고리즘 F * 는 고정적인 점이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d7d86-5fa4-45e5-be5a-605cb99b0cd7",
   "metadata": {},
   "source": [
    "- 알려진 않은 값+ 알려지지 않은 값 = 이 분포를 추정하려 할때, 알려진 값을 고정 점으로 보고...기댓값 구할 수 있다는 말로 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af5141-15d6-4b48-bc52-9aa32f8d7b61",
   "metadata": {},
   "source": [
    "This parallels the interpretation of self-consistent points in a k-means algorithm; see Section 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1871e7b7-87ef-4c18-8609-479c70984841",
   "metadata": {},
   "source": [
    "The expectation-maximization (EM) algorithm (Dempster, Laird and Rubin, 1967; Little and Rubin, 1987) is an iterative procedure for maximizing the log-likelihood in the presence of missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2365df37-431c-450f-a297-9aae8a0a8df7",
   "metadata": {},
   "source": [
    "EM 알고리즘은 결측값이 존재할때 로그 우도를 최대화하는 반복적인 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24b2b2c-dfc9-4c00-bc4f-1d13e77181d2",
   "metadata": {},
   "source": [
    "Suppose we have a model for complete data $X$, with density $f(x, \\theta)$ indexed by an unknown parameter $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578ba81-3757-4688-bed9-10747665d96b",
   "metadata": {},
   "source": [
    "complete data X에 대한 알려지지 않은 파라메터 theta에 의해 index된 density f가 있는 model을 가지고 있다고 가정해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc0537-1759-48db-83ce-13f1924d1d6b",
   "metadata": {},
   "source": [
    "- 결측값 인덱스에는 값이 없고, 값이 있는 인덱스에는 값이 있는"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4828eb8a-156c-4169-bd8e-b664f712aef0",
   "metadata": {},
   "source": [
    "Write $X = (X_{obs}, X_{mis})$, where $X_{obs}$ represents the observed part of the data, and $X_{mis}$ the missing part."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5129f36-bd30-4434-8fba-92bf2e40b650",
   "metadata": {},
   "source": [
    "xobs는 관찰된 부분의 데이터이고, xmis는 결측값 부분의 데이터이다. x는 xobs, xmis로 이뤄져 있다고 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6183bd38-ac18-4b72-a809-387ad7dbffc9",
   "metadata": {},
   "source": [
    "Let $l(\\theta |X)$ denote the complete data log-likelihood, and let $\\theta^{(t)}$ denote the current value of the parameter estimate in iteration $t$ of the EM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533c7eb-c396-465f-bd2d-a095cf49c195",
   "metadata": {},
   "source": [
    "l(theta)를 complete데이터의 로그우도로 보고, theta의 t제곱을 EM알고리즘의 반복을 의미하는 t의 모수 추정치의 현재값으로 정의하자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf2e9d-2006-4cee-b937-0922585d7382",
   "metadata": {},
   "source": [
    "- EMEMEM 그 반복의 t 번째\n",
    "- t 번 업데이트하는 거랑 EM알고리즘의 EM반복이랑 동일하게 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bd4ab-c5c7-4eb2-b341-1a6fa2ee0dc8",
   "metadata": {},
   "source": [
    "Each iteration of the EM algorithm consists of an E (expectation) step and an M (maximization) step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177199c-c2d1-4268-9d90-89bb926d64ba",
   "metadata": {},
   "source": [
    "EM 알고리즘의 각 반복은 기댓값 E 단계와 최댓값 M 단계로 이루어져 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3472518f-fecf-4caa-b679-893ecc6e127c",
   "metadata": {},
   "source": [
    "The E step corresponds to taking the expectation of the complete data log-likelihood, given the observed data $X_{obs}$, and using the current value $\\theta^{(t)}$ of the parameter estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fad4e61-d0ff-49db-9d1b-8ad0440d5bc2",
   "metadata": {},
   "source": [
    "E 단계는 xobs 값이 주어졌을때, 모수 추정치의 t번 반복하여 얻은 theta를 사용하여 complete 데이터 로그 우도값의 기댓값을 가진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4dd353-280b-46e6-b2a0-79449c4caf26",
   "metadata": {},
   "source": [
    "That is, the E step computes $Q(\\theta, \\theta^{(t)} ) = E[l(\\theta ; X) |X_{obs} , \\theta^{(t)} ]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c884cc68-fc16-45cc-a854-c4f44f042714",
   "metadata": {},
   "source": [
    "즉, E 단계는 Q를 얻게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9e748-b6e9-4819-84bb-077b04d0c457",
   "metadata": {},
   "source": [
    "The M step then finds $\\theta^{(t+1)}$ which maximizes $Q(\\theta, \\theta^{(t)})$ over all $\\theta$ in the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a6a9d6-3935-4d29-86a2-01f0bd94df61",
   "metadata": {},
   "source": [
    "M 단계는 모수 공간에서 모든 theta에 걸쳐 Q함수를 최대화하는 theta의 t+1번째 반복값을 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453780ae-e762-4659-a11d-1c0406849682",
   "metadata": {},
   "source": [
    "Convergence is reached if $\\theta^{(t+1)} = \\theta^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1102fcc-18ee-4805-aa9b-17441bddcc35",
   "metadata": {},
   "source": [
    "theta의 t+1번째 반복값이 theta의 t번째 반복값과 같게 된다면 수렴의 공간에 도달한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8280c-9af6-4e47-8497-4a0d397c0563",
   "metadata": {},
   "source": [
    "Thus the final estimate, denoted by $\\hat{\\theta}$, is again a fixed point of the algorithm, and the estimate $\\hat{\\theta}$ **\"confirms itself\"** in any further iteration of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc63bd-a318-458a-9fd1-316991b17515",
   "metadata": {},
   "source": [
    "그러므로 theta_hat의 마지막 추정치(마지막 반복값)는 다시 알고리즘의 fixed point가 된다. 그리고 그 추정치 theta_hat은 어느 반복 알고리즘에서 confirms itself 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98be085-0829-4edf-ba82-5d0950aeff41",
   "metadata": {},
   "source": [
    "The EM algorithm has been shown to converge under general conditions to a maximum of the likelihood function based on the observed data $X_{obs}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87b85c-1867-42e8-bc94-7ae453679881",
   "metadata": {},
   "source": [
    "이 EM 알고리즘은 관찰값 xobs를 기반으로 우도 함수의 최대화를 위한 일반적인 조건 아래 수렴하는 것으로 보여져 왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec6c7c-d252-48cf-8988-95805ed4b306",
   "metadata": {},
   "source": [
    "Since an iteration of the EM algorithm can never decrease the log-likelihood, Cox and Oakes (1984, page 171) define the self-consistency condition for the maximum likelihood estimator $\\hat{\\theta}$ as $Q(\\theta , \\hat{\\theta} ) \\le Q ( \\hat{\\theta} , \\hat{\\theta})$ for all $\\theta$ in the parameter space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d93e59e-23d3-4588-ad77-d4103970eea6",
   "metadata": {},
   "source": [
    "EM알고리즘의 iteration은 절대 로그우도를 감소시킬 수 없기 때문에 cox,oakes는 모수 공간에서 모든 theta에 대하여 위 식에 따라 최대 우도 추정치 theta_hat에 대한 self-consistency 조건을 정의했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca7d7e9-2bb2-4074-bf54-b31c631f7fb4",
   "metadata": {},
   "source": [
    "- Em 알고리즘이 로그 우도를 최대화 하여 최적의 expectation값을 구한다는 조건을 이용해서 모수를 넣은 Q값보다 추정치를 넣은 Q가 크거나 작다면 self-consistency를 만족한다고 정의한듯!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fabf48-5365-488d-be9b-9434a394f8a5",
   "metadata": {},
   "source": [
    "If the density of the complete data X is from the exponential family, **we can establish a direct connection between our notion of self-consistency and the notion of a self-consistent estimator just explained.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b2e62-01c1-4539-9117-f3d44c50d42e",
   "metadata": {},
   "source": [
    "만약 complete data x의 밀도가 exponential family지수족에서 온다면, self-consistency의 정의와 self-consistent 추정치의 정의 간 직접적인 연결성이 설명 될 수 있다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374054b4-87cb-403f-8c73-0585a0873368",
   "metadata": {},
   "source": [
    "Suppose $X$ has a density of the form $f(X; \\theta) =b(X) exp [ \\theta ' s(X)] /a(\\theta)$, where $\\theta \\in \\mathbb{R}^d$ is a parameter vector, $s(X)$ is a d-vector of complete-data sufficient statistics, and a and b are functions of $\\theta$ and $X$, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7790a2-5c9b-4172-9e2c-ec1e0f237125",
   "metadata": {},
   "source": [
    "theta가 d차원의 실수에 속하는 파라메터 벡터이고, s(x)는 complete 데이터 충분 통계량의 d-벡터이고, a,b 함수는 각각 theta, X의 함수인 함수 f의 density를 X가 가지고 있다고 가정해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074cf284-158a-48a9-b0a1-356ec00eba48",
   "metadata": {},
   "source": [
    "Then the E step simplifies to $s^{(t)} = E[s(X) | X_{obs} , \\theta^{(t)}]$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaf9bed-c7e0-468f-8b1c-220b75c38948",
   "metadata": {},
   "source": [
    "그러면 E 단계가 단순화 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eeafdd-a79a-4b35-997b-16fa73f1ce90",
   "metadata": {},
   "source": [
    "By Lemma 2.5, $s^{(t)}$ is self-consistent for $s(X)$, that is, $\\cal{E}$ $[s(X)| s^{(t)}] = s^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12dd2a-fcf4-49f3-af43-c56f9e46e52c",
   "metadata": {},
   "source": [
    "lemma 2.5에 의하면, s(t)는 s(X)에 대해 self-consistent하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75a20e5-f11b-4fd2-96b7-1f3e3be54c87",
   "metadata": {},
   "source": [
    "> LEMMA 2.5. Let $X$ and $Y$ denote two jointly distributed random vectors, not necessarily of the same dimension. Then $\\cal{E}$ $[X|Y]$ is self-consistent for $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2e9efe-38fa-464f-8656-33603ab1574a",
   "metadata": {},
   "source": [
    "The M step determines the updated estimate $\\theta^{(t+1)}$ as the solution of the equation $E[s(X); \\theta] = s^{(t)}$, based on which the next conditional expectation is taken."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a6942-b0d9-40af-9720-bd80bc48ac55",
   "metadata": {},
   "source": [
    "M 단계는 다음 조건부 기댓값을 적용하기 위한 equation의 solution으로 업데이트된 theta 값을 결정한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55292aa3-127e-4279-bf42-223944a69b1c",
   "metadata": {},
   "source": [
    "Convergence is reached when the sequence $\\{ s^{(t)} \\}_{t \\ge 1}$ of self-consistent random variables has stabilized, that is, $s^{(t+l)} = s^{(t)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d55d80-85d8-41aa-b1f2-7e00592b8f43",
   "metadata": {},
   "source": [
    "self-consistent 확률 변수 순열 s(t)이 업데이트 해도 변화가 거의 없는 안정화stablize 상태가 되었을때, 즉 s(t+1) = s(t)가 되었을때 수렴했다고 말한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7bed584-4a72-4715-93fc-fb67c9cb6418",
   "metadata": {},
   "source": [
    "**Thus the EM algorithm generates a sequence of self-consistent random variables for a sufficient statistic $s(X)$, and the maximum likelihood estimator, which corresponds to a stationary point in the sequence, satisfies the self-consistency condition as defined in Cox and Oakes(1984).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a532e4-070a-412e-b9ed-462551faeee3",
   "metadata": {},
   "source": [
    "그러면 EM 알고리즘은 충분 통계량 s(x)에 대한 self-consistent 확률 변수의 순열로 일반화되고, 순열에서 stationary point와 상응하는 최대 우도 추정치는 self-consistency 조건을 만족한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4d907-b15a-49d7-adf7-3f8aff3f9651",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c26e7-9bd8-41ee-9d4e-4e2895c03630",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
