[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog was generated to manage my blogs.\nThere are two purposes for achieving something here.\n\nFirst\nI will get definitions of any subjects and organize that in my words.\nIt is important to understand those information if I want to research exactly and improve myself.\n\n\nSecond\nI will brief my past and present researches.\nOverall, this blog will be the essential step for developing my skills."
  },
  {
    "objectID": "1_note.html",
    "href": "1_note.html",
    "title": "Note",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 31, 2023\n\n\n[Note] Tips of Linux, Git and Blog\n\n\nSEOYEON CHOI\n\n\n\n\nNov 22, 2023\n\n\n[Note] DGX station 설정_메모 추가\n\n\nGUEBIN CHOI\n\n\n\n\nSep 20, 2023\n\n\n[IT-STGCN]논문리비전_수정\n\n\nSEOYEON CHOI\n\n\n\n\nAug 25, 2023\n\n\n[ggplot3]With Non tidy Data\n\n\nSEOYEON CHOI\n\n\n\n\nAug 10, 2023\n\n\n[ggplot3]Original\n\n\n신록예찬 \n\n\n\n\nDec 31, 2022\n\n\nStudy for Spaces\n\n\nSEOYEON CHOI\n\n\n\n\nApr 4, 2022\n\n\nIntroduction to Python 5wk\n\n\nSEOYEON CHOI\n\n\n\n\nMar 23, 2022\n\n\nIntroduction to Python 4wk\n\n\nSEOYEON CHOI\n\n\n\n\nApr 26, 2019\n\n\n[Essays] 퓨리에 변환\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Lectures_ing",
      "**Note**"
    ]
  },
  {
    "objectID": "3_hcam.html",
    "href": "3_hcam.html",
    "title": "HCAM",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nOct 27, 2023\n\n\n[HCAM]Study\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\n[CAM]Other Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2023\n\n\n[CAM]Image Download\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\n[CAM]Original CAM\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Lectures_ing",
      "**Researches**",
      "HCAM"
    ]
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "",
    "text": "MIG = Multi Instance GPU\ngi = GPU Instance \\(\\rightarrow\\) 가상의 GPU\nnvidia-smi mig \\(\\rightarrow\\) 도움말 보기"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-mig-모드-enable",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-mig-모드-enable",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "A. MIG 모드 enable",
    "text": "A. MIG 모드 enable\n- root 획득\nsudo -i \n\\(\\rightarrow\\) 관리자 권한 획득\n- 모든 GPU enable\nnvidia-smi -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot\nnvidia-smi -mig 1 \n\\(\\rightarrow\\) 여기서 1은 모든 GPU를 의미하는 듯? 즉, 모든 GPU를 mig 모드로 하겠다는 뜻\n\\(\\rightarrow\\) mig 모드 해서 GPU를 나누지 않아도 사용하기 때문에, mig 모드 다 해놔도 괜찮~\n- 모든 특정 GPU만 enable\n#nvidia-smi -i {GPUdev-ID} -mig 1\nnvidia-smi -i 0 -mig 1 \nsudo systemctl stop nvidia-mig-manager.service\nsudo systemctl disable nvidia-mig-manager.service\nreboot \n\\(\\rightarrow\\) 왜인진 모르지만.. 위 sudo~ 를 실행해주어야 함..\n- GPU가 MIG 모드로 되면 아래와 같이 GPU-Util 에 N/A로 표시된다. 아래는 0,1,2,4 에 대응하는 GPU가 MIG모드로 설정된 상태임\n\n\n\nScreenshot 2023-11-22 at 23.55.06.png\n\n\n\\(\\rightarrow\\) 여기에 0,1,2,4의 GPU가 있고, 3은 아님. GPU를 gi로 나누면 MIG deviced에 나타남.\n\\(\\rightarrow\\) 단, 나중에 이 4의 GPU는 3으로 보고 gi 만들어야 함."
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-gpu-gi-ci-확인",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-gpu-gi-ci-확인",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "B. GPU, GI, CI 확인",
    "text": "B. GPU, GI, CI 확인\n- 용어정리\n\nGPU: 말 그대로 GPU\nGI: GPU INSTANCE, 하나의 GPU에 여러개의 GPU INSTANCE가 존재할 수 있음.\nCI: COMPUTE INSTANCE, 하나의 GPU INSTANCE에 여러개의 COMPUTE INSTANCE를 만들 수 있음.\n\n- 상황확인\nnvidia-smi \n\n\n\nScreenshot 2023-11-22 at 23.53.41.png\n\n\n- GPU의 해석\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA A100-SXM...  On   | 00000000:01:00.0 Off |                   On |\n| N/A   37C    P0    53W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA A100-SXM...  On   | 00000000:47:00.0 Off |                   On |\n| N/A   38C    P0    52W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   2  NVIDIA A100-SXM...  On   | 00000000:81:00.0 Off |                   On |\n| N/A   37C    P0    54W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n|   3  NVIDIA DGX Display  On   | 00000000:C1:00.0 Off |                  N/A |\n| 36%   39C    P8    N/A /  50W |      1MiB /  3911MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   4  NVIDIA A100-SXM...  On   | 00000000:C2:00.0 Off |                   On |\n| N/A   37C    P0    55W / 275W |      0MiB / 81251MiB |     N/A      Default |\n|                               |                      |              Enabled |\n+-------------------------------+----------------------+----------------------+\n총 4개의 GPU가 있으며 아이디는 0,1,2,4 임을 알 수 있다.\n- GPUdev-ID, GI-ID, CI-ID, MIGdev-ID 확인\n+-----------------------------------------------------------------------------+\n| MIG devices:                                                                |\n+------------------+----------------------+-----------+-----------------------+\n| GPU  GI  CI  MIG |         Memory-Usage |        Vol|         Shared        |\n|      ID  ID  Dev |           BAR1-Usage | SM     Unc| CE  ENC  DEC  OFA  JPG|\n|                  |                      |        ECC|                       |\n|==================+======================+===========+=======================|\n|  1    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n|  2    0   0   0  |      0MiB / 81251MiB | 98      0 |  7   0    5    1    1 |\n|                  |      1MiB / 13107... |           |                       |\n+------------------+----------------------+-----------+-----------------------+\n아래와 같은 상황을 유추할 수 있다.\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n\n- 생성가능한 gi 확인\n\n\n\nScreenshot 2023-11-22 at 23.56.00.png\n\n\n- 생성가능한 ci 확인\n\n\n\nScreenshot 2023-11-22 at 23.56.31.png\n\n\n\\(\\rightarrow\\) cgi = create GPU Instance\n\\(\\rightarrow\\) lgip = list of GPU Instance Profiles"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#c.-gi-생성",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#c.-gi-생성",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "C. GI 생성",
    "text": "C. GI 생성\n- GPUdev = 4 에서 생성가능한 GI 조회\n#nvidia-smi mig -i {GPUdev-ID} -lgip\nnvidia-smi mig -i 4 -lgip\n\n\n\nScreenshot 2023-11-22 at 23.57.01.png\n\n\n- 아래에 해당하는 GI를 2개 생성하고 싶다고 하자. (GPU-INSTANCE-PROFILE-ID=9 임을 유의)\n+-----------------------------------------------------------------------------+\n| GPU instance profiles:                                                      |\n| GPU   Name             ID    Instances   Memory     P2P    SM    DEC   ENC  |\n|                              Free/Total   GiB              CE    JPEG  OFA  |\n|=============================================================================|\n|   4  MIG 3g.40gb        9     0/2        39.50      No     42     2     0   |\n|                                                             3     0     0   |\n+-----------------------------------------------------------------------------+\n#nvidia-smi mig -i {GPUdev-ID} -cgi {GPU-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -cgi 9 \nnvidia-smi mig -i 4 -cgi 9 \n\n\n\nScreenshot 2023-11-22 at 23.57.29.png\n\n\n\n2개까지는 잘 만들어지고 그 이후에는 리소스부족으로 에러발생\n\n- 만들어진 GI 확인\n\n\n\nScreenshot 2023-11-22 at 23.57.49.png\n\n\n- 생성가능한 CI 확인\nnvidia-smi mig -lcip\n\nNote: {GPU ID: GPU INSTANCE ID} 의 조합에서 {1:0}, {2:0}, {4:1}, {4:2}에 해당하는 GI에서 생성가능한 CI들이 각각 출력된다. 4번 GPU의 GI들은 40기가가 한계이므로 생성가능 CI목록이 상대적으로 제한적임을 캐치하라\n\n\n\n\nScreenshot 2023-11-22 at 23.58.10.png"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#d.-ci-생성",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#d.-ci-생성",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "D. CI 생성",
    "text": "D. CI 생성\n- GPUdev=4 에서 생성가능한 CI 조회\n#nvidia-smi mig -i {GPU ID} -lcip\nnvidia-smi mig -i 4 -lcip\n\nNote: 각 GPU-인스턴스(GI)에서는 3개 계산-인스턴스(CI)를 만들수 있음. 만약에 Profile ID = 0 으로 만든다면 14의 계산능력을 가진 CI를 3개까지 만들수 있음, 만약 Profile ID = 2* 로 만든다면 42개의 계산능력을 가진 CI를 1개만 만들 수 있음\n\n\n\n\nScreenshot 2023-11-22 at 23.59.01.png\n\n\n- {GPUdev-ID:GI-ID} = {4:1} 에서 COMPUTE-INSTANCE-PROFILE-ID=0 에 해당하는 CI를 3개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 1 -cci 0\n\nNote: 자원부족으로 3개까지 밖에 못만든다..\n\n\n\n\nScreenshot 2023-11-22 at 23.59.39.png\n\n\n- {GPUdev-ID:GI-ID}={4:2} 에서 COMPUTE-INSTANCE-PROFILE-ID=2 에 해당하는 CI를 1개 생성\n#nvidia-smi mig -i {GPUdev-ID} -gi {GI-ID} -cci {COMPUTE-INSTANCE-PROFILE-ID}\nnvidia-smi mig -i 4 -gi 2 -cci 2 \n\nNote: 자원이 부족해서 1개밖에 못 만든다.\n\n\n\n\nScreenshot 2023-11-23 at 00.00.18.png\n\n\n- 현재 상황\n\n\n\nScreenshot 2023-11-23 at 00.01.04.png\n\n\n\n\n\nGPUdev ID\nGI ID\nCI ID\nMIGdev ID\n\n\n\n\n1\n0 (80G)\n0 (98SM)\n0\n\n\n2\n0 (80G)\n0 (98SM)\n0\n\n\n4\n1 (80G)\n0 (14SM)\n0\n\n\n4\n1 (80G)\n1 (14SM)\n1\n\n\n4\n1 (80G)\n2 (14SM)\n2\n\n\n4\n2 (80G)\n0 (42SM)\n3"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-컨테이너-생성",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-컨테이너-생성",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "A. 컨테이너 생성",
    "text": "A. 컨테이너 생성\n- 아래와 같은 방식으로 컨테이너 생성\n# nvidia-docker run --gpus '\"device={GPUdev-ID}:{MIGdev-ID}\"' -ti --rm -d -t -p {HOST-PORT}:{CONTAINER-PORT} {DOCKER-IMAGE-NAME} /bin/bash\nnvidia-docker run --gpus '\"device=1:0\"' -ti --rm -d -t -p 7749:7749  -p 1307:1307 ubuntu /bin/bash\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p 4653:4653  -p 1212:1212 -p 1213:1213 -p 1214:1214 ubuntu /bin/bash\n\n-ti: 컨테이너를 대화형(interactive) 모드로 실행. 이 모드에서 컨테이너와 상호작용할 수 있음.\n--rm: 컨테이너가 종료되면 자동으로 컨테이너를 삭제. 이 옵션을 사용하면 컨테이너를 실행한 후 자동으로 정리.\n-d: 컨테이너를 백그라운드(background) 모드로 실행. 이 옵션을 사용하면 컨테이너가 백그라운드에서 실행되며 터미널이 차지되지 않음.\n-t: 컨테이너에 tty (터미널)를 할당. 이것은 대화형 모드와 함께 사용.\n/bin/bash: 컨테이너가 시작될 때 실행할 명령어. 이 경우, Bash 셸을 실행.\n\ndocker start\\(\\rightarrow\\) DOCKER 시작\ndocker ps\\(\\rightarrow\\) 실행중인 DOCKER container list, ps = process status\ndocker ps -a\\(\\rightarrow\\) 실행중인 DOCKER container list + stop된 container까지 모두\ndocker image ls\\(\\rightarrow\\) 다운로드한 이미지 목록\nnvidia-docker run --gpus '\"device=2:0\"' -ti -d -t -p 4653:4653  -p 1212:1212 ubuntu /bin/bash\n\\(\\rightarrow\\) gpus 플래그라고 하는데 잘 모르겠음..\n\\(\\rightarrow\\) device에서 2번 ID의 0번 gi를 의미함"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-컨테이너-실행",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-컨테이너-실행",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "B. 컨테이너 실행",
    "text": "B. 컨테이너 실행\ndocker exec -ti {CONTAINER-ID} bash\n\n여기에서 {CONTAINER-ID}는 docker ps 혹은 docker ps -a로 확인한다."
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-passwd",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#a.-passwd",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "A. passwd",
    "text": "A. passwd\n- 아래를 실행하여 비밀번호를 바꿀것\npasswd root"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-update",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#b.-update",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "B. update",
    "text": "B. update\n- 아래를 실행\napt update \napt install gcc\napt install build-essential\n업데이트 해야 vim 설치 되더라구"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#c.-쓸만한-패키지-설치",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#c.-쓸만한-패키지-설치",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "C. 쓸만한 패키지 설치",
    "text": "C. 쓸만한 패키지 설치\n- 아래를 설치하면 좋음..\napt install vim \napt install openssh-server\napt install git"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#d.-ssh",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#d.-ssh",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "D. ssh",
    "text": "D. ssh\n# apt install openssh-server\nvi /etc/ssh/sshd_config \nPort {My-SSH-Port}\nPermitRootLogin yes\nPasswordAuthentication yes\nservice ssh restart\nvi는 에디터임, i누르면 수정하는 거고 esc누르면 나옴.\nshift + ;로 : 만들면 text 작성 칸 나오는데, q하면 나오기 wq하면 저장하고 나오기 q!하면 강제 종료하기 임\n수정하고 그냥 q하려하면 안 나와진다."
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#e.-anaconda",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#e.-anaconda",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "E. anaconda",
    "text": "E. anaconda\n- 여기참고.."
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#f.-vscode",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#f.-vscode",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "F. vscode",
    "text": "F. vscode\n- 아래를 이용하여 설치\ncurl -Lk 'https://code.visualstudio.com/sha/download?build=stable&os=cli-alpine-x64' --output vscode_cli.tar.gz\ntar -xf vscode_cli.tar.gz\n- 아래를 이용하여 초기 설정 (깃헙아이디로 인증)\n./code tunnel \n- 초기설정 이후 아래를 이용하여 백그라운드에서 실행\nnohup ./code tunnel &"
  },
  {
    "objectID": "posts/1_Note/2023-11-22-DGX staion.out.html#g.-jupyter",
    "href": "posts/1_Note/2023-11-22-DGX staion.out.html#g.-jupyter",
    "title": "[Note] DGX station 설정_메모 추가",
    "section": "G. Jupyter",
    "text": "G. Jupyter\n- 암호설정: 여기로..\n- 주피터 실행할때 아래로 실행\njupyter lab --ip=\"0.0.0.0\" --port={MY-PORT} --no-browser --allow-root"
  },
  {
    "objectID": "posts/1_Note/2023-09-20-논문리비전_수정.out.html",
    "href": "posts/1_Note/2023-09-20-논문리비전_수정.out.html",
    "title": "[IT-STGCN]논문리비전_수정",
    "section": "",
    "text": "1. intro\n- 초록색은 나쁘지 않음. 하지만 아래의 내용을 보완하는게 좋음.\n\n분야의 예시로 신경과학, 환경데이터, 교통자료가 있는데 우리가 실제로 분석한 자료들이 사용된 논문을 찾아보며 예시를 들것 (Chickenpox, …) 사용하지 않더라도 예시를 들것.\n이러한 자료를 분석하는것이 왜 어려운지 설명할 것. 즉 단순히 시계열로 해석하거나 공간자료로 해석하면 어떠한 문제가 있는지 간단히 서술할 것. (1~2문장) 레퍼런스 찾을것. (torch_geometric_temporal 의 도입부분 활용)\n\n기존\nIn recent years, the field of spatiotemporal datasets has emerged, enabling the simultaneous con- sideration of both the time and space dimensions. The examples include neuroscience(Atluri et al., 2016), environmental data(Thompson et al., 2014), traffic dynamics(Castro et al., 2013), and more. Specifically, traffic dynamics is a prevalent spatiotemporal dataset and is crucial because examining traffic data from both spatial and temporal perspectives can lead to advancements in traffic control. The incorporation of both spatial and temporal aspects enables a comprehensive understanding of complex phenomena, making spatiotemporal datasets invaluable for various applications and en- hancing the accuracy of predictive models.\n참고\nPyTorch Geometric Temporal: Spatiotemporal Signal Processing with Neural Machine Learning Models\n\nAt the same time the existing geometric deep learning frameworks operate on graphs which have a fixed topology and it is also assumed that the node features and labels are static. Besides limiting assumptions about the input data, these off-the-shelf libraries are not designed to operate on spatiotemporal data.\n\nSpatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting\n\nClassic statistical and machine learning models are two major representatives of data-driven methods. In time- series analysis, autoregressive integrated moving average (ARIMA) and its variants are one of the most consolidated approaches based on classical statistics [Ahmed and Cook, 1979; Williams and Hoel, 2003]. However, this type of model is limited by the stationary assumption of time sequences and fails to take the spatio-temporal correlation into account. Therefore, these approaches have constrained representabil- ity of highly nonlinear traffic flow. Recently, classic statistical models have been vigorously challenged by machine learning methods on traffic prediction tasks.\nDue to the high nonlinearity and complexity of traffic flow, tradi- tional methods cannot satisfy the requirements of mid-and-long term prediction tasks and often ne- glect spatial and temporal dependencies.\n\n수정\nIn recent years, the field of spatiotemporal datasets has emerged, enabling the simultaneous consider- ation of both the time and space dimensions. The examples include health data(Rozemberczki et al., 2021b), customer data(Rozemberczki et al., 2021a), energy data(Rozemberczki et al., 2021a), neu- roscience(Atluri et al., 2016), environmental data(Thompson et al., 2014), traffic dynamics(Castro et al., 2013), and more. Specifically, traffic dynamics is a prevalent spatiotemporal dataset and is crucial because examining traffic data from both spatial and temporal perspectives can lead to ad- vancements in traffic control. Classic time-series statistical methods to analyze those kind of data already exist, but they are limited by certain conditions, such as assumptions about the data. Specif- ically, these classic methods cannot account for spatiotemporal correlations and are not designed to work with spatiotemporal data(Yu et al., 2017; Rozemberczki et al., 2021a). In result, when we analize spatiotemporal data to use enough information, we can improve accuracy during us- ing appropriate geometric deep learning frameworks.\n\n- 붉은부분\n\n의도는 좋으나 sparse data 는 올바르지 않은 표현임. missing, irregulary observed data 등으로 설명할 것.\n이러한 자료가 왜 발생하는지 설명할 것. (이부분은 레퍼런스 필요) 이러한 자료를 처리하는 것이 어려운 이유를 설명할 것.[1]\n우리의 아이디어는 “호모지니우스하지 않은 그래프 -&gt; 호모지니우스화 시킴” 인데 이러한 방식은 이상한방식이 아님. Yu et al. (2017) and Guo et al. (2019) Bai et al. (2020), Li et al. (2019), Zhao et al. (2019) 이 우리와 비슷한 연구를 했음.\n\n-기존\nHowever, when dealing with spatiotemporal datasets, sparse data is a common occurrence, which is unpredictable. For example, the sensor data from machines representing a spatiotemporal dataset may contain missing values due to unexpected events like sensor malfunction or temporal factors such as distance or time delay. It is a simple way to use interpolation methods like linear, nearest, etc. However, these methods can occasionally be imprecise in producing estimates. Moreover, in a method of learning spatiotemporal data Yu et al. (2017) and Guo et al. (2019) try to learn data after making it to be complete, i.e., allocate to other values from missing data with linear interpolation. Graph Convolution Network(GCN) is also a needed interpolation method before learning. Furthermore, Bai et al. (2020), Li et al. (2019), Zhao et al. (2019) tried to fill missing values by linear interpolation.\n- 참고\nTraffic Speed Prediction with Missing Data based on TGCN\n\nIn addition, there usually contains missing values in the collected data of traffic sensors due to the electronics unit failure. As is shown in Fig.1, There exist a lot of missing values during 22:00-24:00. This can decrease the prediction accuracy of aforementioned prediction models.\nFor the proposed model, if the input time series contains missing values, the model will produce failure because of the missing values can not be computed during the training process.\n\nMissing Data: Our View of the State of the Ar\n\nWhy do missing data create such difficulty in scientific research? Because most data analysis procedures were not designed for them. Missingness is usually a nuisance, not the main focus of inquiry, but handling it in a principled manner raises conceptual difficulties and computational challenges\n\nLSTM-based traffic flow prediction with missing data\n\nNevertheless, due to missing data, irregular sampling, and varying length, the data remain difficult to explore with high efficiency. In a traffic environment, this problem becomes even worse because the traffic sensors are often controlled manually.\n\nGraph neural networks: A review of methods and applications\n\nHomogeneous/Heterogeneous Graphs. Nodes and edges in ho- mogeneous graphs have same types, while nodes and edges have different types in heterogeneous graphs. Types for nodes and edges play important roles in heterogeneous graphs and should be further considered.\n\nT-GCN: A Temporal Graph Convolutional Network for Traffic Prediction\n\nSince the Los-loop dataset contained some missing data, we used the linear interpolation method to fill missing values.\n\nSpatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting\n\nThe linear interpolation method is used to fill missing values after data cleaning. In addition, data input are normalized by Z-Score method.\n\nAdaptive Graph Convolutional Recurrent Network for Traffic Forecasting\n\nData Preprocess: The missing values in the datasets are filled by linear interpolation. Then, both datasets are aggregated into 5-minute windows, resulting in 288 data points per day.\n\n- 수정\nDealing with spatiotemporal datasets often presents a common challenge, which is the frequent occurrence of irregularly observed data. For instance, as highlighted by (Ge et al., 2019), traffic sensor data commonly suffers from missing observations due to electronic unit failures, which can significantly impact prediction accuracy. The difficulty in handling irregular data arises for several reasons. First, many traditional data analysis procedures were designed for datasets with complete observations Schafer & Graham (2002). Second, when dealing with time-series datasets containing missing data, attempting to learn from such data can lead to challenges as it may result in the failure to capture certain time points Ge et al. (2019); Tian et al. (2018). That’s the reason why it’s important to transform incomplete data into complete data before conducting any learning or analysis.\nBefore move on to introduce our purpose, we need a definition of graph signal. To describe the geometric structures of data domain, graphs are well known as generic data representation forms(Shuman et al., 2013). So in this paper, we interpret data as Gt = (Vt,Et), V means ver- tics and E means edges. On specific Gt, it has a finite collection of samples and we call it as a graph signal(Shuman et al., 2013). Now, we would like to show the purpose of this paper that is mak- ing complete data when we approach the irregularly data. To satisfy this condition, we recognize the data not the heterogeneous graph, but the homogeneous graph by interpolation. Homogeneous graphs have same types of nodes and edges, and hetero geneous graphs have different types of them(Zhou et al., 2020). In a method of learning spatiotemporal data, Bai et al. (2020); Zhao et al. (2019); Yu et al. (2017); Guo et al. (2019) try to learn data after making it to be complete, i.e., allocate to other values from missing data with linear interpolation. In our proposed method, it is crucial to rightly estimate the underlying function when training spatiotemporal dataset because the functions define the expected pattern of the data. And that pattern would affect to read the trend of datasets. However it can be hard to estimate when it has many percentage of missing date.\n\n- 아래식은 틀렸음. 이건 회귀모형이 아님.. GNAR의 notation을 사용하여 모형을 다시표현해볼것..\n\n\n\nimage.png\n\n\n\n이부분이 아주 클리어 해야함\n사용하는 대부분의 Notations들이 정리되어야함.\nintro에 쓰는 것이 부담스러우면 제외해도 무방\n뒤에 self consistence estimator에 사용할 Notation을 함께 고려\n\n- 빨간부분 삭제후 다시 작성 (혹은 공부할 것)\n\n\n\nimage.png\n\n\n- 초록색부분은 나쁘지 않음\n\n\n\nimage.png\n\n\n기존\nAfter interpolation to learn dataset, we can write a model as \\[y_i =f(x_i)+ε_i,\\] f(xi) represents the underlying function, and εi is thought to follow a normal distribution. In this paper, we try to train yi as eliminate sparse strong signal of εi to get lower mean square error between test data and predicted data. In other word, we study to remain εi without points which can consider heavier tails. In our proposed method, it is crucial to rightly estimate the underlying function f when training spatiotemporal dataset because the functions define the expected pattern of the data. And that pattern would affect to read the trend of datasets. However it can be hard to estimate f when it has many percentage of missing date.\n수정\n삭제함\n\n\n\n2. Related works\n- 2.1과 2.2를 왜 리뷰하는지 설명이 필요함\n- 2.1에서 왜 Convolution Operator에 집중하는지 설명이 필요\n- 2.2에서 왜 Dynamic graphs에 집중하는지 설명이 필요\n- 전체적으로 이름은 related works인데 뭐가 related 되어있길래 이런것들을 소개하는지 클리어하지 않음. (솔직히 저도 저 방법들이 우리랑 뭔 관련있는지 잘모르겠어요)\n- 기존\nRELATED WORK\n2.1 PROPAGATION MODULE\nTo start build the model with the simple graph structure, we can use computational modules which are the propagation module, the sampling module, and the pooling module. Especially, the prop- agation module is a commonly used computational module. It utilizes convolution and recurrent operators to aggregate information about neighbors. The skip operation is a rule of gathering infor- mation from past representations and mitigating the over-smoothing problem. It can be divided into two types: convolutional and recurrent operator(Zhou et al., 2020) and we focus on colvolutional operator. 2Under review as a conference paper at ICLR 2024\nConvolutional Operator The convolutional operator can be considered a combination of spectral and spatial methods. First, there are a few classic models, which are spectral approaches: Spec- tral Network, ChebNet, and Adaptive Graph Convolution Network(AGCN). The spectral network is proposed by Bruna et al. (2013), which is defined as the characteristics of convolutions in the Fourier domain, which are determined by the eigendecomposition of the graph Laplacian. ChebNet, suggested by Defferrard et al. (2016), employed the K-localized convolution to construct a convolu- tional neural network that could avoid calculating eigenvectors of Laplacian. AGCN(Li et al., 2018) follows the relationship of the spatial aspect, at the same time, uses the residual graph Laplacian, and Li et al. (2018) called it an Adaptive graph. Next are the spatial approaches. The concept of Neural Frames Per Second (Neural FPS) is introduced by Duvenaud et al. (2015). They utilize dif- ferent weight matrices based on nodes with different degrees, but this approach may not be scalable to handle large-scale data. There is a model called Patchy-san proposed by Niepert et al. (2016). In the first step of this model, they select k numbers of neighbors of nodes. After normalizing around k neighbors, the model functions as a receptive field. The Diffusion-Convolutional Neural Net- works(DCNNs) of Atwood & Towsley (2016) are also considered the neighbor between nodes and can be used in classification by changing edges and adjacency matrix. DCNN uses the metrics of transition to get the neighborhood for nodes. The Dual Graph Convolutional Networks (DGCN) pro- posed by Zhuang & Ma (2018) consider local and global consistency. Gao et al. (2018) proposed the Learnable Graph Convolutional Networks (LGCN), which is based on the Learnable Graph Convo- lutional Layer, and the layer transforms the graph into a 1-D format, taking into account the number of nodes for definition.\n2.2 GRAPH TYPE AND SCALE\nIt is important to consider there is not the only simple type graphs. So, we can approach to face variant grape types for real world data which is complex. The graphs’ classification categories can be directed/undirected, Homogeneous/heterogeneous, and static/dynamic graphsZhou et al. (2020). The directed graph can be called when edges of graph are connected, and the undirected graph means the opposite. The directed graph is better than the undirected graph because the first one has more information than the second one. The homogeneous graph has the same types of nodes and edges; however, the heterogeneous graph has different types. That means that information on nodes and edges is important when we analyze the heterogeneous graph. We can call a dynamic graph if the input features or graph topology change. It is reasonable that time points should be considered carefully there rather than a static graph. Zhou et al. (2020) also propose a classification of graphs based on their scale and type, which includes directed, heterogeneous, dynamic, hypergraph, signed, and large graphs.\nDynamic graphs Among them, we focus on the dynamic graph. Spatial and temporal informa- tion is collected on DCRNN(Diffusion Convolution Recurrent Neural Network)(Li et al., 2017) and STGCN(Spatio-temporal graph convolutional networks)(Yu et al., 2017). In detail, DCRNN gets the spatial data by GNN and then transfer the output to sequence-to-sequence or the sequence model such as RNN to consider temporal dependency and STGCN stacks multiple statio-temporal con- volutional blocks which are consisted one spatil graphconvolutional layer and two temporal gate convolutional layers. On the other hand, Structure-RNN(Jain et al., 2016) and ST-GCN(Yan et al., 2018) simultaneously capture spatial and temporal messages. To enable the application of traditional GNNs on the extended graphs, both Structural-RNN and ST-GCN expand the static graph structure by incorporating temporal connections. Structual-RNN adds edges between consecutive time steps, representing nodes and edges with nodeRNNs and edgeRNNs in a bipartite graph. ST-GCN involves constructing spatiotemporal graphs by stacking graph frames from each time step. However, Pareja et al. (2020) argue that using node features in learning can impact the model’s performance and propose EvolceGCN, a method designed for dynamic graphs.\n- 참고\n\nsnapshot이 homogeneous가 아닌데 missing 부분을 채워 넣어 homogeneuos graph 로 해석하고 분석\n\n위에서 언급한 저자들 입력\nSpatio-Temporal Graph Convolutional Networks: A Deep Learning Framework for Traffic Forecasting(Bing Yu, Haoteng Yin, Zhanxing Zhu)\n\nThe linear interpolation method is used to fill missing values after data cleaning. In addition, data input are normalized by Z-Score method.\n\nGraph Markov network for traffic forecasting with missing data\n\nWe denote the completed state by, in which all missing values are filled based on historical data\n\n\n아예 full로 데이터가 존재한다고 가정하고 homogenous graph 로 보고 제시된 방법론\n\nScalable Spatiotemporal Graph Neural Networks(Andrea Cini, Ivan Marisca, Filippo Maria Bianchi, Cesare Alippi)\n\nThe first dataset contains data coming from the Irish Commission for Energy Reg- ulation Smart Metering Project (CER-E; Commission for Energy Regulation 2016), which has been previously used for benchmarking spatiotemporal imputation methods (Cini, Marisca, and Alippi 2022);however, differently from previ- ous works, we consider the full sensor network consisting of 6435 smart meters measuring energy consumption ev- ery 30 minutes at both residential and commercial/industrial premises.\n\n\n처음부터 heterogeneous graph를 input data로 가정하며 만들어진 방법론\n\nLearning Deep Representation from Big and Heterogeneous Data for Traffic Accident Inference(Quanjun Chen, Xuan Song, Harutoshi Yamada, Ryosuke Shibasaki)\n\nBy mining big and hetero- geneous data, we aim to understand and develop a general model to estimate traffic accident risk. With the input of real- time GPS data, our model can simulate traffic accident risk on a large scale.\nWe extract hierarchical feature representation of meshed human mobility data from Stack denoise Autoencoder (SdAE), for a more efficient and precise prediction of risk levels in supervised learning.\n\nISTD-GCN: Iterative Spatial-Temporal Diffusion Graph Convolutional Network for Traffic Speed Forecasting(Yi Xie, Yun Xiong, Yangyong Zhu)\n\nTherefore, we can model such heterogeneous spatial-temporal structures as a homogeneous process ofdiffusion\n\n- 수정\nAs we mentioned, irregular spatiotemporal data is often encountered in the real world. It is well- known that neural networks are better suited for regular data. Therefore, many attempts have been made to transform data with different structures into the same structure through snapshots. If we interpret this as a graph, we can divide it into homogeneous graphs and heterogeneous graphs. Ho- mogeneous graphs have the same types of nodes and edges, while heterogeneous graphs do not(Zhou et al., 2020). There are Numerous methods to address the challenge of dealing with this issue. For instance, to fill missing values, Bai et al. (2020); Yu et al. (2017); Guo et al. (2019) employ linear in- terpolation, while Cui et al. (2020) utilize historical data. All of them tried to convert heterogeneous graph into homogeneous graph. However, if we create regular data using interpolation methods, the result may have low accuracy. Additionally, Cini et al. (2023) assume that the input data is originally complete, which is equivalent to interpreting the data as a homogeneous graph from the beginning. Furthermore, Chen et al. (2016); Xie et al. (2020) proposed a general model that treats input data as a heterogeneous graph, assuming a lack of supported sensing data. It might be efficient to handle data with a heterogeneous structure in each snapshot. But the real data often represents homogeneous graph and the missing values transforms it into a heterogeneous graph, that means the structures of every snapshot are not different.\n\n\n3. Backgrounds\n- 좋아요\n- 자잘한건 제가 수정하면 될 듯합니다.\n\n\n4.\n- 내용을 좀 더 팬시하게 쓸 필요가 있어보임\n- 아래부분을 정리하여 알고리즘화 해야함.\n\n\n\nimage.png\n\n\n- 기존\n\n\n5. Experiments\n- 아직 덜 읽어봄\n- 데이터 설명은 Appendix에, 실험결과와 Fig는 본문에 있는게 좋음\n[1] 보통 결측없이 모두 관측한상태에서는 모형이 잘 동작함, 대부분의 spatio temporal data는 각각의 스냅샷마다 동일한 그래프구조를 가진다는 가정을 사용함. 스냅샷마다 그래프구조가 다른 경우를 가정하는 모형도 있음. 그러한 모형의 예시는 A,B,C,…. 등이 있음. 하지만 이러한 연구는 애초에 데이터가 스냅샷마다 non-호모지니우스하게 생겼으면 효율적일 수 있으나, 실제true model은 스냅샷마다 그래프구조가 동일하다고 여겨지지만 결측치로 인하여 스냅샷마다 호모지니우스가 깨지는 경우는 효율적이지 않을 수 있음. 우리는 이 부분에 초점을 맞추었음. 우리의 아이디어는 호모지니우스 하지 않은 그래프를 A,B,C, 등을 이용하여 그대로 처리하는것 보다 missing을 처리하여 호모지니우스하게 강제로 만들고 그 자료를 분석하자는 아이디어임."
  },
  {
    "objectID": "posts/1_Note/2022-04-03-(5주차) 4월2일.html",
    "href": "posts/1_Note/2022-04-03-(5주차) 4월2일.html",
    "title": "Introduction to Python 5wk",
    "section": "",
    "text": "소스코드 관리, 모듈, 패키지, 라이브러리\n\nhttps://guebin.github.io/IP2022/2022/04/03/(5%EC%A3%BC%EC%B0%A8)-4%EC%9B%942%EC%9D%BC.html\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-yzovneTfJptA4K705FOG1f\n\n- (1/7) intro\n- (2/7) import 사용방법, 도움말 작성기능\n- (3/7) import 사용시 주의점\n- (4/7) import 고급\n- (5/7) site-packages 1\n- (6/7) site-packages 2\n- (7/7) 모듈, 패키지, 라이브러리, 숙제설명\n\n\nintro\n- 현재 파이썬은 길이가 2인 벡터의 덧셈을 지원하지 않음\n\na=[1,2]\nb=[3,4]\na+b\n\n[1, 2, 3, 4]\n\n\n- 아래와 같은 기능을 구현하는 함수를 만들고 싶음\n[1,2], [3,4] -&gt; [4,6]\n- 구현\n\ndef vec2_add(a,b): \n    return [a[0]+b[0], a[1]+b[1]]\n\n- test\n\na=[1,2]\nb=[3,4]\n\n\nvec2_add(a,b)\n\n[4, 6]\n\n\n\n\nmake myfuns.py\n- 생각해보니까 vec2_add는 내가 앞으로 자주 쓸 기능임\n- 그런데 현재 사용방법으로는 내가 노트북파일을 새로 만들떄마다 def vec2_add(a,b): 와 같은 형태로 vec2_add를 매번 정의해줘야 하는 불편한이 있다.\n\n해결1\n- 자주 사용하는 함수를 myfuns.py에 저장한다.\n# myfuns.py\ndef vec2_add(a,b): \n    return [a[0]+b[0], a[1]+b[1]]\n- %run myfuns를 실행\n준비: “00” -&gt; 커널재시작\n\n%run myfuns \n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\n\n해결2\n- 자주 사용하는 함수를 myfuns.py에 저장한다.\n# myfuns.py\ndef vec2_add(a,b): \n    return [a[0]+b[0], a[1]+b[1]]\n- import myfuns를 이용\n(준비) “00” -&gt; 커널재시작\n\nimport myfuns \n\n\na=[1,2]\nb=[3,4]\nmyfuns.vec2_add(a,b)\n\n[4, 6]\n\n\n\n\n\nimport 기본\n\n사용방법\n- 사용방법1\n준비: “00” -&gt; 커널재시작\n\nimport myfuns \n\n\nmyfuns.vec2_add([1,2],[3,4]) \n\n[4, 6]\n\n\n\nmyfuns.vec2_add 의 의미: myfuns.py 라는 파일안에 vec2_add라는 함수가 있음. 그것을 실행하라.\n.의 의미: 상위.하위의 개념!\n\n(주의) 아래와 같이 사용불가능 하다.\n\nvec2_add([1,2],[3,4])\n\nNameError: name 'vec2_add' is not defined\n\n\n- 사용방법2\n준비: “00” -&gt; 커널재시작\n\nfrom myfuns import vec2_add \n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n(주의) 이 경우는 오히려 아래가 불가능함\n\nmyfuns.vec2_add([1,2],[3,4]) # myfuns안의 vec2_add만 임포트했지 myfuns자체를 임포트 한것은 아님 \n\nNameError: name 'myfuns' is not defined\n\n\n- 사용방법3\n준비: “00” -&gt; 커널재시작\n\nimport myfuns\nfrom myfuns import vec2_add\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n- 사용방법4\n준비: “00” -&gt; 커널재시작\n\nfrom myfuns import vec2_add, vec2_sub \n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_sub([1,2],[3,4])\n\n[-2, -2]\n\n\n- 사용방법5\n준비: “00” -&gt; 커널재시작\n\nfrom myfuns import * #*는 all의 의미 \n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_sub([1,2],[3,4])\n\n[-2, -2]\n\n\n- 사용방법6\n준비: “00” -&gt; 커널재시작\n\nimport myfuns as mf \n\n\nmf.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nmf.vec2_sub([1,2],[3,4])\n\n[-2, -2]\n\n\n(오히려 아래는 실행불가능)\n\nmyfuns.vec2_add([1,2],[3,4])\n\nNameError: name 'myfuns' is not defined\n\n\n\nmyfuns.vec2_sub([1,2],[3,4])\n\nNameError: name 'myfuns' is not defined\n\n\n- 잘못된 사용방법1\n준비: “00” -&gt; 커널재시작\n\nimport myfuns as mf \nfrom mf import vec2_add \n\nModuleNotFoundError: No module named 'mf'\n\n\n- 사용방법7\n준비: “00” -&gt; 커널재시작\n\nimport myfuns as mf \nfrom myfuns import vec2_add \n\n\nmf.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n- 사용방법8\n준비: “00” -&gt; 커널재시작\n\nimport myfuns as mf \nfrom myfuns import vec2_add as add \n\n\nmf.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n\nvec2_add([1,2],[3,4])\n\nNameError: name 'vec2_add' is not defined\n\n\n\nadd([1,2],[3,4])\n\n[4, 6]\n\n\n\n\n도움말 작성기능\n- mf란 무엇인가?\n준비: “00” -&gt; 커널재시작\n\nimport myfuns as mf \n\n\nmf\n\n&lt;module 'myfuns' from '/home/cgb3/Dropbox/07_lectures/IP2022/_notebooks/myfuns.py'&gt;\n\n\n\nmf?\n\n\nType:        module\nString form: &lt;module 'myfuns' from '/home/cgb3/Dropbox/07_lectures/IP2022/_notebooks/myfuns.py'&gt;\nFile:        ~/Dropbox/07_lectures/IP2022/_notebooks/myfuns.py\nDocstring:   &lt;no docstring&gt;\n\n\n\n\n\ntype(mf)\n\nmodule\n\n\n\nmf의 타입은 모듈이라고 나옴, 현재 단계에서는 무엇인지 알기 어려움\n\n- Docstring의 내용을 채울 수 있을까?\n준비1: myfuns.py 파일을 아래와 같이 수정한다.\n준비2: “00” -&gt; 커널재시작\n\nimport myfuns as mf \n\n\nmf?\n\n\nType:        module\nString form: &lt;module 'myfuns' from '/home/cgb3/Dropbox/07_lectures/IP2022/_notebooks/myfuns.py'&gt;\nFile:        ~/Dropbox/07_lectures/IP2022/_notebooks/myfuns.py\nDocstring:   이것은 길이가 2인 벡터의 합 혹은 차를 구하는 모듈입니다.\n\n\n\n\n\n\n주의점\n- myfuns.py는 최초 한번만 import 된다.\n준비: “00” -&gt; 커널재시작\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\nmyfuns.py파일을 열고 함수를 아래와 같이 바꾸자.\n\"\"\"이것은 길이가 2인 벡터의 합 혹은 차를 구하는 모듈입니다.\"\"\" \ndef vec2_add(a,b): \n    print(\"이것은 myfuns.py에 정의된 함수입니다\") \n    return [a[0]+b[0], a[1]+b[1]]\ndef vec2_sub(a,b): \n    return [a[0]-b[0], a[1]-b[1]]\n다시 myfuns를 로드하고 myfuns.vec2_add 를 실행하여 보자.\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n[4, 6]\n\n\n바뀐내용이 적용되지 않는다.\n커널을 다시 시작하고 임포트해보자.\n“00” -&gt; 커널재시작\n\nimport myfuns\n\n\nmyfuns.vec2_add([1,2],[3,4])\n\n이것은 myfuns.py에 정의된 함수입니다\n\n\n[4, 6]\n\n\n- myfuns.py는 주피터노트북파일과 같은 폴더에 존재해야 한다.\n준비1: “00” -&gt; 커널재시작\n준비2: myfuns.py을 복사하여 다른 폴더로 이동. 예를들면 IP0403 폴더를 만들고 그 폴더안에 myfuns.py파일을 복사해서 붙여넣은뒤에 파일이름을 myfuns2.py 로 변경.\n\nimport myfuns # 주피터노트북파일과 같은 폴더에 있는 myfuns는 잘 로드되지만 \n\n\nimport myfuns2 # 주피터노트북파일과 다른 폴더에 있는 myfuns2는 그렇지 않다. \n\nModuleNotFoundError: No module named 'myfuns2'\n\n\n- IP0403 폴더에 있는 myfuns2.py를 실행하기 위해서는 아래와 같이 할 수 있다.\n준비: “00” -&gt; 커널재시작\n\nfrom IP0403 import myfuns2\n\n\nmyfuns2.vec2_add([1,2],[3,4]) \n\n이것은 myfuns2.py에 정의된 함수입니다\n\n\n[4, 6]\n\n\n- 아래도 가능하다.\n준비: “00” -&gt; 커널재시작\n\nfrom IP0403.myfuns2 import vec2_add as add \n\n\nadd([1,2],[3,4])\n\n이것은 myfuns2.py에 정의된 함수입니다\n\n\n[4, 6]\n\n\n참고로 아래는 모두 정의되지 않음\n\nIP0403.myfuns2.vec2_add([1,2],[3,4]) \n\nNameError: name 'IP0403' is not defined\n\n\n\nmyfuns2.vec2_add([1,2],[3,4]) \n\nNameError: name 'myfuns2' is not defined\n\n\n\nvec2_add([1,2],[3,4]) \n\nNameError: name 'vec2_add' is not defined\n\n\n\n\n\nimport 고급\n\n폴더와 함께 사용할시\n- 언뜻 생각하면 아래가 가능할 것 같다.\nimport IP0403 \nIP0403.myfuns2.vec2_add([1,2],[3,4]) \n- 하지만 불가능하다.\n준비: “00” -&gt; 커널재시작\n\nimport IP0403 \n\n\n되는거아냐?\n\n\nIP0403.myfuns2.vec2_add([1,2],[3,4])\n\nAttributeError: module 'IP0403' has no attribute 'myfuns2'\n\n\n\n여기서 불가능하다.\n\n- (암기) IP0403 폴더안에 __init__.py라는 파일을 만들고 내용에 아래와 같이 쓰면 가능하다.\n# ./IP0403/__init__.py \nfrom . import myfuns2\n준비1: 위의 지침을 따른다.\n준비2: “00” -&gt; 커널재시작\n\nimport IP0403 \n\n\nIP0403.myfuns2.vec2_add([1,2],[3,4])\n\n이것은 myfuns2.py에 정의된 함수입니다\n\n\n[4, 6]\n\n\n컴퓨터 상식 - .: 현재폴더를 의미 - ..: 상위폴더를 의미 - ./myfuns.py: 현재폴더안에 있는 myfuns.py를 의미 - ./IP0403/myfuns2.py: 현재폴더만에 IP0403폴더안의 myfuns2.py 파일을 의미 - ../myfuns.py: 현재폴더보다 한단계상위폴더에 있는 myfuns.py를 의미 - cd ./IP0403: 현재폴더안에 있는 IP0403폴더로 이동해라. (cd IP0403으로 줄여쓸 수 있음) - cd .. 현재폴더보다 한단계 상위폴더로 이동하라.\n따라서 from . import myfuns2는 현재폴더에서 myfuns2를 찾아서 임포트 하라는 의미로 해석가능\n- 의미상으로 보면 아래가 실행가능할듯 한데 불가능하다.\n\n#import myfuns\nfrom . import myfuns\n\nImportError: attempted relative import with no known parent package\n\n\n\n\n\nsite-packages (실습금지)\n- 의문: 왜 현재폴더에 numpy.py라든가 numpy라는 이름의 폴더가 없는데도 import 가능한지?\n준비: “00” -&gt; 커널재시작\n\nimport numpy as np\n\n\nimport IP0403 as ip \n\n\nip?\n\n\nType:        module\nString form: &lt;module 'IP0403' from '/home/cgb3/Dropbox/07_lectures/IP2022/_notebooks/IP0403/__init__.py'&gt;\nFile:        ~/Dropbox/07_lectures/IP2022/_notebooks/IP0403/__init__.py\nDocstring:   &lt;no docstring&gt;\n\n\n\n\n\nnp?\n\n\nType:        module\nString form: &lt;module 'numpy' from '/home/cgb3/anaconda3/envs/py310/lib/python3.10/site-packages/numpy/__init__.py'&gt;\nFile:        ~/anaconda3/envs/py310/lib/python3.10/site-packages/numpy/__init__.py\nDocstring:  \nNumPy\n=====\nProvides\n  1. An array object of arbitrary homogeneous items\n  2. Fast mathematical operations over arrays\n  3. Linear Algebra, Fourier Transforms, Random Number Generation\nHow to use the documentation\n----------------------------\nDocumentation is available in two forms: docstrings provided\nwith the code, and a loose standing reference guide, available from\n`the NumPy homepage &lt;https://www.scipy.org&gt;`_.\nWe recommend exploring the docstrings using\n`IPython &lt;https://ipython.org&gt;`_, an advanced Python shell with\nTAB-completion and introspection capabilities.  See below for further\ninstructions.\nThe docstring examples assume that `numpy` has been imported as `np`::\n  &gt;&gt;&gt; import numpy as np\nCode snippets are indicated by three greater-than signs::\n  &gt;&gt;&gt; x = 42\n  &gt;&gt;&gt; x = x + 1\nUse the built-in ``help`` function to view a function's docstring::\n  &gt;&gt;&gt; help(np.sort)\n  ... # doctest: +SKIP\nFor some objects, ``np.info(obj)`` may provide additional help.  This is\nparticularly true if you see the line \"Help on ufunc object:\" at the top\nof the help() page.  Ufuncs are implemented in C, not Python, for speed.\nThe native Python help() does not know how to view their help, but our\nnp.info() function does.\nTo search for documents containing a keyword, do::\n  &gt;&gt;&gt; np.lookfor('keyword')\n  ... # doctest: +SKIP\nGeneral-purpose documents like a glossary and help on the basic concepts\nof numpy are available under the ``doc`` sub-module::\n  &gt;&gt;&gt; from numpy import doc\n  &gt;&gt;&gt; help(doc)\n  ... # doctest: +SKIP\nAvailable subpackages\n---------------------\ndoc\n    Topical documentation on broadcasting, indexing, etc.\nlib\n    Basic functions used by several sub-packages.\nrandom\n    Core Random Tools\nlinalg\n    Core Linear Algebra Tools\nfft\n    Core FFT routines\npolynomial\n    Polynomial tools\ntesting\n    NumPy testing tools\nf2py\n    Fortran to Python Interface Generator.\ndistutils\n    Enhancements to distutils with support for\n    Fortran compilers support and more.\nUtilities\n---------\ntest\n    Run numpy unittests\nshow_config\n    Show numpy build configuration\ndual\n    Overwrite certain functions with high-performance SciPy tools.\n    Note: `numpy.dual` is deprecated.  Use the functions from NumPy or Scipy\n    directly instead of importing them from `numpy.dual`.\nmatlib\n    Make everything matrices.\n__version__\n    NumPy version string\nViewing documentation using IPython\n-----------------------------------\nStart IPython with the NumPy profile (``ipython -p numpy``), which will\nimport `numpy` under the alias `np`.  Then, use the ``cpaste`` command to\npaste examples into the shell.  To see which functions are available in\n`numpy`, type ``np.&lt;TAB&gt;`` (where ``&lt;TAB&gt;`` refers to the TAB key), or use\n``np.*cos*?&lt;ENTER&gt;`` (where ``&lt;ENTER&gt;`` refers to the ENTER key) to narrow\ndown the list.  To view the docstring for a function, use\n``np.cos?&lt;ENTER&gt;`` (to view the docstring) and ``np.cos??&lt;ENTER&gt;`` (to view\nthe source code).\nCopies vs. in-place operation\n-----------------------------\nMost of the functions in `numpy` return a copy of the array argument\n(e.g., `np.sort`).  In-place versions of these functions are often\navailable as array methods, i.e. ``x = np.array([1,2,3]); x.sort()``.\nExceptions to this rule are documented.\n\n\n\n\n- 추측: ~/anaconda3/envs/py310/lib/python3.10/site-packages/를 찾아가보자. 그곳에 numpy폴더가 있을 것이다.\n\n!ls ~/anaconda3/envs/py310/lib/python3.10/site-packages | grep numpy\n\nnumpy\nnumpy-1.22.2.dist-info\n\n\n- 추측2: ~/anaconda3/envs/py310/lib/python3.10/site-packages/에 내가 자주 쓰는 기능을 폴더로 만들어서 모아두면 어디서든지 import 할 수 있다.\n\n!mkdir ~/anaconda3/envs/py310/lib/python3.10/site-packages/guebin # guebin 폴더 생성 \n\n\n!cp ./myfuns.py ~/anaconda3/envs/py310/lib/python3.10/site-packages/guebin \n# 현폴더에 있는 myfuns.py를 아까만든 guebin 폴더로 복사 \n\n\nfrom guebin import myfuns\n\n\nmyfuns?\n\n\nType:        module\nString form: &lt;module 'guebin.myfuns' from '/home/cgb3/anaconda3/envs/py310/lib/python3.10/site-packages/guebin/myfuns.py'&gt;\nFile:        ~/anaconda3/envs/py310/lib/python3.10/site-packages/guebin/myfuns.py\nDocstring:   이것은 길이가 2인 벡터의 합 혹은 차를 구하는 모듈입니다.\n\n\n\n\n\n!rm  ~/anaconda3/envs/py310/lib/python3.10/site-packages/guebin -rf # guebin 폴더삭제 \n\n- 추측3: guebin이 사라진 상태에서는 from guebin import myfuns 이 동작하지 않을 것이다.\n준비: “00” -&gt; 커널재시작\n\nfrom guebin import myfuns\n\nModuleNotFoundError: No module named 'guebin'\n\n\n- 추측4: ~/anaconda3/envs/py310/lib/python3.10/site-packages/에서 numpy를 지운다면 numpy를 import할 수 없다.\n준비: “00” -&gt; 커널재시작\n\nimport numpy as np\n\nModuleNotFoundError: No module named 'numpy'\n\n\n- 추측5: !pip install numpy를 하면 다시 폴더가 생길 것이다.\n\n!pip uninstall numpy -y \n\nFound existing installation: numpy 1.22.2\nUninstalling numpy-1.22.2:\n  Successfully uninstalled numpy-1.22.2\n\n\n\n!pip install numpy \n\nCollecting numpy\n  Downloading numpy-1.22.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n     |████████████████████████████████| 16.8 MB 11.4 MB/s eta 0:00:01\nInstalling collected packages: numpy\nSuccessfully installed numpy-1.22.3\n\n\n\n\n모듈, 패키지, 라이브러리?\n- 모듈의 개념은 아까 살펴본것과 같다. (import를 하여 생기게 되는 오브젝트)\n- 교수님들: 모듈이 모이면 패키지라고 부른다. 그리고 라이브러리는 패키지보다 큰 개념이다.\n- 그런데 구분이 모호하다.\n\nimport numpy as np\n\n\ntype(np)\n\nmodule\n\n\n- python에서의 numpy의 type은 모듈\n- 그런데 numpy package 라고 검색하면 검색이 된다.\n- 심지어 numpy library 라고 해도 검색가능\n- 내생각: 넘파이모듈, 넘파이패키지, 넘파이라이브러리 다 맞는 말임\n\n\n숙제\nmyfuns.py 도움말 만드는 예제에서\n이것은 길이가 2인 벡터의 합 혹은 차를 구하는 모듈입니다\n대신에\n이것은 길이가 2인 벡터의 합 혹은 차를 구하는 모듈입니다. (학번: 2022-43052) \n와 같이 출력되도록 하고 스크린샷 제출"
  },
  {
    "objectID": "posts/1_Note/2019-04-26-퓨리에 변환.html",
    "href": "posts/1_Note/2019-04-26-퓨리에 변환.html",
    "title": "[Essays] 퓨리에 변환",
    "section": "",
    "text": "About this doc\n- 이번에는 퓨리에 표현들을 정리하도록 하겠다. 내생각엔 퓨리에 표현들도 벡터의 미분만큼 복잡한 것 같다. 정의가 너무 많고 그게 그거 같아서 그렇다. 이번기회에 깔끔하게 정리하도록 하자. 참고한 문헌은 아래와 같다.\n\nHaykin, S., & Van Veen, B. (2007). Signals and systems. John Wiley & Sons.\n\n\n\n들어가며\n- 우선 신호와 하나의 신호값을 구분하는 notation을 생각하자. 우리가 다루는 신호 즉 데이터는 값들의 집합이다. 우리가 시계열자료를 다룬다면 데이터는 아래와 같이 표현한다.\n\n\\(\\{x_i: i \\in \\mathbb{Z}\\}\\)\n\n이와 유시하게 우리가 다루는 자료가 \\(t \\in \\mathbb{R}\\)인 연속신호라면 아래와 같이 표현한다.\n\n\\(\\{x(t): t \\in \\mathbb{R}\\}\\)\n\n우리가 모든 \\(i \\in \\mathbb{Z}\\) 혹은 모든 \\(t \\in \\mathbb{R}\\)에서 신호를 다룰 생각이 없다면 아래와 같은 표현도 얼마든지 가능하다.\n\n\\(\\{x_i: i=0,1,\\dots, \\xi-1 \\}\\)\n\\(\\{x(t):t \\in (0,\\zeta) \\}\\)\n\n- 위와 같이 집합의 표현 없이 단독으로 \\(x_i\\), \\(x(t)\\)와 같이 쓰면 하나의 고정된 값 \\(i,t\\)에 대한 \\(x_i\\), \\(x(t)\\)로 이해하자. 솔직히 이렇게 꼭 신호를 엄밀하게 집합으로 정의하는게 유별나 보일수도 있다. 일반적으로 사람들은 \\(\\{x(t): ~t \\in \\mathbb{R} \\}\\) 대신에 보통 \\(x(t)\\)로 간단하게 줄여서 쓰곤한다.1 하지만 이 포스팅에 한정하여 위와 같이 집합의 형태로 엄밀하게 구분해 쓰도록 하자. 처음에는 익숙하지 않지만 나중에는 편리하다.\n1 나도 그렇다.\n\n퓨리에표현들\n- 지금부터 우리가 고려하는 모든 신호들은 기본적으로 (1) infinity range에서 정의된 신호라고 가정한다. 즉 연속신호이면 \\(\\mathbb{R}\\)에서 정의된다고 가정하고 이산신호면 \\(\\mathbb{Z}\\)에서 정의된다고 가정한다. 또한 우리가 분석하고자 하는 신호는 (2) integrable 하다고 가정한다. 이건 퓨리에표현들이 적분 혹은 무한합의 형태로 표현된다는 것을 상기하면 타당하여 보인다.\n- 즉 우리가 고려하는 신호는 인피니티-레인지에서 정의되며 인피니티-레인지에서 적분값이 유한한 연속신호 혹은 이산신호 임을 알 수 있다. 이러한 신호는 구체적으로는 아래와 같이 쓸 수 있다.\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}\\)\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}\\)\n\n- 그런데 integrable 한 함수들만을 고려하다 보면 우리가 다룰 수 있는 신호의 범위가 확 줄어들게 된다. 가령 예를 들어서 아래와 같은 신호는 적분을 하면 무한대가 나오기 때문에 intergrable 하지 않다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in \\mathbb{R} \\right\\}\\)\n\n이것은 좀 불합리해 보이는데 위의 신호는 주기신호라서 한 주기의 패턴만 분석하면 될것 같이 보이기 때문이다. 위의 신호는 intergrable 하지않지만 아래의 신호는 intergrable 하다.\n\n\\(\\left\\{x(t): x(t)=\\sin(t)+1 ,~ t \\in (0,2\\pi) \\right\\}\\)\n\n우리는 이런신호까지 분석하기로 한다. 이런신호를 분석할 수 있는 이유는 해석학 교재를 참고하면 된다.2\n2 사실 나도 잘 모름 (뭐 quotient group이런거 알아야 하는데 공부하려면 꽤 걸릴듯)- 아무튼 우리는 (1) 인피니티-레인지에서 정의되는 가지는 신호 (2) 인피니티-레인지에서 적분값이 잘 정의되는 신호, 혹은 한 주기만 적분해 보았을때 그 값이 잘 정의되는 주기신호 를 타겟팅해 분석한다. 즉 분석하는 신호는 구체적으로 아래의 4가지이다.\ncase 1: 연속-비주기\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\}.\\)\n\ncase 2: 연속-주기\n\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty, ~ , x(t)=x(t+\\zeta), ~ t \\in \\mathbb{R}, \\right\\}.\\)\n\ncase 3: 이산-비주기\n\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 4: 이산-주기\n\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ i, x_i=x_{i+\\xi},~ i \\in \\mathbb{Z} \\right\\}.\\)\n\n- 표현들을 정리하기에 앞서서 몇 가지 알아두어야 할 사항이 있다. (1) 시간축에서 연속인 신호는 주파수측에서는 비주기신호가 나온다. (2) 시간축에서 디스크릿한 신호는 주파수측에서는 주기신호이다. (3) 시간축에서 주기인 신호는 주파수에서는 디스크릿하다. (4) 시간축에서 비주기신호는 주파수에서 연속이다. 이 사실들을 종합하면 각각의 경우에 해당하는 퓨리에 표현들은 아래와 같은 특징을 가지고 있음을 알 수 있다.\ncase 1: 연속-비주기\n\n\\(\\left\\{x(t): \\int_{-\\infty}^{\\infty} |x(t)| dt &lt;\\infty,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\int_{-\\infty}^{\\infty} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\omega \\in \\mathbb{R} \\right\\}\\)\n\ncase 2: 연속-주기\n\n\\(\\left\\{x(t): \\int_{0}^{\\zeta} |x(t)| dt &lt;\\infty,~ x(t)=x(t+\\zeta),~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\sum_{k=-\\infty}^{\\infty} |\\hat x_k| &lt;\\infty,~ k \\in \\mathbb{Z} \\right\\}\\)\n\ncase 3: 이산-비주기\n\n\\(\\left\\{x_i: \\sum_{i=-\\infty}^{\\infty} |x_i| &lt;\\infty,~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\int_{0}^{2\\pi} |\\hat x(\\omega)| d\\omega &lt;\\infty,~ \\hat x(\\omega)=\\hat x(\\omega+2\\pi),~ \\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 4: 이산-주기\n\n\\(\\left\\{x_i: \\sum_{i=0}^{\\xi-1} |x_i| &lt;\\infty,~ x_i=x_{i+\\xi},~ i \\in \\mathbb{R} \\right\\} \\\\ \\overset{DTFS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\sum_{k=0}^{\\xi-1} |\\hat x_k| &lt;\\infty,~\\hat x_k = \\hat x_{k+\\xi} ,~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 여기에서 \\(\\zeta\\)는 (시간축에서) 연속신호의 주기라고 정의하고 \\(\\xi\\)는 (시간축에서) 이산신호의 주기라고 약속하자. 주파수영역이 디스크릿하게 나오면 FS라고 부르고 주파수영역이 컨티뉴어스하게 나오면 FT라고 부른다. 특이한점은 비주기-이산신호에 대한 FS \\(\\hat x(\\omega)\\)는 주파수 영역에서 주기가 \\(2\\pi\\)임을 파악할 수 있다. 이유는 궁금해하지말자. (내생각에 그냥 \\(\\omega\\)를 적당히 스케일링하여 주기를 \\(2\\pi\\)로 맞췄을 거다.)\n- 이제 짜증나는 적분가능조건따위는 버리도록 하자. 대신에 각 경우에 퓨리에변환(혹은series)과 그 역이 어떻게 정의되는지 알아보자. 그리고 외우자. 각 신호가 어떠한 도메인에서 정의되는지만 잘 파악하면 의외로 외우기 쉽다.\ncase 1. 연속-비주기\n\n\\(\\left\\{x(t): x(t)=\\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\int_{-\\infty}^{\\infty} x(t)e^{-j\\omega t} dt,~ \\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 2. 연속-주기\n\n\\(\\left\\{x(t): x(t)= \\sum_{k=-\\infty}^{\\infty} \\hat x_k e^{j \\frac{2\\pi}{\\zeta} t} ,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt,~ k \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 3. 이산-비주기\n\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega, ~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): \\hat x(\\omega)=\\sum_{i=-\\infty}^{\\infty}x_ie^{-j\\omega i}, ~\\omega \\in \\mathbb{R} \\right\\}.\\)\n\ncase 4. 이산-주기\n\n\\(\\left\\{x_i: x_i=\\sum_{k=0}^{\\xi-1} \\hat x_k e^{-j\\frac{2\\pi k}{\\xi}i},~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFS}{\\Longleftrightarrow} \\left\\{\\hat x_k: \\hat x_k= \\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i},~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 주기함수는 (그것이 이산이든 연속이든) 주파수영역에서의 값이 디스크릿하다. 즉 위에서 case2와 case4인 경우는 주파수영역에서 값이 디스크릿하다. 이것을 연속함수인것처럼 바꿔보면 아래와 같이 쓸 수 있다.\ncase 2. 연속-주기\n\n\\(\\left\\{x(t): x(t)= \\frac{1}{2\\pi}\\int_{-\\infty}^{\\infty} \\hat x(\\omega)e^{j\\omega t} d\\omega,~ t \\in \\mathbb{R} \\right\\} \\\\ \\overset{FT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\zeta}\\int_{0}^{\\zeta}x(t)e^{-j \\frac{2\\pi k}{\\zeta}t}dt\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\zeta}\\right), ~ k \\in \\mathbb{Z} \\right\\}.\\)\n\ncase 4. 이산-주기\n\n\\(\\left\\{x_i: x_i=\\frac{1}{2\\pi}\\int_{0}^{2\\pi}\\hat x(\\omega)e^{j \\omega i}d\\omega,,~ i \\in \\mathbb{Z} \\right\\} \\\\ \\overset{DTFT}{\\Longleftrightarrow} \\left\\{\\hat x(\\omega): 2\\pi\\sum_{k=-\\infty}^{\\infty}\\left[\\frac{1}{\\xi}\\sum_{i=0}^{\\xi-1} x_i e^{-j\\frac{2\\pi k}{\\xi}i}\\right]\\delta\\left(\\omega-\\frac{2\\pi k}{\\xi}\\right),~ k \\in \\mathbb{Z} \\right\\}.\\)\n\n- 주목할것은 주기가 \\(\\zeta\\) 혹은 \\(\\xi\\) 인 함수의 주파수 응답은 오로지\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\zeta}, k \\in \\mathbb{Z}\\right\\}\\)\n\n혹은\n\n\\(\\omega \\in \\left\\{\\frac{2 \\pi k}{\\xi}, k \\in \\mathbb{Z}\\right\\}\\)\n\n에서만 존재한다는 점이다. 또한 이산신호의 경우 \\(x_i\\)의 주기가 \\(\\xi\\) 이면 \\(\\hat{x}(\\omega)\\)의 주기역시 \\(\\xi\\) 라는점 역시 주목할만한 부분이다.\n- 주파수영역에서 디스크릿한 함수를 연속인것처럼 표현했듯이 시간영역에서 디스크릿한 함수 역시 연속인것처럼 표현할 수 있다. 예를들면 \\(\\{x_i: x_i=x(iT),~i \\in \\mathbb{Z}\\}\\) 와 같은 관계가 있는 경우 아래와 같이 표현 가능하다.\n\\[x_{\\delta}(t)=\\sum_{i=-\\infty}^{\\infty}x_i\\delta(t-iT).\\]\n이거 엄청 중요하다."
  },
  {
    "objectID": "posts/3_Researches/GODE/2023-05-20-EbayesThresh toy ex.html",
    "href": "posts/3_Researches/GODE/2023-05-20-EbayesThresh toy ex.html",
    "title": "EbayesThresh Toy ex",
    "section": "",
    "text": "Import\n\nfrom itstgcn.learners import * \n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nimport pandas as pd\n\n\nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\nWhile \\({\\bf p}_y\\) serves as a consistent estimator for \\(\\mathbb{E}[|{\\bf V}^H{\\bf y}|^2]\\), it is not an efficient estimator, and therefore, improvement is needed (Djuric and Richard 2018). The traditional approach for improvement is to use the windowed periodogram.\nThe windowed periodogram is efficient in detecting specific frequencies or periods, but it may not be as efficient in estimating the underlying function. One notable paper that utilized the windowed periodogram is the one that detected the El Niño phenomenon.\nAs this structure exhibits a “sparse signal + heavy-tailed” characteristics, by applying Bayesian modeling and thresholding \\({\\bf p}_y\\), we can estimate an appropriate \\({\\bf p}_{pp}\\) as discussed in (Johnstone and Silverman 2004).\n\n\nDjuric, Petar, and Cédric Richard. 2018. Cooperative and Graph Signal Processing: Principles and Applications. Academic Press.\n\nJohnstone, Iain M, and Bernard W Silverman. 2004. “Needles and Straw in Haystacks: Empirical Bayes Estimates of Possibly Sparse Sequences.”\n\n\nBayesian Model\n\\(x_i \\sim N(\\mu_i,1)\\)\n확률변수가 잘 정의되어 있을때, 여기서 \\(\\mu_i\\)를 정하는 Baysian.\n\n\\(\\mu_i \\sim\\) 사전분포(\\(\\mu_i\\)를 뽑을 수 있는)\n\\((\\mu_i | X_i = x_i)^n_{i=1} \\sim\\) 사후분포\n\nex) \\(N(10,1) \\sim\\) 사전분포\n관측치\n\n_obs = [7.1,6.9,8.5]\n\n\nnp.mean(_obs)\n\n7.5\n\n\n관측치를 보니 평균이 10이 아닌 것 같다.\n\\(N(10-3,1) \\sim\\) 사후분포\n\n여기서, \\(10-3\\)이 posterior meman\n사후 분포를 정의할때, 이벤트의 mean이냐, median이냐로 잡는 방법은 정해진 것이 아니다.(이베이즈에서는 median으로 잡음)\n\nEbayes는 사전분포를 Heavy-tail으로 정의했다.\nheavy tail?\n\n\n\nimage.png\n\n\n\\(\\mu_x \\sim\\) Double Exponential \\(= p_{pp} + p_{ac}\\) -&gt; 혼합형(misture) = pure point + absolutely continuous\n\\(E(\\mu_i | X_i = x_i) = \\hat{\\mu}_i\\) -&gt; thresholding의 결과\n\\(f_{prior}(\\mu) = (1-w)\\delta_0(\\mu) + w \\gamma (\\mu)\\)\n\n\\(\\delta_0\\) = 디렉함수(특정값이 아니면 다 0으로 봄)\n\\(\\gamma = \\frac{a}{2} e^{-a|\\mu|}\\)\n\nEbayes의 역할 = 자동으로 \\(w\\)를 계산 혹은 추정\n\n\\(1-w\\) 확률로 \\(\\delta_0\\)를 정의, \\(w\\)의 확룔로 \\(\\gamma\\)를 정의.\n\n\\(X_i = \\mu_i + \\epsilon_i, \\epsilon_i \\sim N(0,1)\\)에서 \\(\\mu_i\\)를 찾는게 목적이다. 이게 바로 \\(\\eta\\)값\n\nEbayes로 sparse signal만 골러낼 것이다.\n평균 이상의 값에서 자를 것이다.\n\nthresh(임계치)를 잡는 게 어려울 텐데, 위에서 이베이즈가 \\(w\\)를 자동으로 잡아 확률 계산되는 방법론을 제안한 것,\n\nbaysian modeling 사용하여 heavy tail + impulse(sparse)에서 posterior median 추정하여 임계값thresh으로 \\(p\\)에서 \\(p_{pp}\\)를 추출하는 것이 GODE 목적\n\n\n\nEbayesThresh\n\nT = 100\n\n\nt = np.arange(T)/T * 10\n\n\ny_true = 3*np.sin(0.5*t) + 1.2*np.sin(1.0*t) + 0.5*np.sin(1.2*t) \n\n\ny = y_true + np.random.normal(size=T)\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y_true)\n\n\n\n\n\n\n\n\n- 관찰한 신호\n\nplt.plot(t,y,'o')\nplt.plot(t,y_true,'--')\n\n\n\n\n\n\n\n\n- 퓨리에 변환\n\nf = np.array(y)\nif len(f.shape)==1: f = f.reshape(-1,1)\nT,N = f.shape\nPsi = make_Psi(T)\nfbar = Psi.T @ f # apply dft \n\n\nplt.plot(t,fbar**2) # periodogram \n\n\n\n\n\n\n\n\n- threshed\n\nfbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\nplt.plot((fbar**2)) # periodogram \nplt.plot((fbar_threshed**2)) \n\n\n\n\n\n\n\n\n\nplt.plot((fbar**2)[20:80]) # periodogram \nplt.plot((fbar_threshed**2)[20:80]) \n\n\n\n\n\n\n\n\n- 역퓨리에변환\n\nyhat = Psi @ fbar_threshed # inverse dft\n\n\nplt.figure(figsize=(10,6))\nplt.plot(t,y,'.')\nplt.plot(t,y_true,'--')\nplt.plot(t,yhat)\n\n\n\n\n\n\n\n\n\nplt.figure(figsize=(10,6))\nplt.plot(y,'.')\nplt.plot(y_true)\n\n\n\n\n\n\n\n\n\n\nResult\n\nwith plt.style.context('seaborn-white'):\n    fig, ((ax1,ax2),(ax3,ax4)) = plt.subplots(2,2,figsize=(40,15))\n    fig.suptitle('Figure 1',fontsize=40)\n    \n    ax1.plot(y, 'b.',alpha=0.5)\n    ax1.plot(y_true,'p--',label='True')\n    ax1.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    \n    ax1.tick_params(axis='y', labelsize=20)\n    ax1.tick_params(axis='x', labelsize=20)\n    \n    ax2.plot(y, 'b.',alpha=0.5)\n    ax2.plot(y_true,'p--',label='True')\n    ax2.plot(yhat,label='y hat')\n    ax2.legend(fontsize=20,loc='upper left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=20)\n    ax2.tick_params(axis='x', labelsize=20)\n    \n    ax3.plot((fbar**2)) # periodogram \n    ax3.plot((fbar_threshed**2)) \n    ax3.tick_params(axis='y', labelsize=20)\n    ax3.tick_params(axis='x', labelsize=20)\n    ax3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n    \n    ax4.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \n    ax4.plot(range(20, 80),(fbar_threshed**2)[20:80]) \n    ax4.set_xticks(range(20, 81, 10))\n    ax4.set_xticklabels(range(20, 81, 10))\n    # ax4.set_xticklabels(['20','40','60'])\n    ax4.tick_params(axis='y', labelsize=20)\n    ax4.tick_params(axis='x', labelsize=20)\n\n\n\n\n\n\n\n\n\nfrom mpl_toolkits.axes_grid1.inset_locator import mark_inset, inset_axes\nplt.figure(figsize = (20,10))\nplt.suptitle('Figure',fontsize=40)\nax = plt.subplot(1, 1, 1)\nax.plot(range(0,100),(fbar**2))\nax.plot((fbar_threshed**2)) \naxins = inset_axes(ax, 8, 3, loc = 1, bbox_to_anchor=(0.8, 0.8),\n                   bbox_transform = ax.figure.transFigure)\naxins.plot(range(20, 80),(fbar**2)[20:80])\naxins.plot(range(20, 80),(fbar_threshed**2)[20:80]) \naxins.set_xlim(20, 80)\naxins.set_ylim(-0.1, 7)\nmark_inset(ax, axins, loc1=4, loc2=3, fc=\"none\", ec = \"0.01\")\nax.tick_params(axis='y', labelsize=20)\nax.tick_params(axis='x', labelsize=20)\naxins.tick_params(axis='y', labelsize=15)\naxins.tick_params(axis='x', labelsize=15)\n# plt.savefig('Ebayes_Toy.png')\n\n\n\n\n\n\n\n\n\nfrom matplotlib.patches import ConnectionPatch\nfig = plt.figure(figsize=(20,10))\nplt.suptitle('Figure 1',fontsize=40)\nplot1 = fig.add_subplot(2,2,(1,2))\n\nplot1.plot(range(20, 80),(fbar**2)[20:80]) # periodogram \nplot1.plot(range(20, 80),(fbar_threshed**2)[20:80]) \nplot1.set_xticks(range(20, 81, 10))\nplot1.set_xticklabels(range(20, 81, 10))\nplot1.tick_params(axis='y', labelsize=20)\nplot1.tick_params(axis='x', labelsize=20)\n\nplot3 = fig.add_subplot(2,2,(3,4)) \n\nplot3.plot((fbar**2)) # periodogram \nplot3.plot((fbar_threshed**2)) \nplot3.tick_params(axis='y', labelsize=20)\nplot3.tick_params(axis='x', labelsize=20)\nplot3.axvspan(20, 80, facecolor='gray', alpha=0.2)\n\n# plot3.fill_between((20, 80), 10, 60, facecolor= \"red\", alpha = 0.2)\nconn1 = ConnectionPatch(xyA = (20, -0.1), coordsA=plot1.transData,\n                       xyB=(20, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn1)\nconn2 = ConnectionPatch(xyA = (79, -0.1), coordsA=plot1.transData,\n                       xyB=(80, 0), coordsB=plot3.transData, color = 'black')\nfig.add_artist(conn2)\nplt.show()\n\n\n\n\n\n\n\n\n\n\nIn article\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\n%load_ext rpy2.ipython\n\n\n%%R\nlibrary(GNAR)\nlibrary(igraph)\n\nR[write to console]: Loading required package: igraph\n\nR[write to console]: \nAttaching package: ‘igraph’\n\n\nR[write to console]: The following objects are masked from ‘package:stats’:\n\n    decompose, spectrum\n\n\nR[write to console]: The following object is masked from ‘package:base’:\n\n    union\n\n\nR[write to console]: Loading required package: wordcloud\n\nR[write to console]: Loading required package: RColorBrewer\n\n\n\n\nimport rpy2\n\n\nfrom rpy2.robjects.packages import importr\n\n\nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n#import rpy2\n#import rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector\nimport rpy2.robjects as robjects\nfrom rpy2.robjects.packages import importr\nimport rpy2.robjects.numpy2ri as rpyn\nGNAR = importr('GNAR') # import GNAR \n#igraph = importr('igraph') # import igraph \nebayesthresh = importr('EbayesThresh').ebayesthresh\n\n\n%%R\nset.seed(1)\nx &lt;- rnorm(1000) + sample(c( runif(25,-7,7), rep(0,975)))\n\n\\(X_i\\)에서 \\(\\mu_i\\) 추출 가능하는 것을 증명할 예제\n\n%%R\n# png(\"Ebayes_plot1.png\", width=1600, height=800)\npar(mfrow=c(1,2))\npar(cex.axis=2) \npar(cex.lab=2)\nplot(x, type='l', xlab=\"Observed data\", ylab=\"\")\nplot(ebayesthresh(x, sdev=1),type='l', xlab=\"Estimate\", ylab=\"\")\n# dev.off()\n\n\n\n\n\n\n\n\n\nimport itstgcn\n\n\nitstgcn.make_Psi(T)\n\narray([[ 0.07106691, -0.10050378,  0.10050378, ..., -0.10050378,\n        -0.10050378,  0.07106691],\n       [ 0.10050378, -0.14206225,  0.14184765, ...,  0.14184765,\n         0.14206225, -0.10050378],\n       [ 0.10050378, -0.14184765,  0.14099032, ..., -0.14099032,\n        -0.14184765,  0.10050378],\n       ...,\n       [ 0.10050378,  0.14184765,  0.14099032, ...,  0.14099032,\n        -0.14184765, -0.10050378],\n       [ 0.10050378,  0.14206225,  0.14184765, ..., -0.14184765,\n         0.14206225,  0.10050378],\n       [ 0.07106691,  0.10050378,  0.10050378, ...,  0.10050378,\n        -0.10050378, -0.07106691]])\n\n\ndef trim(f):\n    f = np.array(f)\n    if len(f.shape)==1: f = f.reshape(-1,1)\n    T,N = f.shape\n    Psi = make_Psi(T)\n    fbar = Psi.T @ f # apply dft \n    fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)\n    fhat = Psi @ fbar_threshed # inverse dft \n    return fhat\n\nplt.plot(y)\n\n\n\n\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T).T@y)\n\n\n\n\n\n\n\n\n\nplt.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\n\n\n\n\nplt.plot(itstgcn.make_Psi(T)@ebayesthresh(FloatVector(itstgcn.make_Psi(T).T@y)))\n\n\n\n\n\n\n\n\n\n_T = 1000\n\n\n_t = np.arange(_T)/_T * 10\n\n\n_x = 1.5*np.sin(2*_t)+2*np.random.rand(_T)+1.5*np.sin(4*_t)+1.5*np.sin(8*_t)\nplt.plot(_x)\n\n\n\n\n\n\n\n\n\nimport itstgcn\n\n\nclass Eval_csy:\n    def __init__(self,learner,train_dataset):\n        self.learner = learner\n        # self.learner.model.eval()\n        try:self.learner.model.eval()\n        except:pass\n        self.train_dataset = train_dataset\n        self.lags = self.learner.lags\n        rslt_tr = self.learner(self.train_dataset) \n        self.X_tr = rslt_tr['X']\n        self.y_tr = rslt_tr['y']\n        self.f_tr = torch.concat([self.train_dataset[0].x.T,self.y_tr],axis=0).float()\n        self.yhat_tr = rslt_tr['yhat']\n        self.fhat_tr = torch.concat([self.train_dataset[0].x.T,self.yhat_tr],axis=0).float()\n\n\n_node_ids = {'node1':0,'node2':1}\n\n_FX1 = np.stack([_x,_x],axis=1).tolist()\n\n_edges1 = torch.tensor([[0,1]]).tolist()\n\ndata_dict1 = {'edges':_edges1, 'node_ids':_node_ids, 'FX':_FX1}\n\ndata1 = pd.DataFrame({'x':_x,'x1':_x,'xer':_x,'xer1':_x})\n\n\nloader1 = itstgcn.DatasetLoader(data_dict1)\n\n\ndataset = loader1.get_dataset(lags=2)\n\n\nmindex = itstgcn.rand_mindex(dataset,mrate=0.7)\ndataset_miss = itstgcn.miss(dataset,mindex,mtype='rand')\n\n\ndataset_padded = itstgcn.padding(dataset_miss,interpolation_method='linear')\n\n\nlrnr = itstgcn.StgcnLearner(dataset_padded)\n\n\nlrnr.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor = Eval_csy(lrnr,dataset_padded)\n\n\nlrnr_2 = itstgcn.ITStgcnLearner(dataset_padded)\n\n\nlrnr_2.learn(filters=16,epoch=10)\n\n10/10\n\n\n\nevtor_2 = Eval_csy(lrnr_2,dataset_padded)\n\nPsi\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fst.pdf', format='pdf')\n\n\n\n\n\n\n\n\nfourier transform\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem(itstgcn.make_Psi(_T).T@np.array(_x),linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd.pdf', format='pdf')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(itstgcn.make_Psi(_T).T@np.array(_x),'-',color='C1',label='Fourier Transform',lw=3)\n    ax1.stem((itstgcn.make_Psi(_T).T@np.array(_x))[:100],linefmt='C1-',basefmt='k-',label='Fourier Transform')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_snd_zin.pdf', format='pdf')\n\n\n\n\n\n\n\n\nEbayesthresh/trim\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd.pdf', format='pdf')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # ax1.plot(ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='EbayesThresh',lw=3)\n    ax1.stem((ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))))[:100],linefmt='C1-',basefmt='k-',label='EbayesThresh')\n    ax1.legend(fontsize=40,loc='upper right',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\nplt.savefig('Ebayes_trd_zout.pdf', format='pdf')\n\n\n\n\n\n\n\n\nfhat\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    ax1.plot(_x,'k--',label='Observed Data',lw=3,alpha=0.3)\n    ax1.plot(itstgcn.make_Psi(_T)@ebayesthresh(FloatVector(itstgcn.make_Psi(_T).T@np.array(_x))),'-',color='C1',label='Inverse Fourier Transform',lw=5)\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n    ax1.set_ylim(-6,6)\nplt.savefig('Ebayes_fth.pdf', format='pdf')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax1 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax1.plot(data1['x'][:],'-',color='C3',label='Complete Data')\n    ax1.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax1.tick_params(axis='y', labelsize=40)\n    ax1.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_fst.png')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax2 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax2.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax2.plot(torch.cat([torch.tensor(data1['x'][:4]),torch.tensor(dataset_miss.targets).reshape(-1,2)[:,0]],dim=0),'--o',color='C3',label='Observed Data',markersize=15)\n    ax2.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax2.tick_params(axis='y', labelsize=40)\n    ax2.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_snd.png')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax3 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)    \n    ax3.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax3.plot(evtor_2.f_tr[:,0],'--o',color='C3',alpha=0.8,label='Interpolarion')\n    ax3.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax3.tick_params(axis='y', labelsize=40)\n    ax3.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_3rd.png')\n\n\n\n\n\n\n\n\n\nwith plt.style.context('seaborn-white'):\n    fig, ax4 = plt.subplots(figsize=(40,15))\n    # fig.suptitle('Figure 1(node 1)',fontsize=40)\n    ax4.plot(data1['x'][:],'--',color='C5',alpha=0.5,label='Complete Data')\n    ax4.plot(evtor.fhat_tr[:,0],color='brown',lw=3,label='STGCN')\n    ax4.plot(evtor_2.fhat_tr[:,0],color='blue',lw=3,label='ITSTGCN')\n    # ax4.plot(138, -1.2, 'o', markersize=230, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(220, -1.5, 'o', markersize=200, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(290, -1.2, 'o', markersize=310, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    # ax4.plot(455, -0.9, 'o', markersize=280, markerfacecolor='none', markeredgecolor='red',markeredgewidth=3)\n    ax4.legend(fontsize=40,loc='lower left',facecolor='white', frameon=True)\n    ax4.tick_params(axis='y', labelsize=40)\n    ax4.tick_params(axis='x', labelsize=40)\n# plt.savefig('node1_4th_1.png')"
  },
  {
    "objectID": "posts/3_Researches/GODE/2023-07-01-graph_spectral_domain.html",
    "href": "posts/3_Researches/GODE/2023-07-01-graph_spectral_domain.html",
    "title": "Graph and Spectral domain",
    "section": "",
    "text": "Graph domain에서 Spectral domain으로, 아니면 그 반대로\n\n\ngraph Lebesgue decomposition theorem\n\\[F = F_{ac} + F_{sc} + F_{pp}\\]\n\n\\(F\\)가 미분 가능하다는 말은 \\(p\\)1이 존재하다는 말이 된다. 즉, \\(F = p\\)\n\\(y\\)가 weakly stationary하다 \\(\\to\\) \\(p\\)가 존재한다. \\(\\to\\) \\(F\\)가 미분가능하다. \\(\\to\\) \\(F_{sc} = 0\\)이다.\nWold representation theorem2에 따라 임의의 시계열 \\(y_t\\)는 deterministic term(predictable term)3과 stocastic term4으로 나눌 수 있고, 이 때 stocastic term은 무한 차수의 MA로 나타낼 수 있다.\n\n연구에서 \\(V^H y_t = V^H \\text{결정적 성분} + V^H \\text{확률적 성분}\\)\n확률적 성분을 무한차수의 MA는 GFT하면 \\(p_{ac}\\)가 나온다.5\n\n\n1 periodogram2 time domain에서만 정의된3 결정적 성분4 확률적 성분5 이미 알려진 사실..\\[p = p_{ac} + p_{pp}\\]\n\\(F\\)가 증가함수 일때, \\(F_{sc}\\)는 라돈니코딤 도함수(미분)에 의해 \\(F_{sc}\\)이 없어진다.6\n6 0이 되기 때문에\n\nAppendix 1 르벡분해정리\n- Thm: 분포함수의 정의7를 만족하는 임의의 \\(F\\)는 항상 아래와 같이 분해가능하다.\n7 증가함수\\[F = F_{ac}+F_{pp}+F_{sing}\\]\n여기에서 \\(F_{ac}\\)는 르벡메져에 대하여 절대연속이고 \\(F_{pp}\\)는 카운팅메져에 대하여 절대연속이다. 따라서 \\(F_{ac}\\)와 \\(F_{pp}\\)는 각각 르벡메져와 카운팅메져에 대응하는 밀도함수가 존재한다. \\(F_{sing}\\)는 칸토어분포와 같이 밀도함수가 존재하지 않는 경우이다.\n\n여기에서 \\(ac\\)는 absolutely continuous 의 약자이고, \\(pp\\) pure point 의 약자이며 \\(sing\\)은 singular continuous 약자이다.\n\n- 의미: \\(F_{ac}\\)는 우리가 일반적으로 생각하는 singular하지 않은 연속함수를 상상하면 된다.8 \\(F_{pp}\\)는 완벽한 불연속이며 오직 jump를 통해서만 증가하는 함수라 생각하면 된다. 즉 우리가 익숙한 이산형확률변수의 cdf를 상상하면 된다.\n8 칸토어처럼 이상한 연속함수 말고 상식적인 수준의 연속함수라는 의미- 이론: \\(F_{pp}\\)는 기껏해야 countable한 불연속점을 가진다. (jump 하는 point는 countable이라는 의미, 결국 이산형확률변수의 support는 countable이라는 의미)\n- 이론: 분포함수 정의를 만족하는 임의의 \\(F\\)가 아래와 같다면\n\\[F=F_{ac}\\]\n\\(F\\)에 대응하는 연속형 확률변수 \\(X\\)가 존재하고 그에 대응하는 pdf가 존재한다.\n- 이론: 분포함수 정의를 만족하는 임의의 \\(F\\)가 아래와 같다면\n\\[F=F_{pp}\\]\n\\(F\\)에 대응하는 이산형 확률변수 \\(X\\)가 존재하고 그에 대응하는 (일반화된) pdf 혹은 pmf가 존재한다.\n- 이론: 분포함수 정의를 만족하는 임의의 \\(F\\)가 아래와 같다면\n\\[F=F_{ac}+F_{pp}\\]\n\\(F\\)에 대응하는 혼합형 확률변수 \\(X\\)가 존재하고 그에 대응하는 (일반화된) pdf가 존재한다.\n\n\nAppendix 2 라돈니코딤 정리\n- 이론: 분포함수 \\(F_X:\\mathbb{R} \\to [0,1]\\)가 (르벡메져에 대하여) 절대연속이라면 아래를 만족하는 함수 \\(f_X:\\mathbb{R} \\to \\mathbb{R}^+\\)가 존재한다.\n\\[F_X = \\int_{(-\\infty,x]}f_Xd\\lambda\\]\n여기에서 함수 \\(f_X\\)를 \\(F_X\\)의 밀도함수 (density function) 이라고 한다. 일반적으로 밀도함수 \\(f_X\\)는 유일하지 않지만, 르벡측도로 재었을때 0인 집합을 제외한 부분에서는 유일하게 결정된다. (요약: 분포함수 \\(F_X\\)가 절대연속이면 밀도함수 \\(f_X\\)가 존재하고, 거의 유일함)\n\n위에서 “르벡측도로 재었을때 0인 집합을 제외한 부분에서는 유일하게 결정된다”라는 부분은 “르벡메져 \\(\\lambda\\)에 대하여 거의 유일하다” 라고 이해해도 무방. 엄밀하게 쓰면 “분포함수 \\(F_X\\)가 있다면 밀도함수의 정의하는 만족하는 함수가 반드시 하나는 존재한다. 만약에 두 함수 \\(f\\)와 \\(g\\)가 모두 밀도함수의 정의를 만족한다면 ‘\\(f=g\\) a.e. with respect to \\(\\lambda\\)’ 가 성립한다.” 와 같은 식으로 쓸 수 있음.\n\n\n위에서 \\(f\\)의 공역이 \\(\\mathbb{R}^+\\)인 이유는 \\(F_X\\)가 증가함수라서..\n\n- Thm (라돈니코딤 정리)(Durrett 2019, Thm A.4.8.): 가측공간 \\((S,{\\cal S})\\)를 고려하자. 그리고 \\(\\mu\\)와 \\(\\lambda\\)가 \\((S,{\\cal S})\\)에서의 \\(\\sigma\\)-finite measure 라고 하자. 만약에 \\(\\mu &lt;&lt; \\lambda\\) 이라면 아래를 만족하는 가측함수 \\(f:(S,{\\cal S}) \\to (\\mathbb{R}^+,{\\cal R}^+)\\)가 거의 유일하게 (w.r.t. \\(\\lambda\\)) 존재한다.\n\nDurrett, Rick. 2019. Probability: Theory and Examples. Vol. 49. Cambridge university press.\n\\[\\forall B \\in {\\cal S}:~ \\mu(B) = \\int_B f d\\lambda.\\]\n여기에서 \\(f\\)를 Radon-Nikodym derivative of \\(\\mu\\) w.r.t. \\(\\lambda\\) 라고 하며, 이러한 의미에서 \\(f=\\frac{d\\mu}{d\\lambda}\\)와 같이 표현하기도 한다."
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-09-02-CAM_original.html",
    "href": "posts/3_Researches/HCAM/2023-09-02-CAM_original.html",
    "title": "[CAM]Original CAM",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\n\nimport\n\nimport torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\n\n원본 CAM\n\n# os.mkdir(\"original_pet\")\n\n\nfor i in range(len(path.ls())) :\n    img = PILImage.create(get_image_files(path)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    (w, h) = (img.shape[0], img.shape[1])\n    # a = random.uniform(0, w*0.7)\n    # b = random.uniform(0, h*0.9)\n    shape = [(a, b), (a+100, b+50)]\n    # font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.08))\n    name = str(list(path.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if name[0].isupper() == True :\n        img1 = ImageDraw.Draw(img)  \n        # img1.rectangle(shape, fill =\"white\", outline =\"black\")\n        # ImageDraw.Draw(img).text((a, b), 'CAT', (0,0,0), font=font)\n        img.save(\"original_pet/\"+name)\n    else: \n        img1 = ImageDraw.Draw(img)  \n        # img1.rectangle(shape, fill =\"black\", outline =\"black\")\n        # ImageDraw.Draw(img).text((a, b), 'DOG', (255,255,255), font=font)\n        img.save(\"original_pet/\"+name)\n\n\npath_o=Path('original_pet')   #랜덤박스넣은사진\n\n\nfiles_o=get_image_files(path_o)\n\n\ndls_o=ImageDataLoaders.from_name_func(path_o,files_o,label_func,item_tfms=Resize(512)) \n\n\nlrnr_o1=cnn_learner(dls_o,resnet34,metrics=error_rate)\nlrnr_o1.fine_tune(1)\n\n\nnet_o1=lrnr_o1.model[0]\nnet_o2=lrnr_o1.model[1] \n\n\nnet_o2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet_o=torch.nn.Sequential(net_o1,net_o2)\n\n\nlrnr_o2=Learner(dls_o,net_o,metrics=accuracy) \n\n\nlrnr_o2.fine_tune(10) \n\n\ninterp_o = ClassificationInterpretation.from_learner(lrnr_o2)\ninterp_o.plot_confusion_matrix()\n\n\nx_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[7389])]))\n\n\ncamimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\n\n\n# 서연 수정 code\nfig, (ax1,ax2) = plt.subplots(1,2) \n# \ndls_o.train.decode((x_o,))[0].squeeze().show(ax=ax1)\nax1.imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\n#\ndls_r.train.decode((x_o,))[0].squeeze().show(ax=ax2)\nax2.imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,511,511,0),interpolation='bilinear',cmap='bone')\nfig.set_figwidth(8)            \nfig.set_figheight(8)\nfig.tight_layout()\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n        camimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x_o).squeeze())\n        a_o,b_o = net_r(x_o).tolist()[0]\n        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o)) \n        if catprob&gt;dogprob: \n            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(camimg_o[0].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            dls_o.train.decode((x_o,))[0].squeeze().show(ax=ax[i][j])\n            ax[i][j].imshow(camimg_o[1].to(\"cpu\").detach(),alpha=0.7,extent=(0,512,512,0),interpolation='bilinear',cmap='bone')\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\nfig, ax = plt.subplots(5,5) \nk=0 \nfor i in range(5):\n    for j in range(5): \n        x_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[k])]))\n        camimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\n        a_o,b_o = net_o(x_o).tolist()[0]\n        catprob, dogprob = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\n        if catprob&gt;dogprob: \n            test=camimg_o[0]-torch.min(camimg_o[0])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"cat(%s)\" % catprob.round(5))\n        else: \n            test=camimg_o[1]-torch.min(camimg_o[1])\n            A1=torch.exp(-0.1*test)\n            X1=np.array(A1.to(\"cpu\").detach(),dtype=np.float32)\n            Y1=torch.Tensor(cv2.resize(X1,(512,512),interpolation=cv2.INTER_LINEAR))\n            x1=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1\n            (x1*0.25).squeeze().show(ax=ax[i][j])\n            ax[i][j].set_title(\"dog(%s)\" % dogprob.round(5))\n        k=k+1 \nfig.set_figwidth(16)            \nfig.set_figheight(16)\nfig.tight_layout()\n\n\n.mat파일 있나 확인\n\n\nfor i in range(len(path_o.ls())) :\n    img = PILImage.create(get_image_files(path_o)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    name = str(list(path_o.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if fname!=\"jpg\" : \n        print(name)\n    else : pass\n\n\nx_o, = first(dls_o.test_dl([PILImage.create(get_image_files(path_o)[1])]))\ncamimg_o = torch.einsum('ij,jkl -&gt; ikl', net_o2[2].weight, net_o1(x).squeeze())\na_o,b_o = net_o(x_o).tolist()[0]\ncatprob_o, dogprob_o = np.exp(a_o)/ (np.exp(a_o)+np.exp(b_o)) ,  np.exp(b_o)/ (np.exp(a_o)+np.exp(b_o))\nif catprob_o&gt;dogprob_o: \n    test_o=camimg_o[0]-torch.min(camimg_o[0])\n    A1_o=torch.exp(-0.01*test_o)\n    X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n    Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n    x1_o=x_o.squeeze().to('cpu')*Y1_o-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n    (x1_o*0.25).squeeze().show()\nelse: \n        test_o=camimg_o[1]-torch.min(camimg_o[1])\n        A1_o=torch.exp(-0.01*test_o)\n        X1_o=np.array(A1_o.to(\"cpu\").detach(),dtype=np.float32)\n        Y1_o=torch.Tensor(cv2.resize(X1_o,(512,512),interpolation=cv2.INTER_LINEAR))\n        x1_o=x_o.squeeze().to('cpu')*Y1-torch.min(x_o.squeeze().to('cpu'))*Y1_o\n        (x1_o*0.25).squeeze().show()\n\n\n# #저장 참고\n# np_arr = np.array(tensor, dtype=np.uint8)\n# img = PIL.Image.fromarray(np_arr)\n# img.save('path')\n\n\n# name = str(list(path.ls())[1]).split('/')[-1]\n# res1=(x1*0.35).squeeze()\n# res1.show()\n# save_image(res1, \"pet3_mode1_res/\"+name)\n#res1.save(\"pet3_mode1_res/\"+name)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-09-14-CAM_Image_download.html",
    "href": "posts/3_Researches/HCAM/2023-09-14-CAM_Image_download.html",
    "title": "[CAM]Image Download",
    "section": "",
    "text": "https://seoyeonc.github.io/chch/cnn/feature%20extraction/big%20data%20analysis/2022/01/11/bd_9주차.html\nhttps://seoyeonc.github.io/chch/cam/2022/01/10/bd-8주차_1.html\n\nimport\n\nimport torch \nfrom fastai.vision.all import *\nimport cv2\nimport numpy as np\nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import ImageDraw\nfrom PIL import ImageFont\nfrom PIL import ImageFile\nfrom PIL import Image\nImageFile.LOAD_TRUNCATED_IMAGES = True\nfrom torchvision.utils import save_image\nimport os\n\n\nimport rpy2\nimport rpy2.robjects as ro \nfrom rpy2.robjects.vectors import FloatVector \nfrom rpy2.robjects.packages import importr\n\n\ndef label_func(f):\n    if f[0].isupper():\n        return 'cat' \n    else: \n        return 'dog' \n\n\n\nOriginal Image로 학습하는 과정\n\npath=untar_data(URLs.PETS)/'images'\n\n\n# path.ls()\n\n\nfiles=get_image_files(path)\n\n\ndls=ImageDataLoaders.from_name_func(path,files,label_func,item_tfms=Resize(512)) \n\n\nlrnr=cnn_learner(dls,resnet34,metrics=error_rate)\nlrnr.fine_tune(1)\n\n\nnet1=lrnr.model[0]\nnet2=lrnr.model[1] \n\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), \n    torch.nn.Flatten(),\n    torch.nn.Linear(512,out_features=2,bias=False))\n\n\nnet=torch.nn.Sequential(net1,net2)\n\n\nlrnr2=Learner(dls,net,metrics=accuracy) \n\n\nlrnr2.fine_tune(10) \n\n\ninterp = ClassificationInterpretation.from_learner(lrnr2)\ninterp.plot_confusion_matrix()\n\n\ninterp.print_classification_report()\n\n\n\n랜덤박스가 들어간 개 고양이 그림 다운로드\n\npath=untar_data(URLs.PETS)/'images'\n\n\nif str(list(path.ls())[103]).split('/')[-1].split('.')[-1]==\"jpg\" :\n    print(\"jpg\")\n#name=str(list(path.ls())[i]).split('/')[-1]\n\n\npath.ls()\n\n\nfor i in range(7393) :\n    img = PILImage.create(get_image_files(path)[i])\n    img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n    name = str(list(path.ls())[i]).split('/')[-1]\n    fname = name.split('.')[-1]\n    if fname!=\"jpg\" : \n        print(name)\n    else : pass\n\n.mat 파일 같은 이상한 거 삭제\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat\")\n\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat\")\n\n\n# os.remove(r\"/home/csy/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat\")\n\n\n# os.mkdir(\"random_pet_one\")\n\n\n# for i in range(len(path.ls())) :\n#     img = PILImage.create(get_image_files(path)[i])\n#     img = img.resize([512,512], resample=None, box=None, reducing_gap=None)\n#     (w, h) = (img.shape[0], img.shape[1])\n#     a = random.uniform(0, w*0.7)\n#     b = random.uniform(0, h*0.9)\n#     shape = [(a, b), (a+85, b+85)]\n#     font = ImageFont.truetype(\"DejaVuSans.ttf\", round(h*0.075))\n#     name = str(list(path.ls())[i]).split('/')[-1]\n#     fname = name.split('.')[-1]\n#     if name[0].isupper() == True :\n#         img1 = ImageDraw.Draw(img)  \n#         img1.rectangle(shape, fill =\"white\", outline =\"black\")\n#         ImageDraw.Draw(img).text((a+5, b+15), 'Cat', (0,0,0), font=font)\n#         img.save(\"random_pet_one/\"+name)\n#     else: \n#         img1 = ImageDraw.Draw(img)  \n#         img1.rectangle(shape, fill =\"black\", outline =\"black\")\n#         ImageDraw.Draw(img).text((a+5, b+15), 'Dog', (255,255,255), font=font)\n#         img.save(\"random_pet_one/\"+name)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html",
    "title": "Regular Graph",
    "section": "",
    "text": "summary\n모든 노드가 동일한 degree를 갖는 그래프, degree matrix가 \\(I\\)나 \\(kI\\)로 나타낼 수 있는 그래프\ndegree matrix: the degree matrix of an undirected graph is a diagonal matrix which contains information about the degree of each vertex—that is, the number of edges attached to each vertex."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-1",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-1",
    "title": "Regular Graph",
    "section": "0-regular graph",
    "text": "0-regular graph\n\n참고 아래도 동일 차수이므로 regular graph\n\n\nw = np.array([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\nDegree matrix = \\(I\\)\n\n\nD\n\narray([[1., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])\n\n\n\nlst = []\nfor i in range(5):\n    for j in range(5):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-2",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-2",
    "title": "Regular Graph",
    "section": "1-regular graph",
    "text": "1-regular graph\n\nw = np.array([\n       [0., 1., 0., 0., 0., 0.],\n       [1., 0., 0., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 0., 0., 1.],\n       [0., 0., 0., 0., 1., 0.]])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\nDegree matrix = \\(I\\)\n\n\nD\n\narray([[1., 0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0., 0.],\n       [0., 0., 1., 0., 0., 0.],\n       [0., 0., 0., 1., 0., 0.],\n       [0., 0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 0., 1.]])\n\n\n\nlst = []\nfor i in range(6):\n    for j in range(6):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-3",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-3",
    "title": "Regular Graph",
    "section": "2-regular graph",
    "text": "2-regular graph\n\nw = np.array([\n       [0., 1., 1., 0., 0., 0.],\n       [1., 0., 1., 0., 0., 0.],\n       [1., 1., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 1., 1.],\n       [0., 0., 0., 1., 0., 1.],\n       [0., 0., 0., 1., 1., 0.]])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\nDegree matrix = \\(2I\\)\n\n\nD\n\narray([[2., 0., 0., 0., 0., 0.],\n       [0., 2., 0., 0., 0., 0.],\n       [0., 0., 2., 0., 0., 0.],\n       [0., 0., 0., 2., 0., 0.],\n       [0., 0., 0., 0., 2., 0.],\n       [0., 0., 0., 0., 0., 2.]])\n\n\n\nlst = []\nfor i in range(6):\n    for j in range(6):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-4",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Regular Graph.html#regular-graph-4",
    "title": "Regular Graph",
    "section": "3-regular graph",
    "text": "3-regular graph\n\nw = np.array([\n       [0., 1., 1., 0., 0., 1.],\n       [1., 0., 1., 1., 0., 0.],\n       [1., 1., 0., 0., 1., 0.],\n       [0., 1., 0., 0., 1., 1.],\n       [0., 0., 1., 1., 0., 1.],\n       [1., 0., 0., 1., 1., 0.]])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\nDegree matrix = \\(3I\\)\n\n\nD\n\narray([[3., 0., 0., 0., 0., 0.],\n       [0., 3., 0., 0., 0., 0.],\n       [0., 0., 3., 0., 0., 0.],\n       [0., 0., 0., 3., 0., 0.],\n       [0., 0., 0., 0., 3., 0.],\n       [0., 0., 0., 0., 0., 3.]])\n\n\n\nlst = []\nfor i in range(6):\n    for j in range(6):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "",
    "text": "using LinearAlgebra, FFTW"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#cyclic-shfit-operator-bf-b",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#cyclic-shfit-operator-bf-b",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Cyclic shfit operator \\({\\bf B}\\)",
    "text": "Cyclic shfit operator \\({\\bf B}\\)\nThe matrix \\({\\bf B}\\) representing the periodic shift is\n\nB= [0 0 0 0 1\n    1 0 0 0 0 \n    0 1 0 0 0\n    0 0 1 0 0\n    0 0 0 1 0]\n\n5×5 Matrix{Int64}:\n 0  0  0  0  1\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n\n\nThis matrix is the cyclic shift.\nnote: \\({\\bf B}\\) is orthogonal matrix.\n\nB'B\n\n5×5 Matrix{Int64}:\n 1  0  0  0  0\n 0  1  0  0  0\n 0  0  1  0  0\n 0  0  0  1  0\n 0  0  0  0  1\n\n\n(ex1) Define \\({\\bf s}\\) as\n\ns = [1,2,3,4,5]\ns\n\n5-element Vector{Int64}:\n 1\n 2\n 3\n 4\n 5\n\n\nObserve that\n\nB*s\n\n5-element Vector{Int64}:\n 5\n 1\n 2\n 3\n 4\n\n\n\nB^2*s\n\n5-element Vector{Int64}:\n 4\n 5\n 1\n 2\n 3\n\n\n\nB^3*s\n\n5-element Vector{Int64}:\n 3\n 4\n 5\n 1\n 2\n\n\nThus we can interprete the matrix \\({\\bf B}\\) as cyclic shift operator such that\n\\[\n{\\bf B}s_n =s_{n-1}\n\\]\nfor \\(n=1,\\dots, N-1\\) and \\({\\bf B}s_0 =s_N\\).\nnote: \\({\\bf B}\\)는 시계열에서 다루는 backshift operator 와 비슷함."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\nThe matrix \\({\\bf B}\\) can be expressed as\n\\({\\bf B}={\\bf DFT}^\\ast \\cdot {\\bf \\Lambda} \\cdot {\\bf DFT}\\)\nwhere \\({\\bf DFT}\\) is unitary and symmetric matrix and \\(\\bf \\Lambda\\) is diagonal matrix.\n\nλ, Ψ = eigen(B)\n\nEigen{ComplexF64, ComplexF64, Matrix{ComplexF64}, Vector{ComplexF64}}\nvalues:\n5-element Vector{ComplexF64}:\n -0.8090169943749472 - 0.5877852522924725im\n -0.8090169943749472 + 0.5877852522924725im\n 0.30901699437494734 - 0.9510565162951536im\n 0.30901699437494734 + 0.9510565162951536im\n  0.9999999999999998 + 0.0im\nvectors:\n5×5 Matrix{ComplexF64}:\n  0.138197+0.425325im   0.138197-0.425325im  …  0.447214+0.0im\n -0.361803-0.262866im  -0.361803+0.262866im     0.447214+0.0im\n  0.447214-0.0im        0.447214+0.0im          0.447214+0.0im\n -0.361803+0.262866im  -0.361803-0.262866im     0.447214+0.0im\n  0.138197-0.425325im   0.138197+0.425325im     0.447214+0.0im\n\n\n\nB ≈ Ψ * Diagonal(λ) * Ψ'\n\ntrue\n\n\nDefine \\({\\boldsymbol \\Psi}^\\ast={\\bf DFT}\\).\n\nDFT = Ψ'\n\n5×5 adjoint(::Matrix{ComplexF64}) with eltype ComplexF64:\n  0.138197-0.425325im  -0.361803+0.262866im  …  0.138197+0.425325im\n  0.138197+0.425325im  -0.361803-0.262866im     0.138197-0.425325im\n -0.361803-0.262866im  -0.361803+0.262866im     0.138197-0.425325im\n -0.361803+0.262866im  -0.361803-0.262866im     0.138197+0.425325im\n  0.447214-0.0im        0.447214-0.0im          0.447214-0.0im\n\n\nNote that the eigenvalues are not ordered in julia.\n\nλ[5], exp(-im* 2π/5 * 0)\n\n(0.9999999999999998 + 0.0im, 1.0 - 0.0im)\n\n\n\nλ[3], exp(-im* 2π/5 * 1)\n\n(0.30901699437494734 - 0.9510565162951536im, 0.30901699437494745 - 0.9510565162951535im)\n\n\n\nλ[1], exp(-im* 2π/5 * 2)\n\n(-0.8090169943749472 - 0.5877852522924725im, -0.8090169943749473 - 0.5877852522924732im)\n\n\n\nλ[2], exp(-im* 2π/5 * 3)\n\n(-0.8090169943749472 + 0.5877852522924725im, -0.8090169943749475 + 0.587785252292473im)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#spectral-components-and-frequencies",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#spectral-components-and-frequencies",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral components and Frequencies",
    "text": "Spectral components and Frequencies\nWe remark:\n(1) Spectral components: For \\(k = 0,1,2,\\dots, N-1\\), the \\(k\\)-th column of \\({\\bf DFT}^\\ast\\) is defined by\n\\[\\Psi_k:=\\frac{1}{\\sqrt{N}}\\begin{bmatrix} 1 \\\\ e^{j\\frac{2\\pi}{N}k} \\\\ e^{j\\frac{2\\pi}{N}2k} \\\\ e^{j\\frac{2\\pi}{N}3k} \\\\  \\dots \\\\ e^{j\\frac{2\\pi}{N}(N-1)k} \\end{bmatrix}.\\]\nNote that \\(\\Psi_k\\) can be also interpreted as \\(\\ell\\)-th eigenvector of \\({\\bf A}\\) correspoding \\(\\lambda_\\ell = e^{-j\\frac{2\\pi}{N}k}\\). Those eigenvectors\n\\[\\big\\{{\\bf 1},\\Psi_1,\\Psi_2, \\dots, \\Psi_{N-1}\\big\\}\\]\nform a complete orthonomal basis of \\(\\mathbb{C}^N\\). These vectors are called spectral components.\n(2) Frequencies: The diagonal entries of \\({\\bf \\Lambda}\\) are the eigenvalues of the time shift \\({\\bf B}\\). In Physics and in operator theory, these eigenvalues are the frequencies of the signal. In DSP it is more common to call frequencies\n\\[\\Omega_k=\\frac{-1}{2\\pi j}\\ln\\lambda_k=\\frac{-1}{2\\pi j}\\ln e^{-j \\frac{2\\pi}{N}k}=\\frac{k}{N}, \\quad k=0,1,2,\\dots,N-1.\\]\n\nThe \\(N\\) (time) frequencies \\(\\Omega_k\\) are all distinct, positive, equally spaced, and increasing from \\(0\\) to \\(\\frac{N-1}{N}\\). The spectral components are the complex exponential sinusiodal functions. For example, corresponding to the zero frequency is the DC spectral component (a vector whose entries are constant and all equal to \\(\\frac{1}{\\sqrt{N}}\\))."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft-1",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft-1",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT",
    "text": "DFT\n일반적으로 우리가 알고있는 DFT1는 아래와 같다. (이 그림은 위키피디아에서 캡쳐한 것이다)\n1 discrete Fourier transform\n\n\n그림1: 위키에서 긁어온 DFT의 정의\n\n\n즉 DFT는 임의의 신호 \\(\\{{\\bf x}_n\\}:=x_0,x_1,\\dots,x_{N-1}\\)를 적당한 규칙2에 따라서 \\(\\{{\\bf X}_k\\}:=X_0,X_1,\\dots,X_{N-1}\\)로 바꾸는 변환을 이라고 이해할 수 있다. 이때 사용되는 적당한 규칙은 구체적으로 아래의 수식을 의미한다.\n2 \\(X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\)\\[X_k = \\sum_{n=0}^{N-1}x_n\\cdot e^{-i\\frac{2\\pi}{N}kn}\\]\n그런데 매트릭스를 활용하면 위의 수식을 아래와 같이 표현할 수 있다.\n\\[\\begin{bmatrix} X_1 \\\\ X_2 \\\\ X_3 \\\\ \\dots \\\\ X_{N-1} \\end{bmatrix}\n=\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n\\end{bmatrix}\n\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3 \\\\ \\dots \\\\ x_{N-1} \\end{bmatrix}\\]\n편의상 \\({\\bf X}\\)와 \\({\\bf x}\\)를 \\(N \\times 1\\) col-vec이라고 생각하고 DFT를 아래와 같은 matrix로 정의하자.\n\\[{\\bf DFT} = \\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n그러면\n\\[{\\bf X} = {\\bf DFT} \\cdot {\\bf x}\\]\n와 같이 표현할 수 있고 \\({\\bf x}\\)에서 \\({\\bf X}\\)로 바꾸는 과정을 단순히 \\({\\bf DFT}\\)행렬을 \\({\\bf x}\\)의 왼쪽에 곱하는 과정으로 이해할 수 있다.\n(참고) 사실 아래와 같이 \\({\\bf DFT}\\)를 정의하는 버전도 있다. (둘이 혼용해서 쓰인다)\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\n예제1 아래는 위키에서 긁어온 예제이다. 이 예제를 따라가보자.\n\n\n\n그림2: 위키에서 긁어온 예제이미지\n\n\n예제를 풀기위해서 우선 아래와 같은 벡터를 선언하다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n(풀이1)\n\\(4\\times 4\\)의 크기를 가지는 DFT행렬을 선언한다.\n(step1) 아래의 매트릭스 생성\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\n_DFT\n\n4×4 Matrix{Int64}:\n 0  0  0  0\n 0  1  2  3\n 0  2  4  6\n 0  3  6  9\n\n\n(step2) _DFT의 각 원소에 함수 \\(f: x \\to \\exp(-i\\frac{2\\pi}{4}x)\\)를 취함\n\nf = x -&gt; exp(-im * (2π/4) * x)\nDFT = _DFT .|&gt; f\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n이제 \\({\\bf X}\\)를 구하면 아래와 같다.\n\nDFT * x\n\n4-element Vector{ComplexF64}:\n                   2.0 + 0.0im\n   -1.9999999999999998 - 2.0000000000000004im\n 8.881784197001252e-16 - 1.9999999999999998im\n    3.9999999999999987 + 4.000000000000001im\n\n\n위키의 답이 잘 나옴\n(풀이2)\n참고로 아래와 같이 패키지를 이용하여 구할 수도 있다.\n\nfft(x)\n\n4-element Vector{ComplexF64}:\n  2.0 + 0.0im\n -2.0 - 2.0im\n  0.0 - 2.0im\n  4.0 + 4.0im"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#inverse-dft",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#inverse-dft",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Inverse DFT",
    "text": "Inverse DFT\n앞으로는 \\({\\bf DFT}\\)를 아래와 같이 정의하자.\n\\[{\\bf DFT} = \\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 1} & e^{-i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot 2} & e^{-i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{-i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{-i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n\\({\\bf DFT}\\)행렬에는 몇 가지 특징이 있다.\n특징1: 유니터리행렬이다. 즉 \\({\\bf DFT}^\\ast \\cdot {\\bf DFT} = {\\bf DFT}^\\ast \\cdot{\\bf DFT} = {\\bf I}\\) 이다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nf = x -&gt; exp(-im * (2π/4) * x)\nDFT = _DFT .|&gt; f\nDFT # 아까의 예제의 DFT!\n\n4×4 Matrix{ComplexF64}:\n 1.0-0.0im           1.0-0.0im          …           1.0-0.0im\n 1.0-0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0-0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0-0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n\n\n\nDFT = (1/√4)*DFT # 새로운 DFT의 정의 \nDFT'DFT .|&gt; round # 유니터리행렬임을 확인!\n\n4×4 Matrix{ComplexF64}:\n  1.0+0.0im  -0.0-0.0im   0.0-0.0im   0.0-0.0im\n -0.0+0.0im   1.0+0.0im  -0.0-0.0im   0.0-0.0im\n  0.0+0.0im  -0.0+0.0im   1.0+0.0im  -0.0-0.0im\n  0.0+0.0im   0.0+0.0im  -0.0+0.0im   1.0+0.0im\n\n\n특징2: \\({\\bf DFT}\\)는 대칭행렬이다. 따라서 이 행렬의 켤레전치는 DFT의 각 원소에서 단순히 \\(i=\\sqrt{-1}\\) 대신에 \\(-i\\) 를 넣은 것과 같다.\n특징1-2를 조합하면 아래와 같이 \\({\\bf DFT}\\)에서 \\(i\\) 대신에 \\(-i\\)를 넣은 행렬이 변환 DFT를 취소시킬 수 있음을 이해할 수 있다. 3\n3 아래의 행렬은 \\({\\bf DFT}^\\ast\\) 혹은 \\({\\bf DFT}\\)의 conjugate matrix 혹은 \\({\\bf DFT}^{-1}\\)로 생각할 수 있음\\[\\frac{1}{\\sqrt{N}}\\begin{bmatrix}\n1 & 1 & 1 & \\dots & 1 \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 1} & e^{i \\frac{2\\pi}{N}\\cdot 2} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)}\\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot 2} & e^{i \\frac{2\\pi}{N}\\cdot 4} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)}\\\\\n\\dots & \\dots & \\dots & \\dots & \\dots \\\\\n1 & e^{i \\frac{2\\pi}{N}\\cdot (N-1)} & e^{i \\frac{2\\pi}{N}\\cdot 2(N-1)} & \\dots & e^{i \\frac{2\\pi}{N}\\cdot (N-1)^2}\n    \\end{bmatrix}\\]\n행렬 \\({\\bf DFT}\\)를 discrete Fourier transform으로 생각했듯이 위의 행렬을 inverse discrete Fourier transform으로 해석할 수 있다."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft의-또-다른-정의",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#dft의-또-다른-정의",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "DFT의 또 다른 정의",
    "text": "DFT의 또 다른 정의\n이번에는 \\({\\bf DFT}\\)에 대한 다른 정의를 생각해보자. 우선 아래와 같은 행렬 \\({\\bf B}\\)를 고려하자.\n\nB= [0 0 0 1 \n    1 0 0 0 \n    0 1 0 0\n    0 0 1 0]\n\n4×4 Matrix{Int64}:\n 0  0  0  1\n 1  0  0  0\n 0  1  0  0\n 0  0  1  0\n\n\n이것은 길이가 4인 임의의 column vector를 아래로 한칸씩 이동시키는 매트릭스이다.\n\nx = [1, 2-im, -im, -1+2im]\n\n4-element Vector{Complex{Int64}}:\n  1 + 0im\n  2 - 1im\n  0 - 1im\n -1 + 2im\n\n\n\nB*x # 아래로 한칸이동 \n\n4-element Vector{Complex{Int64}}:\n -1 + 2im\n  1 + 0im\n  2 - 1im\n  0 - 1im\n\n\n\nB^2*x # 아래로 두칸이동, B^2*x = B*(Bx) 이므로 \n\n4-element Vector{Complex{Int64}}:\n  0 - 1im\n -1 + 2im\n  1 + 0im\n  2 - 1im\n\n\n한편 이 매트릭스 \\({\\bf B}\\)는 아래와 같이 고유분해가 가능하다.\n\\[ {\\bf B} = {\\bf \\Psi} {\\bf \\Lambda} {\\bf \\Psi}^\\ast\\]\n\n\\({\\bf \\Psi}\\): make \\(\\frac{1}{\\sqrt{N}}[e^{\\sqrt{-1} \\frac{2\\pi}{N} ij}~\\text{ for }~ i=0,1,2,\\dots,N-1~\\text{ for }~j=0,1,2,\\dots,N-1]\\) and apply reshape function with \\((N,N)\\).\n\\({\\bf \\Lambda}\\): make \\([e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}~\\text{ for }~ i=0,1,2\\dots,N-1]\\) and apply Diagonal function.\n\n\nN = 4 \nλ = [exp(-im * (2π/N) *i) for i in 0:(N-1)]\nΛ = Diagonal(λ)\n_Ψ = 1/√N *[exp(im * (2π/N) * i*j) for i in 0:(N-1) for j in 0:(N-1)]\nΨ = reshape(_Ψ, (N,N))\nB ≈ Ψ * Λ * Ψ'\n\ntrue\n\n\n그런데 위에서 정의된 \\({\\bf \\Psi}^\\ast\\)는 우리가 그전에 정의하였던 \\({\\bf DFT}\\)의 행렬과 같다.\n\n_DFT = reshape([i*j for i in 0:3 for j in 0:3], (4,4))\nDFT = _DFT .|&gt; (x -&gt; exp(-im * (2π/4) * x)) \nDFT = DFT * 1/√N\n\n4×4 Matrix{ComplexF64}:\n 0.5-0.0im           0.5-0.0im          …           0.5-0.0im\n 0.5-0.0im   3.06162e-17-0.5im             -9.18485e-17+0.5im\n 0.5-0.0im          -0.5-6.12323e-17im             -0.5-1.83697e-16im\n 0.5-0.0im  -9.18485e-17+0.5im              2.75546e-16-0.5im\n\n\n\nΨ' == DFT \n\ntrue\n\n\n결국 요약하면 길이가 \\(N\\)인 신호의 \\({\\bf DFT}\\)행렬은 아래의 과정으로 구할 수 있음을 알 수 있다.\n\nForward operator \\({\\bf A}\\)를 정의한다.\n\\({\\bf A}\\)의 고유벡터행렬 \\({\\bf \\Psi}\\)을 구한다. 4\n\\({\\bf \\Psi}\\)의 conjugate transpose matrix \\({\\bf \\Psi}^\\ast\\) 를 구한다. 이것이 \\({\\bf DFT}\\) matrix 이다. 5\n\n4 고유벡터행렬은 고유값 \\(e^{-\\sqrt{-1}\\frac{2\\pi}{N}i}\\)에 의하여 정렬되어 있어야 함.5 사실 이미 대칭행렬이므로 conjugate matrix만 구하면 된다."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#spectral-component-and-frequencies",
    "href": "posts/2_Studies/GRAPH/2022-12-24-Chap-8.3.html#spectral-component-and-frequencies",
    "title": "[CGSP] Chap 8.3: Discrete Fourier Transform",
    "section": "Spectral component and Frequencies",
    "text": "Spectral component and Frequencies\n\\({\\bf A}\\)의 고유벡터 \\({\\bf \\Psi}\\)의 각 column을 spectral component라고 부른다.\n\nψ₁ = Ψ[:,1] # ψ₁ is first spectral component \nψ₂ = Ψ[:,2] # ψ₂ is seconde spectral component \nψ₃ = Ψ[:,3] # ψ₃ is third spectral component \nψ₄ = Ψ[:,4] # ψ₄ is last spectral component\n\n그리고 아래와 같은 수열을 \\(\\Omega_{k}=\\frac{k}{N}\\)을 frequency 라고 부른다.\n\nN=4 \nΩ = [k/N for k in 0:(N-1)]\nΩ\n\n4-element Vector{Float64}:\n 0.0\n 0.25\n 0.5\n 0.75"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-01-15-Chap-12.4.html",
    "href": "posts/2_Studies/GRAPH/2023-01-15-Chap-12.4.html",
    "title": "[CGSP] Chap 12.4: Node Subsampling for PSD Estimation",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics\n\n\ncolumnwise_kron = \n(C,D) -&gt; hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#49 (generic function with 1 method)\n\n\n\n12.4.1 The Sampling Problem\n아래와 같이 길이가 \\(N=10\\) 인 신호 \\({\\bf x}\\)를 고려하자.\n\nx = rand(10)\n\n10-element Vector{Float64}:\n 0.03235208758206609\n 0.5069925854414447\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n 0.24116013388795854\n 0.8439116925218157\n 0.6362602319916778\n 0.386069828675059\n 0.5313655894235898\n\n\n여기에서 1,3,4,5 번째 원소만 추출하여길이가 \\(K=4\\) 인 신호 \\({\\bf y}\\)를 만들고 싶다.\n\ny = x[[1,3,4,5]]\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n이 과정은 아래와 같이 수행할 수도 있다.\n\nΦ= [1 0 0 0 0 0 0 0 0 0\n    0 0 1 0 0 0 0 0 0 0\n    0 0 0 1 0 0 0 0 0 0\n    0 0 0 0 1 0 0 0 0 0]\n\n4×10 Matrix{Int64}:\n 1  0  0  0  0  0  0  0  0  0\n 0  0  1  0  0  0  0  0  0  0\n 0  0  0  1  0  0  0  0  0  0\n 0  0  0  0  1  0  0  0  0  0\n\n\n\nΦ*x\n\n4-element Vector{Float64}:\n 0.03235208758206609\n 0.5795228508497553\n 0.682832351742401\n 0.64422613488741\n\n\n즉 적당한 \\(K\\times N\\) selection matrix를 선언하여 subsampling을 수행할 수 있다. 이때 매트릭스 \\({\\bf \\Phi}\\)를 subsampling matrix 혹은 sparse sampling matrix 라고 부른다.\n\n\n12.4.2 Compressed LS Estimator\n\nN = 10\nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x) \n\n10×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n\n\n\nG = columnwise_kron(conj(V),V)\n\n100×10 Matrix{ComplexF64}:\n 1.0+0.0im        1.0+0.0im          …        1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0+1.22465e-16im  …       -1.0+1.10218e-15im\n 1.0+0.0im  -0.809017-0.587785im        -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im   0.809017-0.587785im     …   0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n    ⋮                                ⋱  \n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n 1.0+0.0im   0.809017+0.587785im         0.809017-0.587785im\n 1.0+0.0im   0.809017+0.587785im     …   0.809017-0.587785im\n 1.0+0.0im   0.309017+0.951057im         0.309017-0.951057im\n 1.0+0.0im  -0.309017+0.951057im        -0.309017-0.951057im\n 1.0+0.0im  -0.809017+0.587785im        -0.809017-0.587785im\n 1.0+0.0im       -1.0-1.11022e-16im          -1.0+2.27596e-15im\n 1.0+0.0im  -0.809017-0.587785im     …  -0.809017+0.587785im\n 1.0+0.0im  -0.309017-0.951057im        -0.309017+0.951057im\n 1.0+0.0im   0.309017-0.951057im         0.309017+0.951057im\n 1.0+0.0im   0.809017-0.587785im         0.809017+0.587785im\n 1.0+0.0im        1.0+0.0im                   1.0+0.0im\n\n\n- 방법1\n\nĉx = vec(x*x')\np̂ = inv(G' * G) * G' * ĉx\n\n10-element Vector{ComplexF64}:\n    0.25854107856772546 + 2.245922875954761e-20im\n   0.004743491121735806 - 1.3138893409553828e-18im\n   0.006946482731189413 - 9.791191432641327e-19im\n   0.001721693617954179 - 1.9827974128203887e-18im\n   0.011344167525098774 + 2.6827005818057562e-19im\n 0.00012662617844242917 - 3.748573865136995e-20im\n   0.011344167525098762 + 2.7448152053954017e-18im\n  0.0017216936179541913 - 9.35534609073096e-19im\n   0.006946482731189404 + 1.954408900185458e-18im\n   0.004743491121735756 - 2.561030398375897e-18im\n\n\n- 방법2\n\nĉy = vec(y*y')\np̂ = (kron(Φ,Φ)*G)' * ĉy\n\n10-element Vector{ComplexF64}:\n   3.759462826821233 + 0.0im\n   2.765185174577697 - 2.0816681711721685e-17im\n   1.077337414764992 + 2.7755575615628914e-17im\n 0.11594812606807317 + 2.0816681711721685e-17im\n 0.08838298603932843 + 3.903127820947816e-17im\n 0.32863702713833354 + 4.622231866529366e-33im\n 0.08838298603932859 + 9.540979117872439e-18im\n  0.1159481260680729 - 2.0816681711721685e-17im\n  1.0773374147649915 + 0.0im\n  2.7651851745776965 - 2.0816681711721685e-17im"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-07-02-GSO.html",
    "href": "posts/2_Studies/GRAPH/2023-07-02-GSO.html",
    "title": "Graph Shift Operator",
    "section": "",
    "text": "Definition(Djuric and Richard 2018): Given a normal shift operator \\({\\bf S}\\), we say that a graph signal \\({\\bf y}\\) is weakly stationary with respect to \\({\\bf S}\\) if, for all \\(a\\), \\(b\\), and \\(c \\leq b\\), the following equality holds:\nDjuric, Petar, and Cédric Richard. 2018. Cooperative and Graph Signal Processing: Principles and Applications. Academic Press.\n\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf y}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf y}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf y}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf y} \\Big)^H \\bigg].\\]\n\n\n\n\n\n\nNote\n\n\n\nUsing \\({\\bf S}\\) as the periodic shift operator \\({\\bf S}=\\begin{cases} 1 & j-j = 1 \\\\ 0 & o.w.\\end{cases}.\\), the definition is equivalent to the traditional stationarity definition in time series analysis.\n\n\n\nConjugate\n\\(E(y)=0\\)을 가정하고, \\(y = (y_1,y_2)\\)의 벡터를 가정했을 때,\n\\(Cov(y) = \\begin{pmatrix} cov(y_1,y_2) & cov(y_1,y_2) \\\\ cov(y_2,y_1) & cov(y_2,y_2) \\end{pmatrix}\\)\n\n\\(cov(y_1,y_1) = V(y_1) = E(y_1 - \\mu_1)^2 = E(y_1)^2 (\\therefore \\mu = 0)\\)\n\\(cov(y_2,y_1) = E(y_2 - \\mu_2)E(y_1 - \\mu_1) = E(y_2-y_1)\\)\n\\(cov(y_2,y_2) = V(y_2) = E(y_2 - \\mu_2)^2 = E(y_2)^2 (\\therefore \\mu = 0)\\)\n\\(cov(y_1,y_2) = E(y_1 - \\mu_1)E(y_2 - \\mu_2) = E(y_1-y_2)\\)\n\n\\(= E \\begin{pmatrix} y_1^2 & y_1y_2 \\\\ y_2 y_1 & y_2^2 \\end{pmatrix} = E(y y^\\top)\\)\n\\(y = (y_q y_2)^\\top\\)\n\\(y^\\top = (y_1,y_2)\\)\n\\(y y^\\top = \\begin{bmatrix} y1 \\\\ y_2 \\end{bmatrix} \\begin{bmatrix} y2 & y_2 \\end{bmatrix} = \\begin{bmatrix} y_1^2 & y_1y_2 \\\\ y_2y_1 & y_2^2 \\end{bmatrix}\\)\n\\(cov(y) = E(y t^\\top) = E(y y^H)\\) -&gt; 확률변수가 복소수일 경우 가정 가능하다\n\\(cov(y\\text{의 } a \\text{만큼 평행이동}) = cov(y\\text{의 } b \\text{만큼 평행이동})\\)\n\\(cov((S^ay)(S^b y)^\\top) = cov((S^c y)(S^d y)^\\top)\\)\n\n결국, normal GSO가 주어질 때, \\(y\\)는 약정상성을 S에 대해 가지고 있다는 말이 된다.\n정상성 조건: 평균, 분산이 일정할때, 자기 공분산이 시차 t에만 의존할 때"
  },
  {
    "objectID": "3_gode.html",
    "href": "3_gode.html",
    "title": "GODE",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJul 1, 2023\n\n\nGraph and Spectral domain\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nNon-Euclidean data of GODE\n\n\nSEOYEON CHOI\n\n\n\n\nMay 18, 2023\n\n\nEbayesThresh Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Lectures_ing",
      "**Researches**",
      "GODE"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Seoyeon",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nDec 31, 2023\n\n\n[Note] Tips of Linux, Git and Blog\n\n\nSEOYEON CHOI\n\n\n\n\nNov 22, 2023\n\n\n[Note] DGX station 설정_메모 추가\n\n\nGUEBIN CHOI\n\n\n\n\nOct 27, 2023\n\n\n[HCAM]Study\n\n\nSEOYEON CHOI\n\n\n\n\nOct 18, 2023\n\n\n[CAM]Other Methods\n\n\nSEOYEON CHOI\n\n\n\n\nSep 20, 2023\n\n\n[IT-STGCN]논문리비전_수정\n\n\nSEOYEON CHOI\n\n\n\n\nSep 14, 2023\n\n\n[CAM]Image Download\n\n\nSEOYEON CHOI\n\n\n\n\nAug 28, 2023\n\n\n[CAM]Original CAM\n\n\nSEOYEON CHOI\n\n\n\n\nAug 25, 2023\n\n\n[ggplot3]With Non tidy Data\n\n\nSEOYEON CHOI\n\n\n\n\nAug 10, 2023\n\n\n[ggplot3]Original\n\n\n신록예찬 \n\n\n\n\nJul 2, 2023\n\n\nGraph Shift Operator\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nGraph and Spectral domain\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nNon-Euclidean data of GODE\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nNon-Euclidean vs Euclidean\n\n\nSEOYEON CHOI\n\n\n\n\nJun 30, 2023\n\n\nGraph Signal\n\n\nSEOYEON CHOI\n\n\n\n\nJun 30, 2023\n\n\nRegular Graph\n\n\nSEOYEON CHOI\n\n\n\n\nMay 18, 2023\n\n\nEbayesThresh Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nMay 18, 2023\n\n\nSelf Consistency Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\nJan 15, 2023\n\n\n[CGSP] Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nDec 31, 2022\n\n\nStudy for Spaces\n\n\nSEOYEON CHOI\n\n\n\n\nDec 27, 2022\n\n\n[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 26, 2022\n\n\n[CGSP] Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n[CGSP] Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\nApr 4, 2022\n\n\nIntroduction to Python 5wk\n\n\nSEOYEON CHOI\n\n\n\n\nMar 23, 2022\n\n\nIntroduction to Python 4wk\n\n\nSEOYEON CHOI\n\n\n\n\nApr 26, 2019\n\n\n[Essays] 퓨리에 변환\n\n\n신록예찬 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html",
    "href": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "",
    "text": "using LinearAlgebra, DSP"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "href": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#simultaneously-diagonalizable",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Simultaneously Diagonalizable",
    "text": "Simultaneously Diagonalizable\n매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 대각화 가능하다는 것은 아래의 표현을 만족하는 적당한 invertible matrix \\({\\bf \\Psi}_A\\), \\({\\bf \\Psi}_B\\)와 대각행렬 \\({\\bf \\Lambda}_A\\), \\({\\bf \\Lambda}_B\\)가 존재한다는 의미가 된다.\n\\[{\\bf A} = {\\bf V}_{A} {\\bf \\Lambda}_A {\\bf V}_{A}^{-1}\\]\n\\[{\\bf B} = {\\bf V}_{B} {\\bf \\Lambda}_B {\\bf V}_{B}^{-1}\\]\n그리고 만약에 \\({\\bf V}_{A}={\\bf V}_{B}\\)이라면 즉\n\\[{\\bf A} = {\\bf V} {\\bf \\Lambda}_A {\\bf V}^{-1}\\]\n\\[{\\bf B} = {\\bf V} {\\bf \\Lambda}_B {\\bf V}^{-1}\\]\n이라면 \\(\\{{\\bf A},{\\bf B}\\}\\)가 simultaneously diagonalzable 하다고 표현한다."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#commute",
    "href": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#commute",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Commute",
    "text": "Commute\n두 matrix \\({\\bf A}\\)와 \\({\\bf B}\\)에 대하여\n\\[{\\bf A}{\\bf B}= {\\bf B}{\\bf A}\\]\n인 관계가 성립하면 두 매트릭스가 commute 한다고 표현한다. 그런데 \\({\\bf A}{\\bf B}={\\bf A}{\\bf B}\\)의 조건은 \\({\\bf A}, {\\bf B}\\)가 동시대각화가능할 (simultaneously diagonalzable) 조건과 같다. 1 따라서 simultaneously diagonalzable 는 commute와 같은 말이라 생각해도 무방하다.\n1 필요충분조건이다.\n참고: 위키피디아.."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "href": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#shift-invariant-filter",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Shift Invariant Filter",
    "text": "Shift Invariant Filter\n\nref: Djuric and Richard (2018) Chap 8.3 의 내용 중 일부\n\nDjuric, Petar, and Cédric Richard. 2018. Cooperative and Graph Signal Processing: Principles and Applications. Academic Press.\n\nDefine the matrix \\({\\bf B}\\) as periodic shift matrix such that\n\\[\n{\\bf B} = \\begin{bmatrix}\n0 & 0 & 0 & \\dots  & 0 & 1 \\\\\n1 & 0 & 0 & \\dots & 0 & 0 \\\\\n0 & 1 & 0 & \\dots & 0 & 0 \\\\\n\\dots & \\dots & \\dots & \\dots & \\dots & \\dots\\\\\n0 & 0 & \\dots & 1 & 0 & 0 \\\\\n0 & 0 & \\dots & 0 & 1 & 0 \\\\\n\\end{bmatrix}.\\]\nA generic filter \\({\\boldsymbol h}\\) is given by its \\(z\\)-transform\n\\[h(z)=h_0z^0+h_1z^{-1}+\\cdots +h_{N-1}z^{-(N-1)}\\]\nwhere \\(s_{n-1}=z^{-1}s_n\\). In vector notation, and with respect to the standard basis \\({\\bf I}\\), the filter is represented by the matrix \\({\\bf H}\\), a polynomial in the cyclic shift\n\\[{\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+\\cdots+h_{N-1}{\\bf B}^{N-1}.\\]\nFilters are shift invariant iff\n\\[z\\cdot h(z) = h(z)\\cdot z\\]\nor from the matrix representation\n\\[{\\bf B}h({\\bf B})=h({\\bf B}){\\bf B}.\\]\nExample\nLet \\({\\bf B}\\) as\n\nB= [0 1 0 0 0 0 0\n    0 0 1 0 0 0 0 \n    0 0 0 1 0 0 0 \n    0 0 0 0 1 0 0 \n    0 0 0 0 0 1 0 \n    0 0 0 0 0 0 1 \n    1 0 0 0 0 0 0]\n\n7×7 Matrix{Int64}:\n 0  1  0  0  0  0  0\n 0  0  1  0  0  0  0\n 0  0  0  1  0  0  0\n 0  0  0  0  1  0  0\n 0  0  0  0  0  1  0\n 0  0  0  0  0  0  1\n 1  0  0  0  0  0  0\n\n\nDefine \\({\\boldsymbol h}\\) as\n\nh = [1/3,1/3,1/3]\n\n3-element Vector{Float64}:\n 0.3333333333333333\n 0.3333333333333333\n 0.3333333333333333\n\n\nFurthermore define \\({\\bf H}=h({\\bf B})=h_0{\\bf B}^0+h_1{\\bf B}^1+h_2{\\bf B}^2\\)\n\nH = (1/3)*B^0 + (1/3)*B^1 + (1/3)*B^2 \n\n7×7 Matrix{Float64}:\n 0.333333  0.333333  0.333333  0.0       0.0       0.0       0.0\n 0.0       0.333333  0.333333  0.333333  0.0       0.0       0.0\n 0.0       0.0       0.333333  0.333333  0.333333  0.0       0.0\n 0.0       0.0       0.0       0.333333  0.333333  0.333333  0.0\n 0.0       0.0       0.0       0.0       0.333333  0.333333  0.333333\n 0.333333  0.0       0.0       0.0       0.0       0.333333  0.333333\n 0.333333  0.333333  0.0       0.0       0.0       0.0       0.333333\n\n\nObserve following:\n\nB*H == H*B \n\ntrue\n\n\nThus, filter \\({\\boldsymbol h}\\) is shift invariant filter and matrix \\({\\bf H}\\) is shift invariant operator.\nnote: \\({\\boldsymbol h}\\) is moving average filter.\nnote: for any \\({\\bf x}\\), \\({\\bf H}{\\bf x}\\) is definded by\n\\[\\left[\\frac{x_{n-1}+x_n+x_1}{3},\\frac{x_n+x_1+x_2}{3},\\dots,\\frac{x_{n-3}+x_{n-2}+x_n}{3}\\right].\\]\n\nx = [1,1,1,1,2,2,2]\nH*x\n\n7-element Vector{Float64}:\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666665\n 2.0\n 1.6666666666666665\n 1.3333333333333333\n\n\nnote: In some sense, the matrix \\({\\bf H}{\\bf x}\\) can be thought as generalized version of \\({\\boldsymbol h}\\star {\\bf x}\\) where \\(\\star\\) is convolution up to shift\n\nconv(h,x)\n\n9-element Vector{Float64}:\n 0.3333333333333334\n 0.6666666666666667\n 1.0\n 1.0\n 1.3333333333333333\n 1.6666666666666667\n 2.0\n 1.3333333333333333\n 0.6666666666666667\n\n\nFinally, we observe that, from the Cayley-Hamilton Theorem, \\({\\bf B}\\) satisfies its characteristic polynomial \\(\\Delta({\\bf B})\\), where \\(\\Delta(\\lambda)\\) is the determinant of \\(\\lambda{\\bf I}-{\\bf B}\\). The characteristic polynomial \\(\\Delta({\\bf B})\\) has degree \\(N\\), so, in DSP, as described so far, linear filters are (matrix) polynomial with degree at most \\(N-1\\).\n\n이 부분은 책에 써있길래 가져오긴 했는데, 무슨 의미인지 모르겠음"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "href": "posts/2_Studies/GRAPH/2022-12-26-Chap-12.2.html#coexisting-approaches",
    "title": "[CGSP] Chap 12.2: Weakly Stationary Graph Processes",
    "section": "Coexisting Approaches",
    "text": "Coexisting Approaches\nStationary graph processes were first defined and analyzed in (Girault 2015). The fundamental problem identified there is that GSOs do not preserve energy in general and therefore cannot be isometric (Gavili and Zhang 2017). This problem is addressed in (Girault, Gonçalves, and Fleury 2015) with the definition of an isometric graph shift that preserves the eigenvector space of the Laplacian GSO but modifies its eigenvalues.\n\nGirault, Benjamin. 2015. “Stationary Graph Signals Using an Isometric Graph Translation.” In 2015 23rd European Signal Processing Conference (EUSIPCO), 1516–20. IEEE.\n\nGavili, Adnan, and Xiao-Ping Zhang. 2017. “On the Shift Operator, Graph Frequency, and Optimal Filtering in Graph Signal Processing.” IEEE Transactions on Signal Processing 65 (23): 6303–18.\n\nGirault, Benjamin, Paulo Gonçalves, and Éric Fleury. 2015. “Translation on Graphs: An Isometric Shift Operator.” IEEE Signal Processing Letters 22 (12): 2416–20.\nA stationary graph process is then defined as one whose probability distributions are invariant with respect to multiplications with the isometric shift. One drawback of this approach is that the isometric shift is a complex-valued operator and has a sparsity structure (if any) different from \\({\\bf S}\\). By contrast, the vertex-based definition in\n\\[\\mathbb{E} \\bigg[ \\big({\\bf S}^a{\\bf x}\\big)\\Big(\\big({\\bf S}^H)^b {\\bf x}\\Big)^H  \\bigg]=\\mathbb{E}\\bigg[\\big({\\bf S}^{a+c}{\\bf x}\\big)\\Big(\\big({\\bf S}^H\\big)^{b-c}{\\bf x} \\Big)^H \\bigg]\\]\nis based on the original GSO \\({\\bf S}\\), which is local and real-valued. As a result, above Eq. provides intuition on the relations between stationarity and locality, which can be leveraged to develop stationarity tests or estimation schemes that work with local information. Graph stationarity was also studied in (Perraudin and Vandergheynst 2017) where the requirement of having a covariance matrix diagonalizable by the eigenvectors of the Laplacian GSO is adopted as a definition. This condition is shown to be equivalent to statistical invariance with respect to the translation operator introduced in (Shuman, Ricaud, and Vandergheynst 2016). When the shift \\({\\bf S}\\) coincides with the Laplacian of the graph and the eigenvalues of \\({\\bf S}\\) are all distinct, Definitions 12.1 and 12.2 are equivalent to those in Perraudin and Vandergheynst (2017). Hence, the definitions presented here differ from (Perraudin and Vandergheynst 2017) in that we consider general normal shifts instead of Laplacians and that we see Definition 12.1 as a definition, not a property. These are mathematically minor differences that are important in practice though; see Segarra et al. (2017) for more details.\n\nPerraudin, Nathanaël, and Pierre Vandergheynst. 2017. “Stationary Signal Processing on Graphs.” IEEE Transactions on Signal Processing 65 (13): 3462–77.\n\nShuman, David I, Benjamin Ricaud, and Pierre Vandergheynst. 2016. “Vertex-Frequency Analysis on Graphs.” Applied and Computational Harmonic Analysis 40 (2): 260–91.\n\nSegarra, Santiago, Antonio G Marques, Gonzalo Mateos, and Alejandro Ribeiro. 2017. “Network Topology Inference from Spectral Templates.” IEEE Transactions on Signal and Information Processing over Networks 3 (3): 467–83."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "",
    "text": "using LinearAlgebra, Plots, FFTW, Statistics"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#kronecker-product",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Kronecker product",
    "text": "Kronecker product\n크로네커곱의 정의는 아래와 같다.\n\\[{\\bf A} \\otimes {\\bf B}\n=\\begin{bmatrix}\na_{11}{\\bf B} & a_{12}{\\bf B} & \\dots & a_{1m}{\\bf B} \\\\\na_{21}{\\bf B} & a_{22}{\\bf B} & \\dots & a_{2m}{\\bf B} \\\\\n\\dots & \\dots & \\dots & \\dots \\\\\na_{n1}{\\bf B} & a_{n2}{\\bf B} & \\dots & a_{nm}{\\bf B} \\\\\n\\end{bmatrix}\\]\n두 행렬 \\({\\bf A}_{m\\times n}\\), \\({\\bf B}_{p\\times q}\\)의 크로네커곱 \\({\\bf A}\\otimes {\\bf B}\\)의 차원은 \\(mp \\times nq\\) 가 된다. 계산예시는 아래와 같다.\n\n\n\n위키에서 긁은 예제, 글씨가 좀 작음\n\n\n크로네커곱에 대한 성질들이 위키에 많이 있으니 참고하면 좋다.\n(예제1)\n\nA= [1 2\n    3 4]\nB= [0 5\n    6 7]\nC = kron(A, B)\n\n4×4 Matrix{Int64}:\n  0   5   0  10\n  6   7  12  14\n  0  15   0  20\n 18  21  24  28\n\n\n(예제2)\n\nA= [1 -4 7; -2 3 3]\nB= [8 -9 -6 -5; 1 -3 -4 7; 2 8 -8 -3; 1 2 -5 -1]\nC = kron(A, B)\n\n8×12 Matrix{Int64}:\n   8   -9  -6   -5  -32   36   24   20  56  -63  -42  -35\n   1   -3  -4    7   -4   12   16  -28   7  -21  -28   49\n   2    8  -8   -3   -8  -32   32   12  14   56  -56  -21\n   1    2  -5   -1   -4   -8   20    4   7   14  -35   -7\n -16   18  12   10   24  -27  -18  -15  24  -27  -18  -15\n  -2    6   8  -14    3   -9  -12   21   3   -9  -12   21\n  -4  -16  16    6    6   24  -24   -9   6   24  -24   -9\n  -2   -4  10    2    3    6  -15   -3   3    6  -15   -3"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#khatrirao-product",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Khatri–Rao product",
    "text": "Khatri–Rao product\n카트리-라오곱은 매트릭스 \\({\\bf A}\\)와 \\({\\bf B}\\)가 같은 차원의 블락매트릭스로 정의될때 각 서브매트릭스의 크로네커 곱으로 정의된다. 정의와 계산예시는 아래와 같다.\n\n\n\n예시1: 위키에서 긁은 그림\n\n\n또 다른 계산예시는 아래와 같다. 이 예제는 중요하니까 구현해보자.\n\n\n\n예시2: 위키에서 긁은 그림\n\n\n(예제1)\n\nC= [1 2 3 \n    4 5 6 \n    7 8 9] \nD= [1 4 7\n    2 5 8\n    3 6 9]\n\n3×3 Matrix{Int64}:\n 1  4  7\n 2  5  8\n 3  6  9\n\n\n\nhcat([kron(C[:,i],D[:,i]) for i in 1:3]...)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81\n\n\n이건 자주 쓸일이 있을것 같으니까 함수로 저장하자.\n\ncolumnwise_kron = \n(C,D) -&gt; hcat([kron(C[:,i],D[:,i]) for i in 1:size(C)[2]]...)\n\n#181 (generic function with 1 method)\n\n\n\ncolumnwise_kron(C,D)\n\n9×3 Matrix{Int64}:\n  1   8  21\n  2  10  24\n  3  12  27\n  4  20  42\n  8  25  48\n 12  30  54\n  7  32  63\n 14  40  72\n 21  48  81"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#그래프-표현",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프 표현",
    "text": "그래프 표현\n아래의 그림을 살펴보자.\n\n\n\n그래프의 개념을 이해하는 필요한 그림, 일단 오른쪽의 \\({\\bf S}\\)는 무시할 것\n\n\n오른쪽의 \\({\\bf S}\\)는 무시하고 왼쪽의 그래프만 살펴보자. 이 그림에는 6개의 노드가 있고 각각의 노드는 저 마다의 연결구조를 가진다. 이러한 연결구조는 \\({\\bf G}=({\\bf N},{\\bf E})\\) 으로 표현할 수 있는데 여기에서 \\({\\bf N}\\)은 노드들의 집합이고 \\({\\bf E}\\)는 엣지들의 집합이다.1 보통 \\({\\cal E}\\)는 복잡하므로 연결정보를 매트릭스 \\({\\bf E}\\)로 표현하는데 이러한 \\({\\bf E}\\)를 인접행렬이라고 부른다. 인접행렬의 각 원소는 \\(E_{ij}= \\begin{cases} 1 & (i,j) \\in {\\cal E} \\\\ 0 & o.w \\end{cases}\\) 와 같이 정의한다. 이 그림의 경우 \\({\\cal N}\\) 와 \\({\\cal E}\\), \\({\\bf E}\\) 는 아래와 같다.\n1 노드 \\(i\\)에서 노드 \\(j\\)로 향하는 연결이 있다면 \\((i,j) \\in {\\cal E}\\)이다.\n\\({\\cal N}=\\{1,2,3,4,5,6\\}\\)\n\\({\\bf E}=\\begin{bmatrix} 0 & 1 & 0 & 0 & 1 & 0 \\\\ 1 & 0 & 1 & 0 & 1 & 0\\\\ 0 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 1 & 1 \\\\ 1 & 1 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 \\end{bmatrix}\\)\n\\({\\cal E} = \\{(i,j) : E_{ij}=1 \\}\\)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#gso",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "GSO",
    "text": "GSO\n후에 자세히 서술하겠지만 전통적인 시계열분석기법을 그래프신호로 확장하기 위해서는 단지 퓨리에변환 대신에 그래프퓨리에 변환을 사용하면 된다. 즉 퓨리에변환을 일반화한 그래프퓨리에변환을 잘 정의하면 된다.\n전통적인 신호처리 영역에서의 퓨리에변환은 시계열자료의 인접성을 의미하는 행렬 \\({\\bf B}\\)2의 고유행렬의 켤레전치로 정의할 수 있다. 이를 이용하면 그래프 퓨리에변환은 그래프자료의 인접성을 의미하는 행렬3의 고유행렬의 켤레전치로 정의할 수 있음을 유추할 수 있다. 즉 비유클리드 자료에서도 \\({\\bf B}\\)에 대응하는 어떠한 매트릭스가 정의되어야 하는데 (그리고 이 매트릭스는 그래프자료의 인접성에 대한 정보가 있어야 한다) 이 매트릭스를 \\({\\bf S}\\)라고 정의하고 grahp shift operator (GSO) 라고 이름 붙인다.\n2 원래는 평행이동을 의미하는 행렬이지만, 이걸 인접성을 의미하는 행렬로 해석할 수도 있다. 어차피 인접한 곳으로 이동할 수 있으니까..3 예를들면 인접행렬 \\({\\bf E}\\)와 같은 행렬주어진 그래프 \\({\\cal G}=({\\cal N},{\\cal E})\\) 에 대하여 GSO \\({\\bf S}\\)는 \\({\\bf E}+{\\bf I}\\)의 값이 1인 영역에만 값이 있는 어떠한 행렬이다. 다시 아래의 그림을 생각하여 보자.\n\n\n\nGSO의 개념을 이해하는데 필요한 그림\n\n\n왼쪽그래프의 GSO는 오른쪽과 같은 행렬 \\({\\bf S}\\)가 된다. 이제 \\({\\bf S}\\) 의 고유벡터행렬을 구한 뒤에 그것의 켤레전치를 \\({\\bf GFT}\\) 행렬로 정의하면 될 것 같다. 문제는 “\\({\\bf S}\\)의 고유벡터행렬이 항상 존재하는가?” 인데, 사실 이게 항상 존재한다는 보장이 없다. 즉 \\({\\bf S}\\)의 고유벡터 행렬이 존재 안할 수도 있다. 따라서 GSO \\({\\bf S}\\)가 고유분해가능하다는 조건이 추가적으로 필요한데 이러한 조건을 만족하는 GSO를 normal GSO라고 부른다. 우리는 당연히 normal GSO에 대해서만 관심이 있으므로 앞으로 특별한 언급이 없는한 GSO는 모두 normal GSO라고 가정한다."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#periodogram-correlogram-and-ls-estimator",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "Periodogram, correlogram, and LS estimator",
    "text": "Periodogram, correlogram, and LS estimator\nFrom \\({\\bf C}_{\\tilde{\\bf x}}:= \\mathbb{E}\\left[\\tilde{\\bf x}\\tilde{\\bf x}^H \\right]=\\mathbb{E}\\left[({\\bf V}^H{\\bf x})({\\bf V}^H{\\bf x})^H \\right]=\\text{diag}({\\bf p})\\) it follows that one may express the PSD as \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\). That is, the PSD is given by the expected value of the squared frequency components of the random process. This leads to a natural approach for the estimation of \\({\\bf p}\\) from a finite set of \\(R\\) realizations of the process \\({\\bf x}\\). Indeed, we compute the \\({\\bf GFT} \\tilde{\\bf x}_r = {\\bf V}^H{\\bf x}_r\\) of each observed signal \\({\\bf x}_r\\) and estimate \\({\\bf p}\\) as\n\\[\n\\hat{\\bf p}_{pg}:= \\frac{1}{R}\\sum_{r=1}^R|\\tilde{\\bf x}_r|^2=\\frac{1}{R}\\sum_{r=1}^{R}|{\\bf V}^H{\\bf x}_{r}|^2.\n\\]\nThe estimator \\(\\hat{\\bf p}_{pg}\\) is termed periodogram due to its evident similarity with its homonym5 in classical estimation. It is simple to show that \\({\\bf p}_{pg}\\) is an unbiased estimator, that is, \\(\\mathbb{E}[\\hat{\\bf p}_{pg}]= {\\bf p}\\). A more detailed analysis of the performance of \\(\\hat{\\bf p}_{pg}\\), for the case where the observations are Gaussian, is given in Proposition 12.1.6\n5 동음이의어6 Proposition 12.1은 뒤에 다루는데 \\(\\hat{\\bf p}_{pg}\\)의 분산에 대한 서술이 있음. 분산은 \\(\\mathbb{V}[\\hat{\\bf p}_{pg}]=\\frac{2}{R}\\text{diag}^2({\\bf p})\\)와 같음An alternative nonparametric estimation scheme, denominated correlogram, can be devised by starting from the definition of \\({\\bf p}\\) in\n\\[{\\bf p}:=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big).\\]\nNamely, one may substitute \\({\\bf C}_{\\bf x}\\) in above equation by the sample covariance \\(\\hat{\\bf C}_{\\bf x} = \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\) computed based on the available observations to obtain\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\nNotice that the matrix \\({\\bf V}^H\\hat{\\bf C}_{\\bf x}{\\bf V}\\) is in general, not diagonal because the eigenbasis of \\(\\hat{\\bf C}_{\\bf x}\\) differs from \\({\\bf V}\\), the eigenbasis of \\({\\bf C}_{\\bf x}\\). Nonetheless, we keep only the diagonal elements \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x}{\\bf v}_i\\) for \\(i = 1, \\dots , N\\) as our PSD estimator. It can be shown that the correlogram \\({\\bf p}_{cg}\\) and the periodogram \\({\\bf p}_{pg}\\) lead to identical estimators, as is the case in classical signal processing.\nThe correlogram can also be interpreted as an LS estimator. The decomposition in \\({\\bf C}_{\\bf x}={\\bf V}\\text{diag}({\\bf p}){\\bf V}^H\\) allows a linear parameterization of the covariance matrix \\({\\bf C}_{\\bf x}\\) as\n\\[\n{\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H.\n\\]\nThis linear parametrization will also be useful for the sampling schemes developed in Section 12.4. Vectorizing \\({\\bf C}_{\\bf x}\\) in \\({\\bf C}_{\\bf x}({\\bf p})=\\sum_{i=1}^N p_i{\\bf v}_i{\\bf v}_i^H\\) results in a set of \\(N^2\\) equations in \\({\\bf p}\\)\n\\[\n{\\bf c}_{\\bf x} = \\text{vec}({\\bf C}_{\\bf x})=\\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf G}_{np}{\\bf p},\n\\]\nwhere \\(\\text{vec}({\\bf v}_i{\\bf v}_i^H)={\\bf v}_i^\\ast \\otimes {\\bf v}_i\\). Relying on the Khatri-Rao product, we then form the \\(N^2 \\times N\\) matrix \\({\\bf G}_{np}\\) as\n\\[\n{\\bf G}_{np}:= \\left[{\\bf v}_1^\\ast \\otimes {\\bf v}_1, \\dots, {\\bf v}_N^\\ast \\otimes {\\bf v}_N \\right] = {\\bf V}^\\ast \\odot {\\bf V}.\n\\]\n\nHere \\(\\otimes\\) denote the Kronecker matrix product and \\(\\odot\\) denote the Khatri-Rao matrix product.\n\nUsing the sample covariance matrix \\(\\hat{\\bf C}_{\\bf x}\\) as an estimate of \\({\\bf C}_{\\bf x}\\), we can match the estimated covariance vector \\(\\hat{\\bf c}_{\\bf x}=\\text{vec}(\\hat{\\bf C}_{\\bf x})\\) to the true covariance vector \\({\\bf c}_{\\bf x}\\) in the LS sense as\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\nIn other words, the LS estimator minimizes the squared error \\(\\text{tr}\\left[\\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)^T \\big(\\hat{\\bf C}_{\\bf x} − \\hat{\\bf C}_{\\bf x}({\\bf p})\\big)\\right]\\). From expression \\(\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\) it can be shown that the \\(i\\)th element of \\(\\hat{\\bf p}_{ls}\\) is \\({\\bf v}_i^H \\hat{\\bf C}_{\\bf x} {\\bf v}_i\\). Combining this with Eq.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right]\\]\nwe get that the LS estimator \\(\\hat{\\bf p}_{ls}\\) and the correlogram \\(\\hat{\\bf p}_{cg}\\) —and hence the periodogram as well— are all identical estimators. The estimators derived in this subsection do not assume any data distribution and are well suited for cases where the data probability density function is not available. In what follows, we provide performance bounds for these estimators under the condition that the observed signals are Gaussian."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#정상시계열을-분석하는-두-가지-흐름-acf와-psd",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD",
    "text": "정상시계열을 분석하는 두 가지 흐름, ACF와 PSD\n\n전통적인 분석방법\n클래식한 정상시계열은 유한차수의 ARMA로 근사할 수 있음이 알려져 있다7. 유한차수의 ARMA의 계수 \\(p\\),\\(q\\)를 적절하게 추정하기 위해서는 시계열 \\({\\bf x}\\)를 SACF plot 혹은 SPACF plot 을 이용하면 된다. 이때 SACF 혹은 SPACF 의 그림을 살펴보고 적절한 모형을 선택하기 위해서는 유한차수 ARMA의 이론적 ACF의 모양을 알면 되는데,8 이를 바꾸어서 말하면 결국 정상시계열 \\({\\bf x}\\)의 모든 정보는 ACF에 들어있다는 의미가 된다. 즉 정상시계열은 ACF만 잘 추정하면 모든 것이 해결된다.\n7 Wold’s theorem8 예를들어 “coef가 0.9인 AR(1)의 경우 lag=1 에 대한 이론적 ACF값이 0.9, lag=2에 대한 ACF값이 0.81, … 와 같이 되더라~” 하는식의그런데 ACF의 모든 정보는 다시 아래의 행렬에 들어있다.\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^T]\\]\n여기에서 \\({\\bf x}\\)는 realization이 아니라 확률벡터를 의미함을 유의하자.9 따라서 정상시계열의 경우 \\({\\bf C}_{\\bf x}\\)를 잘 추정하면 모든것이 해결된다고 생각하면 된다.\n9 보통 수리통계에서는 확률변수를 \\(X\\) realization을 \\(x\\)로 표현하지만 여기에서는 매트릭스를 대문자로 쓰고 있어서 그런식으로 표현하기 어렵다, 그래서 그때 그때 이것이 확률변수인지 realization인지 따져봐야 한다\n참고: 정상시계열의 경우 ACF 만 정확하게 알아도 (반대로 PACF만 정확하게 알아도) 이론상 모든 모형을 특정할 수 있다. 즉 정상시계열의 모형을 특정하기 위해서는 ACF plot, PACF plot 하나만 있어도 충분하다. (Wold’s Thm은 떠올리면 모든 정상시계열은 무한MA로 유니크하게 표현할 수 있는데, 이는 PACF plot을 가지고 모든 정상시계열을 유니크하게 특정할 수 있다는 것을 의미한다) 다만 좀 더 모형을 특정하는 과정을 용이하게 하기 위해서 실전에서는 SACF plot 과 SPACF plot 을 함께 보는 것이 유리하다.\n\n(예제) AR(1) 모형\n왜 ACF의 모든정보를 \\({\\bf C}_{\\bf x}\\)로 부터 알수 있는지 코드를 통하여 실습하여 보자. (바로 이해된다면 사실 이 예제는 스킵해도 무방함) 아래와 같은 모형을 가정하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n여기에서 \\(\\epsilon_t\\)는 서로 독립인 표준정규분포를 따른다. 이 모형에서 길이가 100인 시계열을 임의로 발생시키자.\n\nx = zeros(100*1000)\nx[1] = randn()\nfor t in 2:100\n    x[t] = 0.5*x[t-1] + randn()\nend\n\n모형에서 생성된 하나의 시계열을 시각화 하면 아래와 같다.\n\nplot(x) # 그냥 그려본것임. 별 의미는 없음\n\n\n\n\n\n\n\n\nlag=1일 경우 이 시계열의 SACF를 계산하면 아래와 같다.\n\nx[1:99] .* x[2:100]\n\n99-element Vector{Float64}:\n  1.587897526021493\n  1.130306190921068\n  0.5698214432110668\n  0.4648189302568683\n  0.3099446153360606\n  0.36362604534744775\n  0.8191871414624922\n -0.1720390842292145\n -0.06301214708310766\n  0.026414715508855904\n -0.007988283356933327\n -0.04178812545299474\n  0.22453267567940685\n  ⋮\n  3.931333581073927\n  1.315564948810858\n  0.9096080102581454\n  0.5410986320348997\n  0.29627801400693676\n  1.0673283524686212\n -1.0394649044573636\n  2.80195248208142\n  4.152973765526384\n  2.316315764368524\n  0.978758337765867\n -0.5840281943972468\n\n\n\n이 계산결과는 각 \\(t\\)에 대하여 \\(x_{t-1}x_t\\) 를 계산한 것과 같다.\n\n이 수열들의 평균은 아래와 같다.\n\nx[1:99] .* x[2:100] |&gt; mean\n\n0.5835563885014224\n\n\n\n이 계산결과는 \\(\\frac{1}{99}\\sum_{t=2}^{100} x_{t-1}x_t\\)를 계산한 것과 같다.\n\n이론적인 값인 0.5 근처의 값이 잘 나옴을 알 수 있다.\nlag=2일 경우도 마찬가지로 구할 수 있다.\n\nx[1:98] .* x[3:100] |&gt; mean\n\n0.38420263596668275\n\n\n이러한 숫자들은 그런데 \\({\\bf x}{\\bf x}^T\\)를 이용하여서도 구할 수 있다.10\n10 참고로 여기에서 \\({\\bf x}\\)는 확률벡터가 아니라 realization을 의미함\nx*x'\n\n100×100 Matrix{Float64}:\n  0.760108    1.5879      0.541064   …  -1.57394    -0.472676    0.939172\n  1.5879      3.31719     1.13031       -3.28802    -0.987441    1.96197\n  0.541064    1.13031     0.385143      -1.12037    -0.336463    0.668527\n  0.800507    1.67229     0.569821      -1.65759    -0.497799    0.989089\n  0.441361    0.922022    0.314172      -0.913915   -0.274462    0.545336\n  0.533784    1.1151      0.379961   …  -1.10529    -0.331936    0.659531\n  0.517803    1.08171     0.368586      -1.0722     -0.321998    0.639786\n  1.20252     2.51212     0.855987      -2.49003    -0.747794    1.48581\n -0.108745   -0.227173   -0.0774074      0.225175    0.0676234  -0.134363\n  0.440444    0.920106    0.313519      -0.912016   -0.273892    0.544203\n  0.0455859   0.0952309   0.0324492  …  -0.0943935  -0.0283478   0.0563249\n -0.133198   -0.278257   -0.0948139      0.27581     0.0828298  -0.164577\n  0.238468    0.498169    0.169748      -0.493789   -0.148292    0.294646\n  ⋮                                  ⋱                          \n  2.04697     4.2762      1.45708       -4.2386     -1.27291     2.52919\n  0.488514    1.02053     0.347736      -1.01155    -0.303784    0.603596\n  1.41531     2.95665     1.00746    …  -2.93065    -0.880119    1.74873\n  0.290602    0.60708     0.206858      -0.601742   -0.180712    0.359062\n  0.774954    1.61891     0.551632      -1.60468    -0.481908    0.957516\n  1.04688     2.18698     0.745197      -2.16775    -0.651007    1.2935\n -0.754723   -1.57665    -0.537231       1.56279     0.469328   -0.932519\n -2.82194    -5.89516    -2.00873    …   5.84333     1.75484    -3.48673\n -1.11863    -2.33686    -0.796269       2.31632     0.695624   -1.38215\n -1.57394    -3.28802    -1.12037        3.25911     0.978758   -1.94472\n -0.472676   -0.987441   -0.336463       0.978758    0.293936   -0.584028\n  0.939172    1.96197     0.668527      -1.94472    -0.584028    1.16042\n\n\n여기에서 각 원소들이 의미하는 바는 아래와 같다.\n\n대각선의 원소: \\(x_t^2,~ t=1,2,\\dots,100\\) 을 의미\n대각선 한칸 위, 혹은 한칸 아래: \\(x_{t-1} x_t~ t=2,3,\\dots,100\\) 을 의미\n대각선 두칸 위, 혹은 두칸 아래: \\(x_{t-2} x_t~ t=3,4,\\dots,100\\) 을 의미\n\n\n\n\nx*x'의 계산결과를 캡쳐한 그림, 이것은 \\(\\hat{\\bf C}_{\\bf x}\\)를 의미함\n\n\n확인해보자.\nlag=1, 스크린샷의 노란색\n\n(x[1:99] .* x[2:100])[1:5]\n\n5-element Vector{Float64}:\n 1.587897526021493\n 1.130306190921068\n 0.5698214432110668\n 0.4648189302568683\n 0.3099446153360606\n\n\n\nlag1에 해당하는 숫자들임. 이는 스크린샷에서 노란색으로 표현된 1.589, 1.13031, 0.569821 … 등과 일치한다.\n\nlag=2, 스크린샷의 빨간색\n\n(x[1:98] .* x[3:100])[1:5]\n\n5-element Vector{Float64}:\n 0.5410642277088621\n 1.6722932576420804\n 0.3141719983177106\n 0.5621541352252872\n 0.30066534927151267\n\n\n\nlag2에 해당하는 숫자들임. 이는 스크린샷에서 빨간색으로 표현된 숫자들인 0.54164, 1.67229, 0.31417 … 등과 일치한다.\n\n\n\n스펙트럼 방법\n지금까지는 정상시계열일 경우 ACF를 이용한 간단한 분석방법을 다시 복습했다. 그리고 \\({\\bf C}_{\\bf x}\\)가 ACF를 구함에 필요한 모든정보를 가지고 있음을 이해했다. 한편 \\({\\bf C}_{\\bf x}\\)은 positive definite matrix 이므로 아래와 같이 분해가능하다.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식표현을 잘 해석하면 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf V}\\)와 \\({\\bf p}\\)에 담겨있다는 사실을 이해할 수 있다. 그런데 정상시계열일 경우 한정하여 \\({\\bf C}_{x}\\)의 고유벡터행렬은 \\({\\bf B}\\)의 고유벡터행렬과 일치한다는 사실을 알고 있다. 따라서 \\({\\bf V}\\)는 \\({\\bf B}\\)로 부터 그냥 알 수 있는 정보이다. 따라서 \\({\\bf C}_{\\bf x}\\)의 모든 정보는 \\({\\bf p}\\)에 담겨있다는 사실을 알 수 있다. 이는 적절한 \\({\\bf p}\\)를 추정하는 일은 적절한 \\({\\bf C}_{\\bf x}\\)를 추정하는 것과 같다는 사실을 알려준다.\n요약하면 아래와 같다.\n\n임의의 정상시계열은 이론적인 ACF (혹은 PACF)를 잘 추정하면 유니크하게 특정할 수 있다. (Wold’s Thm)\nACF를 잘 추정한다는 말은 \\({\\bf C}_{\\bf x}\\)를 잘 추정한다는 의미이다.\n그런데 \\({\\bf p}\\)를 잘 추정하면 \\({\\bf C}_{\\bf x}\\)를 잘 추정하는 일이 된다.\n따라서 임의의 정상시계열은 \\({\\bf p}\\)를 잘 추정하면 유니크하게 특정할 수 있다는 결론을 얻는다.\n\n여기에서 \\({\\bf p}\\)를 power spectral density 라고 부른다. 일반적으로 정상시계열을 분석하기 위해서는 \\({\\bf C}_{\\bf x}\\)를 특정하거나, \\({\\bf p}\\)를 특정하면 되는데 여기에서 \\({\\bf p}\\)를 특정한뒤 \\({\\bf p}\\)로 부터 \\({\\bf C}\\)를 역으로 해석하는 방법론을 spectral analysis라고 부른다. 경우에 따라서 \\({\\bf C}_{\\bf x}\\)를 특정하는 것이 용이할 수도 있지만 \\({\\bf p}\\)를 특정하고 해석하는 것이 용이할 때도 있다.\n그렇다면 주어진 시계열 \\({\\bf x}\\)에 대하여 \\({\\bf p}\\)를 어떻게 구할까? 직관적으로 생각하면 단순히 아래의 알고리즘으로 구하면 된다는 것을 알 수 있다.\n\n\\({\\bf C}_{\\bf x}\\)를 알아낸다.\n\\({\\bf C}_{\\bf x}\\)를 고유분해하여 \\({\\bf p}\\)를 구한다.\n\n또 다른 방법으로는 교재에 소개된 바 있는 아래의 수식을 이용하는 것이다.11\n11 이 수식이 성립하는 이유는 조금 손으로 써보면 금방 알 수 있음\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\]\n이것을 이용하면 아래와 같은 알고리즘을 떠올릴 수 있다.\n\n\\({\\bf B}\\)의 고유벡터행렬 \\({\\bf V}\\)를 구하고 \\({\\bf V}^H{\\bf x}\\)를 계산한다.\n계산된 결과를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n그런데 \\({\\bf V}^H{\\bf x}= {\\bf DFT} \\cdot {\\bf x}\\) 이므로 1의 과정을 아래와 같이 바꾸어 서술할 수 있다.\n\n\\({\\bf x}\\)를 퓨리에변환하여 \\(\\tilde{\\bf x} = {\\bf DFT} \\cdot {\\bf x}\\) 를 계산한다.\n\\(\\tilde{\\bf x}\\)를 원소별로 제곱하여 \\({\\bf p}\\)를 얻는다.\n\n즉 임의의 시계열을 퓨리에변환한 뒤 제곱하면 \\({\\bf p}\\)를 얻을 수 있다.\n(예제2) – 하나의 realization에서 \\(\\hat{\\bf p}\\)를 구해보자.\n(예제1에 이어서) 아래의 모형에서 생성된 \\({\\bf x}\\)를 다시 고려하자.\n\\[x_{t} = 0.5 x_{t-1} +\\epsilon_t\\]\n\nplot(x)\n\n\n\n\n\n\n\n\n이 자료의 PSD \\({\\bf p}\\)는 아래와 같이 구할 수 있다.\n단계1: \\({\\bf x}\\)의 DFT를 계산\n\nx̃ = fft(x) \n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\\({\\bf B}\\)를 설정하고 고유값분해 하기 귀찮아서 그냥 DFT해주는 패키지 사용함\n\n단계2: \\(\\hat{\\bf p}\\)를 계산\n\np̂ = abs.(x̃).^2\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n참고\nfft(x) 대신에 아래의 코드를 이용해도 된다.\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\nV'x\n\n100-element Vector{ComplexF64}:\n  -5.756917285643587 + 0.0im\n -19.082672090492103 - 1.0178306444775291im\n   14.23050682476898 - 11.867854578090007im\n  3.8980118254428824 + 1.2603018602424476im\n  -16.15797305318818 + 27.48824632227092im\n   12.32574209329044 - 1.5134316695905325im\n  3.9542122497256385 + 15.369129638224617im\n    9.51693811050782 + 19.371467179753516im\n  -19.38292930624826 + 9.495062886234233im\n -7.8539348514784155 + 4.134711886071595im\n -14.072349901900417 - 5.945064076174276im\n -14.596266922162371 + 3.447776409279244im\n   5.857720447482956 + 5.7388951128385735im\n                     ⋮\n   5.857720447482839 - 5.738895112838781im\n -14.596266922162307 - 3.4477764092792627im\n  -14.07234990190023 + 5.945064076174198im\n  -7.853934851478599 - 4.134711886071242im\n -19.382929306248577 - 9.49506288623372im\n   9.516938110507212 - 19.371467179753736im\n  3.9542122497250025 - 15.369129638224603im\n  12.325742093290597 + 1.5134316695903638im\n  -16.15797305318867 - 27.488246322270854im\n  3.8980118254424903 - 1.2603018602428118im\n  14.230506824769146 + 11.867854578089572im\n   -19.0826720904922 + 1.0178306444775123im\n\n\n진짜 똑같은지 확인\n\nfft(x)\n\n100-element Vector{ComplexF64}:\n  -5.756917285643583 + 0.0im\n   -19.0826720904921 - 1.0178306444775302im\n  14.230506824768984 - 11.867854578089997im\n  3.8980118254428726 + 1.2603018602424614im\n -16.157973053188194 + 27.488246322270918im\n   12.32574209329046 - 1.5134316695905219im\n    3.95421224972561 + 15.369129638224624im\n   9.516938110507798 + 19.371467179753544im\n  -19.38292930624831 + 9.49506288623419im\n  -7.853934851478428 + 4.134711886071571im\n -14.072349901900408 - 5.945064076174294im\n -14.596266922162355 + 3.447776409279256im\n   5.857720447482927 + 5.738895112838594im\n                     ⋮\n   5.857720447482924 - 5.738895112838594im\n -14.596266922162352 - 3.4477764092792564im\n -14.072349901900408 + 5.945064076174294im\n   -7.85393485147843 - 4.134711886071569im\n -19.382929306248315 - 9.49506288623419im\n   9.516938110507798 - 19.37146717975354im\n  3.9542122497256105 - 15.36912963822462im\n  12.325742093290458 + 1.5134316695905206im\n -16.157973053188194 - 27.488246322270925im\n  3.8980118254428717 - 1.260301860242461im\n  14.230506824768984 + 11.867854578089993im\n -19.082672090492103 + 1.0178306444775296im\n\n\n\n\n전통적인 방법과 스펙트럼 방법의 비교\n시계열자료의 전통적인 분석과 spectral analysis는 대충 아래의 과정으로 비교 설명할 수 있다.\n\n\n\n\n\n\n\n\n단계\n전통적인 방법\n스펙트럴 분석\n\n\n\n\n1\n\\({\\bf x}\\)의 plot을 그려봄\n\\({\\bf x}\\)의 plot을 그려봄\n\n\n2\nSACF plot, SPACF plot 을 그려봄\nPSD plot을 그려봄\n\n\n3\nACF를 추정 (=ARMA(\\(p\\),\\(q\\))에 대응하는 파라메터를 추정)\n\\({\\bf p}\\)를 추정\n\n\n4\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n추정된 파라메터를 바탕으로 여러가지 분석 수행\n\n\n\n눈여겨 볼 점은 PSD plot의 존재이다. 전통적인 시계열에서 SACF plot 과 비슷하게 스펙트럼 방법에서 시계열을 분석하기 위해 필요한 매우 중요한 시각화 이다. 간단하게 비교를 하면 아래와 같다.\nSACF plot\n\nx축: lag=0, lag=1, ….\ny축: lag에 대응하는 상관계수값\n\nPSD plot\n\nx축: \\(\\Omega=\\big\\{\\frac{k}{N}:~ \\text{for}~ k=0,\\dots, N-1\\big\\}\\), 정규화된 freq를 의미함\ny축: 주파수에 대응하는 power값\n\n전통적인 방법에 비하여 스펙트럴 분석이 가지는 장점은 위의 표에서 소개한 일반적인 분석루틴이 시계열이 아닌 그래프신호로 쉽게 확장가능 하다는 점이다12. 따라서 앞으로는 전통적인 시계열 분석방법 대신 스펙트럴 분석만을 다룰 것이다. 스펙트럴 분석의 핵심적인 부분은 \\({\\bf p}\\)를 추정하는 방법과 추정량의 점근적 성질들을 파악하는 것이다. 이 포스트에서는 \\({\\bf p}\\)를 추정하는 방법만을 다룬다.\n12 퓨리에 변환대신에 그래프 퓨리에 변환을 이용하기만 하면된다"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#그래프신호에서의-psd의-추정",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "그래프신호에서의 PSD의 추정",
    "text": "그래프신호에서의 PSD의 추정\n이제 그래프 신호에서 \\({\\bf p}\\)를 추정하는 방법에 대하여 살펴보자. 그래프이동변환 (Graph Shift Operator, GSO)13 \\({\\bf S}={\\bf V}{\\bf \\Lambda}{\\bf V}^H\\)에 대하여 정상인 시계열 \\({\\bf x}\\)를 고려한다. 이 신호의 그래프퓨리에 변환14은 아래와 같이 구할 수 있다.\n13 Back shift operator의 일반화 버전14 좀 더 정확하게는 \\({\\bf V}^H\\) 에 대한 그래프 변환이라고 한다\\[\\tilde{\\bf x}={\\bf GFT} {\\bf x} = {\\bf V}^H{\\bf x}\\]\n여기에서 \\(\\tilde{\\bf x}\\)를 \\({\\bf x}\\)의 주파수응답(frequency representation)이라고 부른다.15 우리는 아래의 수식에서 \\({\\bf p}\\)의 값에 관심이 있다.\n15 이 \\(\\tilde{\\bf x}\\)를 그냥 graph Fourier transform이라고 부르는 사람도 많다. 즉 그래프퓨리에변환이 (1) 변환매트릭스 \\({\\bf GFT}\\)자체를 지칭할때도 있고 (2) 트랜스폼된 결과 \\(\\tilde{\\bf x}\\)를 지칭할때도 있음. 교재에서는 변환은 graph Fourier transform, 그리고 변환된 결과는 \\({\\bf x}\\)의 주파수응답이라고 한다.\\[{\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\]\n여기에서 \\({\\bf p}\\)를 PSD (power spectrum density) 라고 한다. \\({\\bf p}\\)가 포함된 표현식은 위의 수식 이외에도 2개가 더 있다. 이를 모두 요약하면 아래와 같다16\n16 약간의 계산을 통하면 1,2,3이 쉽게 같은 수식임을 알 수 있음\n\\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)17\n\\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n\\({\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\)\n\n17 이 수식을 살짝 정리하면 \\({\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\) 와 같이 보다 예쁜 수식을 얻을 수 있음위의 표현중 3.에서 \\({\\bf c}_{\\bf x}\\)은 \\({\\bf C}_x\\)를 벡터화한 것이며 \\({\\bf G}_{np}\\)는 \\({\\bf V}^\\ast\\) 와 \\({\\bf V}\\)를 열별-크로네커곱 (column-wise Kronecker product) 이다. 이때 \\({\\bf G}_{np}\\)의 정의가 조금 생소하니 한번 계산하여 보자.\n(예제) 아래와 같은 GSO \\({\\bf B}\\)를 고려하자.\n\nB= [0 1 0 0 \n    0 0 1 0 \n    0 0 0 1 \n    1 0 0 0]\n\n4×4 Matrix{Int64}:\n 0  1  0  0\n 0  0  1  0\n 0  0  0  1\n 1  0  0  0\n\n\n이러한 GSO에 대하여 \\({\\bf G}_{np}\\)는 아래와 같이 구할 수 있다.\n(1) \\({\\bf V}\\)를 정의\n\nV = [i*j for i in 0:3 for j in 0:3] |&gt; \n    x -&gt; reshape(x,(4,4)) .|&gt; \n    x -&gt; exp(im * (2π/4) * x) \n\n4×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n16×4 Matrix{ComplexF64}:\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im  -1.83697e-16-1.0im              5.51091e-16+1.0im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im          -1.0+1.22465e-16im             -1.0+3.67394e-16im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n 1.0+0.0im   6.12323e-17+1.0im             -1.83697e-16-1.0im\n 1.0+0.0im  -1.83697e-16+1.0im              5.51091e-16-1.0im\n 1.0+0.0im          -1.0-1.22465e-16im             -1.0-3.67394e-16im\n 1.0+0.0im   6.12323e-17-1.0im             -1.83697e-16+1.0im\n 1.0+0.0im           1.0+0.0im          …           1.0+0.0im\n\n\n위에서 언급한 표현식 1,2,3 을 이용하면 \\({\\bf p}\\)를 추정하는 세 가지 방법을 각각 정의할 수 있다. 하나씩 살펴보자.\n\n1. \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 수식 \\({\\bf C}_{\\bf x}={\\bf V} \\text{diag}({\\bf p}){\\bf V}^H\\)를 적당히 변형하면 아래를 얻을 수 있다.\n\\[{\\bf p}=\\text{diag}\\big({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V} \\big)\\]\n여기에서\n\\[{\\bf C}_{\\bf x}=\\mathbb{E}[{\\bf x}{\\bf x}^H]\\approx \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_t{\\bf x}_r^H\\]\n이므로 이 수식에 근거하여 \\({\\bf p}\\)을 추정한다면 아래와 같이 할 수 있다.\n\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H\\big[ \\frac{1}{R}\\sum_{r=1}^R{\\bf x}_r{\\bf x}_r^H\\big]{\\bf V} \\right].\\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면18, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n18 대부분은 관측한 시계열이 하나겠지..\\[\\hat{\\bf p}_{cg}:= \\text{diag}\\left({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V} \\right):=\\text{diag}\\left[{\\bf V}^H{\\bf x}_r{\\bf x}_r^H{\\bf V} \\right].\\]\n\n주의: 여기에서 \\({\\bf V}^H {\\bf C}_{\\bf x}{\\bf V}\\) 는 항상 대각행렬이지만 \\({\\bf V}^H \\hat{\\bf C}_{\\bf x}{\\bf V}\\) 은 대각행렬이 아닐수도 있음을 유의하자. 즉 이론적인 모수는 대각행렬이지만 sample version은 대각행렬이 아닐 수 있다. 대각선이 아닌 원소는 버리면 된다.)\n\n\n아이디어: 혹시 대각선이 아닌 원소들을 이용하여 오차항 \\(\\epsilon_t\\)의 분산을 추정할 수도 있지 않을까? 이미 연구가 있겠지?\n\n(예제)\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n\np̂ = diag(V' * (x*x') * V)\n\n100-element Vector{ComplexF64}:\n 33.142096633741986 + 0.0im\n 365.18435333408354 + 1.5376069362644531e-13im\n  343.3532967764883 + 6.904176529646917e-14im\n 16.782856970223083 - 3.5538396658301444e-14im\n 1016.6837790613963 + 5.475049904926759e-15im\n 154.21439356883144 + 6.4512443306088e-14im\n  251.8459403524346 + 2.1316282072803006e-14im\n 465.82585169550384 + 1.816929057526117e-13im\n 465.85416770456044 + 4.1584439183295984e-14im\n    78.780135032089 + 1.3472456770553478e-14im\n 233.37481863133462 + 6.315728724701355e-14im\n 224.93817023139385 - 3.472109560086835e-14im\n  67.24780595702241 + 7.105427357601002e-14im\n                    ⋮\n   67.2478059570233 + 6.384723798533952e-14im\n 224.93817023139195 + 1.9727655769954595e-14im\n 233.37481863132837 - 2.1872689567834747e-14im\n    78.780135032089 + 1.917599080404094e-14im\n 465.85416770456294 + 4.808950231511622e-14im\n 465.82585169550094 - 4.890486289860305e-14im\n  251.8459403524291 + 2.0146681724568905e-14im\n  154.2143935688347 - 1.0948596967617507e-13im\n 1016.6837790614081 + 1.2114814701286432e-13im\n  16.78285697022108 + 2.376159104534641e-14im\n 343.35329677648286 + 1.1310381241837407e-14im\n 365.18435333408746 + 4.574214786667376e-14im\n\n\n\n\n2. \\({\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf p}=\\mathbb{E}\\left[|{\\bf V}^H{\\bf x}|^2\\right]\\approx \\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n따라서 \\(\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2\\) 를 PSD \\({\\bf p}\\)에 대한 추정량이라고 생각할 수 있다. 이러한 추정량을 기호로 \\(\\hat{\\bf p}_{pg}\\)라고 정의하고 periodogram이라고 부른다. 즉\n\\[\\hat{\\bf p}_{pg}=\\frac{1}{R}\\sum_{r=1}^{R} |{\\bf V}^H {\\bf x}_r|^2 \\]\n만약에 확률과정 \\({\\bf x}\\)에서 관측한 시계열이 \\({\\bf x}_r\\) 하나라면, 즉 \\(R=1\\) 이라면 단순히 아래와 같이 쓸 수 있다.\n\\[\\hat{\\bf p}_{pg}=|{\\bf V}^H {\\bf x}_r|^2 \\]\n즉 이 경우 \\(\\hat{\\bf p}_{pg}\\)는 단순히 관측시계열 \\({\\bf x}_r\\)의 그래프 퓨리에 변환 \\(\\tilde{\\bf x}={\\bf V}^H{\\bf x}_r\\) 결과에 절대값을 취하고 제곱한 것과 같다.\n(예제)\n스펙트럼방법챕터 예제2에서 이미 보여준 적 있다. 주어진 시계열 \\({\\bf x}\\)에 대하여 \\(\\hat{\\bf p}_{pg}\\)를 구하는 방법을 요약하면 아래와 같다.\n\nx̃ = fft(x) # 단계1: GFT, 이 신호는 시계열이라서 GFT대신에 DFT를 써도 된다.\np̂ = abs.(x̃).^2 # 단계2: hat p\n\n100-element Vector{Float64}:\n   33.14209663374188\n  365.18435333408365\n  343.3532967764883\n   16.782856970223087\n 1016.6837790613963\n  154.21439356883184\n  251.84594035243464\n  465.8258516955045\n  465.85416770456163\n   78.78013503208902\n  233.37481863133453\n  224.93817023139349\n   67.24780595702228\n    ⋮\n   67.24780595702225\n  224.93817023139337\n  233.37481863133453\n   78.78013503208902\n  465.8541677045618\n  465.8258516955044\n  251.84594035243452\n  154.2143935688318\n 1016.6837790613968\n   16.782856970223072\n  343.3532967764882\n  365.1843533340838\n\n\n\n\n3. \\({\\bf c}_{\\bf x} = {\\bf G}_{np} {\\bf p}\\)\n확률과정 \\({\\bf x}\\)에서 \\(R\\)개의 realization \\(\\{{\\bf x}_1 \\dots {\\bf x}_R\\}\\) 을 관측하였다고 하자. 아래의 수식을 관찰하자.\n\\[{\\bf C}_{\\bf x} = {\\bf V} \\text{diag}({\\bf p}) {\\bf V}^H\\]\n이 수식으로부터 아래를 얻을 수 있다.\n\\[{\\bf c}_{\\bf x} = \\sum_{i=1}^{N}p_i \\text{vec}({\\bf v}_i{\\bf v}_i^H) = {\\bf G}_{np} {\\bf p}\\]\n여기에서 \\({\\bf c}_{\\bf x}\\) 대신에 \\(\\hat{\\bf c}_{\\bf x}\\) 를 대입하면 아래와 같이 생각할 수 있다.\n\\[\\hat{\\bf c}_{\\bf x} \\approx  {\\bf G}_{np} {\\bf p}\\]\n이 문제는 아래와 같은 회귀모형으로 생각할 수 있다.\n\n\n\n\n\n\n\n\n\n회귀모형\n우리의 문제\n\n\n\n\n모형\n\\({\\bf y} \\approx {\\bf X}{\\boldsymbol \\beta}\\)\n\\(\\hat{\\bf c}_{\\bf x} \\approx {\\bf G}_{np}{\\bf p}\\)\n\n\n설명변수\n\\({\\bf X}\\)19\n\\({\\bf G}_{np}\\)20\n\n\n반응변수\n\\({\\bf y}\\)21\n\\(\\hat{\\bf c}_{\\bf x}\\)22\n\n\n추정하고 싶은 파라메터\n\\({\\boldsymbol \\beta}\\)23\n\\(\\hat{\\bf p}\\)24\n\n\n오차항\n대부분 정규분포를 가정\n??? 모르겠는데??\n\n\n\n19 (n,p) matrix20 (N²,N) matrix21 (n,1) col-vector22 (N²,1) col-vector23 (p,1) col-vector24 (N,1) col-vector회귀분석에서 아래의 수식이 익숙하다면\n\\[\n\\hat{\\boldsymbol \\beta}_{ls} = \\underset{\\boldsymbol \\beta}{\\operatorname{argmin}} \\|{\\bf y}-{\\bf X}{\\boldsymbol \\beta}\\|_2^2=({\\bf X}^T{\\bf X})^{-1}{\\bf X}^T{\\bf y}.\n\\]\n\\({\\bf p}\\)를 추정하기 위한 아래의 수식도 쉽게 이해할 수 있다. (의문: 그런데 왜 MSE를 손실함수로 쓰고 있는 거야? 오차항이 설마 정규분포?)\n\\[\n\\hat{\\bf p}_{ls} = \\underset{\\bf p}{\\operatorname{argmin}} \\|\\hat{\\bf c}_{\\bf x}-{\\bf G}_{np}{\\bf p}\\|_2^2=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}.\n\\]\n(예제)\n(1) \\({\\bf V}\\)를 정의\n\nN = 100 \nV = [i*j for i in 0:(N-1) for j in 0:(N-1)] |&gt; \n    x -&gt; reshape(x,(N,N)) .|&gt; \n    x -&gt; exp(im * (2π/N) * x)\n\n100×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.728969-0.684547im      0.728969+0.684547im\n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im   …  0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im      0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im   …  0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im       0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n\n\n(2) \\({\\bf G}_{np}={\\bf V}^{\\ast} \\odot {\\bf V}\\), 여기에서 \\(\\odot\\)은 열별-크로네커곱을 의미한다.\n\n# columnwise_kron은 위에서 정의한적 있음~\nGₙₚ = columnwise_kron(conj(V),V)\n\n10000×100 Matrix{ComplexF64}:\n 1.0+0.0im       1.0+0.0im        …       1.0+0.0im\n 1.0+0.0im  0.998027+0.0627905im     0.998027-0.0627905im\n 1.0+0.0im  0.992115+0.125333im      0.992115-0.125333im\n 1.0+0.0im  0.982287+0.187381im      0.982287-0.187381im\n 1.0+0.0im  0.968583+0.24869im       0.968583-0.24869im\n 1.0+0.0im  0.951057+0.309017im   …  0.951057-0.309017im\n 1.0+0.0im  0.929776+0.368125im      0.929776-0.368125im\n 1.0+0.0im  0.904827+0.425779im      0.904827-0.425779im\n 1.0+0.0im  0.876307+0.481754im      0.876307-0.481754im\n 1.0+0.0im  0.844328+0.535827im      0.844328-0.535827im\n 1.0+0.0im  0.809017+0.587785im   …  0.809017-0.587785im\n 1.0+0.0im  0.770513+0.637424im      0.770513-0.637424im\n 1.0+0.0im  0.728969+0.684547im      0.728969-0.684547im\n    ⋮                             ⋱  \n 1.0+0.0im  0.770513-0.637424im      0.770513+0.637424im\n 1.0+0.0im  0.809017-0.587785im      0.809017+0.587785im\n 1.0+0.0im  0.844328-0.535827im   …  0.844328+0.535827im\n 1.0+0.0im  0.876307-0.481754im      0.876307+0.481754im\n 1.0+0.0im  0.904827-0.425779im      0.904827+0.425779im\n 1.0+0.0im  0.929776-0.368125im      0.929776+0.368125im\n 1.0+0.0im  0.951057-0.309017im      0.951057+0.309017im\n 1.0+0.0im  0.968583-0.24869im    …  0.968583+0.24869im\n 1.0+0.0im  0.982287-0.187381im      0.982287+0.187381im\n 1.0+0.0im  0.992115-0.125333im      0.992115+0.125333im\n 1.0+0.0im  0.998027-0.0627905im     0.998027+0.0627905im\n 1.0+0.0im       1.0+0.0im                1.0+0.0im\n\n\n(3) \\(\\hat{\\bf p}_{ls}=({\\bf G}_{np}^H{\\bf G}_{np})^{-1}{\\bf G}_{np}^H\\hat{\\bf c}_{\\bf x}\\)\n\nĉₓ = vec(x*x')\np̂ = inv(Gₙₚ' * Gₙₚ) * Gₙₚ' * ĉₓ \n\n100-element Vector{ComplexF64}:\n  0.003314209663374193 - 2.7356277964988863e-19im\n   0.03651843533340838 - 4.01518191768058e-18im\n   0.03433532967764885 + 2.515448157755484e-17im\n 0.0016782856970223292 - 1.0070028487673847e-17im\n   0.10166837790613971 + 3.1129277935880596e-18im\n  0.015421439356883134 + 9.403422807142065e-18im\n  0.025184594035243472 - 3.993782799800785e-18im\n   0.04658258516955039 - 1.850761436988587e-18im\n   0.04658541677045607 + 1.1559103895961936e-17im\n  0.007878013503208905 + 3.559698092088507e-18im\n  0.023337481863133468 + 2.6204945155857973e-18im\n   0.02249381702313939 + 5.304406111488559e-18im\n  0.006724780595702225 - 1.655564138463681e-17im\n                       ⋮\n  0.006724780595702329 + 1.8121162053534517e-18im\n  0.022493817023139205 - 1.0461976779111972e-17im\n   0.02333748186313285 - 6.792203007975684e-18im\n  0.007878013503208907 - 2.3575339315335667e-18im\n  0.046585416770456294 + 1.5392042695643853e-17im\n  0.046582585169550106 - 1.123245521985718e-17im\n  0.025184594035242928 + 1.1628578774983873e-18im\n  0.015421439356883466 + 5.864828990948797e-18im\n   0.10166837790614085 + 2.2712943512935246e-17im\n 0.0016782856970221013 + 4.829637376114682e-18im\n   0.03433532967764831 + 3.3208196889839756e-19im\n  0.036518435333408754 + 1.3795822112205515e-17im\n\n\n\n?? 뭔가 스케일이 안맞음\n\n\nN^2 * p̂\n\n100-element Vector{ComplexF64}:\n  33.14209663374193 - 2.7356277964988864e-15im\n 365.18435333408377 - 4.0151819176805797e-14im\n  343.3532967764885 + 2.515448157755484e-13im\n 16.782856970223293 - 1.0070028487673847e-13im\n 1016.6837790613971 + 3.1129277935880596e-14im\n 154.21439356883135 + 9.403422807142065e-14im\n 251.84594035243472 - 3.9937827998007846e-14im\n  465.8258516955039 - 1.850761436988587e-14im\n  465.8541677045607 + 1.1559103895961937e-13im\n  78.78013503208905 + 3.559698092088507e-14im\n 233.37481863133468 + 2.6204945155857973e-14im\n 224.93817023139388 + 5.304406111488559e-14im\n  67.24780595702225 - 1.655564138463681e-13im\n                    ⋮\n  67.24780595702329 + 1.8121162053534517e-14im\n 224.93817023139206 - 1.0461976779111972e-13im\n  233.3748186313285 - 6.792203007975684e-14im\n  78.78013503208906 - 2.3575339315335666e-14im\n 465.85416770456294 + 1.5392042695643854e-13im\n 465.82585169550106 - 1.123245521985718e-13im\n 251.84594035242927 + 1.1628578774983874e-14im\n 154.21439356883465 + 5.864828990948797e-14im\n 1016.6837790614085 + 2.2712943512935246e-13im\n  16.78285697022101 + 4.8296373761146824e-14im\n  343.3532967764831 + 3.3208196889839758e-15im\n  365.1843533340875 + 1.3795822112205514e-13im\n\n\n\n\\(N^2\\)를 곱해주니까 아까부터 구하던 값이 그대로 잘 나옴. (\\({\\bf DFT}\\) 혹은 \\({\\bf GFT}\\)를 정의할때 \\(\\frac{1}{\\sqrt N}\\)으로 스케일링 하느냐 마느냐 차이때문에 생기는 현상임)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "href": "posts/2_Studies/GRAPH/2022-12-27-Chap-12.2.1~12.3.1.html#의문점",
    "title": "[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators",
    "section": "의문점",
    "text": "의문점\n아래의 그림을 살펴보자.\n\n\n\n그림12.3(교재에서 긁어온 그림): Power spectral density estimation. All estimators are based on the same random process defined on the Karate club network (Zachary 1977). (A) Periodogram estimation with different numbers of observations. (B) Windowed average periodogram from a single realization and a different number of windows. (C) Windowed average periodogram for four windows and a varying number of realizations. (D) Parametric MA estimation for 1 and 10 realizations.\n\n\n이 그림은 다양한 방법으로 true PSD \\({\\bf p}\\)를 추정한 결과를 나타내는 PSD plot 이다25. 우리가 적용한 방법은 (A)에서 \\(R=1\\)일 경우이다. 보는것 처럼 true PSD 를 놀라울 정도로 제대로 추정하지 못한다26. 만약에 우리가 모형에서 하나의 시계열이 아니라 1000개의 정도의 시계열을 관측하였다면 좀 더 합리적으로 추정할 수 있다. 그런데 사실 하나의 모형에서 1000개씩이나 되는 시계열을 관측하는 일은 현실적으로 불가능하다27 따라서 우리는 비교적 적은 \\(R\\)에서 합리적인 PSD의 추정치를 이끌어내야 한다. 그림 (B),(C)는 상대적으로 적은 \\(R\\)에 대해 \\({\\bf p}\\)를 추정하는 windowed periodogram 을 이용하여 PSD를 추정한 결과이다. (C)를 살펴보면 \\(R=1\\) 일경우 \\({\\bf p}\\)를 추정한 값들이 나와있는데 (A)와 비교하면 꽤 합리적으로 보인다.\n25 x축이 freq, y축이 PSD26 맞추는게 없는 것 같은데?27 그리고 대부분 \\(R=1\\)이지..28 약간 바이어스가 있어보이긴 하는데, 우연히 생긴건지 이론적으로 항상 생기는 건지는 잘 모르겠네?29 이런걸 세미파라메트릭 모형이라고 해요30 그래서 플랏을 보면서 적당한 ARMA를 찾을 필요도 없고, AIC 니 BIC 를 따져가면서 모형선택을 할 필요도 없고31 적합이후에 잔차분석 같은거 안해도 된다는 의미문제는 (A)-(C)에서 제안된 방법 모두가 (D)에 제시된 전통적인 방법에 비하여 퍼포먼스가 떨어진다는 것이다. (D)는 parametric 모형을 사용한 결과이다. 파라메트릭 방법이므로 특정 모델을 한정하고 거기에 대응하는 한두개의 모수만 추정하면 되므로 추정이 잘 된다.28 반면 (A)-(C)의 경우 한 두개의 파라메터가 아니라 \\({\\bf p}\\)의 모든 원소를 추정해야하므로 추정할 파라메터가 데이터의 수 \\(N\\)과 같다29. 따라서 추정치의 분산이 크다. 사실 이것은 파라메트릭 방법과 세미파라메트릭 방법이라는 구조적인 차이때문에 어쩔 수 없는 것 같다. 그래도 세미파라메트릭 방법은 머리아프게 모델링을 할 필요가 없고30 내가 적합한 모델이 맞는지 확인할 필요도 없다31는 장점이 있다.\n아래는 나름 PSD를 추정하는 신기술인 것 같다.\n\n\n\n그림12.4(교재에서 긁어온 그림): PSD estimation from a subset of nodes. Estimators are based on a random process defined on the Karate club network (Zachary 1977). (A) Graph sampling for nonparametric PSD estimation. Here, 20 out of 34 nodes are observed. The sampled nodes are highlighted by the circles around the nodes. (B) Nonparametric PSD estimation based on observations from 20 nodes and 100 data snapshots. (C) Graph sampling for parametric MA PSD estimation. Here, 4 out of 34 nodes are observed. (D) Parametric MA PSD estimation based on observations from 4 nodes and 100 data snapshots.\n\nZachary, Wayne W. 1977. “An Information Flow Model for Conflict and Fission in Small Groups.” Journal of Anthropological Research 33 (4): 452–73.\n\n\n그래프신호의 sub-sampling을 이용하는 것 같은데 교재의 뒤쪽에 서술되어있다. \\(R=100\\)임을 고려하여도 퍼포먼스가 좋은 편인듯 하다32.\n\n\n32 내 생각엔 이게 핵심 기술인 것 같음"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-06-30-Graph Signal.html",
    "href": "posts/2_Studies/GRAPH/2023-06-30-Graph Signal.html",
    "title": "Graph Signal",
    "section": "",
    "text": "Summary\n\nthe given signal is observed on a graph \\({\\cal G}:=({\\cal V},{\\cal E})\\)\n\n\\({\\cal V}\\) represents the set of nodes\n\\({\\cal E}\\) represents the set of edges (links)\nwe have observed a real-valued signal, denoted as \\(y: V \\to \\mathbb{R}\\)\n\n\nImport\n\nimport numpy as np\nimport networkx as nx\nimport matplotlib.pyplot as plt\n\n\n\nGraph Signal\n\n\n\nFigure: A random positive graph signal on the vertices of the Petersen graph. The height of each blue bar represents the signal value at the vertex where the bar originates (Shuman et al. 2013)\n\nShuman, David I, Sunil K Narang, Pascal Frossard, Antonio Ortega, and Pierre Vandergheynst. 2013. “The Emerging Field of Signal Processing on Graphs: Extending High-Dimensional Data Analysis to Networks and Other Irregular Domains.” IEEE Signal Processing Magazine 30 (3): 83–98.\n\n\nSuppose we have observed a real-valued signal, denoted as \\(y: V \\to \\mathbb{R}\\), from a graph \\({\\cal G} = (V, E)\\), where \\(V\\) represents the set of nodes and \\(E\\) represents the set of edges."
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html",
    "href": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html",
    "title": "Non-Euclidean vs Euclidean",
    "section": "",
    "text": "Regular Graph?\n\nSummary\n\n\nEuclidean data\n\nunderlying function이 regular graph로 정의가 가능한 data\nunderline(domain)이 euclidean domain에 위치한 데이터(x축, 1d-grid, 2d-grid 등)\neuclidean distance로 계산할 수 있는 data\n\nNon-Euclidean data\n\nunderlying function이 regular graph로 정의가 가능하지 않은 data\nunderline(domain)이 non-euclidean domain에 위치한 데이터(곡선, 곡면 등)\neuclidean distance calculation이 not reasonable한 data\n\n\n\n\n\n\n\n\nGraph vs Manifold\n\n\n\n\n굳이 포함관계를 따지자면, Non-Euclidean &gt; Graph &gt; Manifold\nNon-Euclidean\n\nGraph\n\n거리는 Edge 나 weight 로 정의함.\n\nManifold(ex. swiss roll, 아래 예시 있음!)\n\nunderline = domain(swiss roll에서 말린 곡면)\nunderlying function = color(swiss roll에서 무지개 색)\n유한한 그래프 시그널로 표현 가능\n\n무한한 노드에서 realization sample 뽑고,\n그래프로 가져오려면 distance 정의 수정이 필요하다.\n\n수정하는 방법\n\n\\(W_{i,j} = \\begin{cases} \\exp\\left(-\\frac{\\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2}{2\\theta^2}\\right) & \\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2 \\le \\kappa \\\\ 0 & o.w\\end{cases}\\)를 사용하여 가까운 것만 거리 계산하도록 하기, 곡선은 유클리디안 거리를 semi 사용하고(이 식에서 \\(\\kappa\\)로 먼 거리는 자르니까), 곡면은 하버사인 거리를 사용.\nsimilarity(유사도) 따지기(ex. 몇 번 건너서 다음 노드로 가는지 등)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html#euclidean",
    "href": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html#euclidean",
    "title": "Non-Euclidean vs Euclidean",
    "section": "Euclidean",
    "text": "Euclidean\n\nEx1) 1D grid\n\nText, etc.\n\n\n\n\nFigure: Sentence, word, sound: 1D Euclidean domains. This image is sourced from the PAM Workshop “New Deep Learning Techniques” Feb 7th 2017\n\n\n\nw=np.zeros((5,5))\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif i-j == 1 : \n            w[i,j] = 1\n\n\nlst = []\nfor i in range(5):\n    for j in range(5):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\n\n\n\n\n\nNote\n\n\n\n모든 Degree가 동일한, 특히 단위행렬로 나오는(Regular graph인) 유클리디안 데이터\n\n\n\nD\n\narray([[0., 0., 0., 0., 0.],\n       [0., 1., 0., 0., 0.],\n       [0., 0., 1., 0., 0.],\n       [0., 0., 0., 1., 0.],\n       [0., 0., 0., 0., 1.]])\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(20, 5)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)\n\n\n\n\n\n\n\n\n\n\nEx2) 2d grids\n\nImage, etc.\n\n\n\n\nFigure: Image, volume, video: 2D, 3D, 2D+1 Euclidean domains. This image is sourced from the PAM Workshop “New Deep Learning Techniques” Feb 7th 2017\n\n\n\nw = np.ones((4, 4))\nfor i in range(4):\n    for j in range(4):\n        if i==j :\n            w[i,j] = 0\n\n\nlst = []\nfor i in range(4):\n    for j in range(4):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nd= w.sum(axis=1)\nD= np.diag(d)\n\n\n\n\n\n\n\nNote\n\n\n\n모든 Degree가 동일하여 \\(D = 3I\\)로 표현되는(Regular graph인) 유클리디안 데이터\n\n\n\nD\n\narray([[3., 0., 0., 0.],\n       [0., 3., 0., 0.],\n       [0., 0., 3., 0.],\n       [0., 0., 0., 3.]])\n\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)"
  },
  {
    "objectID": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html#non-euclidean",
    "href": "posts/2_Studies/GRAPH/2023-07-01-Euclidean_nonEuclidean.html#non-euclidean",
    "title": "Non-Euclidean vs Euclidean",
    "section": "Non-Euclidean",
    "text": "Non-Euclidean\n\nEx3) Different Weights\n\nWeight 같다고 가정하고 그래프 시각화\n\n\nw=np.zeros((5,5))\nfor i in range(5):\n    for j in range(5):\n        if i==j :\n            w[i,j] = 0\n        elif i!=j: \n            w[i,j] = 1\n\n\nlst = []\nfor i in range(5):\n    for j in range(5):\n        if w[i,j] == 1:\n            lst.append([i,j])\n\n\nG = nx.Graph()\n\n\nG.add_edges_from(np.array(lst))\n\n\nplt.figure(figsize=(10, 10)) \nnx.draw_networkx(G, with_labels=True, font_weight='bold', node_color='orange', node_size=1500, font_color='white', font_size=30,width=5)\n\n\n\n\n\n\n\n\n\npi=np.pi\nang=np.linspace(-pi,pi-2*pi/5,5)\nr=5+np.cos(np.linspace(0,12*pi,5))\nvx=r*np.cos(ang)\nvy=r*np.sin(ang)\nf1=10*np.sin(np.linspace(0,6*pi,5))\nf = f1 + np.random.normal(5)\n\n\nD = np.zeros([5,5])\nlocations = np.stack([vx, vy],axis=1)\nfor i in range(5):\n    for j in range(i,5):\n        D[i,j]=np.linalg.norm(locations[i]-locations[j])\nD = D + D.T\n\n\nD\n\narray([[ 0.        ,  6.0964895 , 11.4126782 ,  9.53062515,  7.05342303],\n       [ 6.0964895 ,  0.        ,  6.0964895 ,  7.60845213,  9.53062515],\n       [11.4126782 ,  6.0964895 ,  0.        ,  6.0964895 , 11.4126782 ],\n       [ 9.53062515,  7.60845213,  6.0964895 ,  0.        ,  6.0964895 ],\n       [ 7.05342303,  9.53062515, 11.4126782 ,  6.0964895 ,  0.        ]])\n\n\n\n\n\n\n\n\nNote\n\n\n\n가중치 값이 다 다르게 형성되어 있다. 따라서 \\(D=kI\\)형태로도 표현할 수 없어 레귤러 메트릭스의 정의를 충족하지 못하며, 이는 비유클리디안 데이터이다.\n\n\n\n\nEx3) Non-Euclidean data with Non-Euclidean domain\n\ndegree matrix가 단위행렬이 아니어서 레귤러 그래프가 아닌 그래프\n\n\n1. 3D shape, Manifold\n\n도메인이 표면(컵)이며, underlying function 이 regular graph로 정의되지 않는다.\n\nreference\n\n\n\nFigure: Surface (non-Euclid data). This image is sourced from the (Fall 2020 course website for Non-Euclidean Methods in Machine Learning (CS468), Stanford University)\n\n\n\n\n2. 3D shape, Manifold\n\n도메인이 구로 형성되어 있고, graph로 인지 시, underlying function 이 색(파란색)으로 볼 수 있고, 다른 색으로 구성된 것은 \\(\\eta\\)로 볼 수 있고, regular graph로 정의되지 않는다.\n\n간단 \\(\\eta\\) 정의 review = noise 이지만, 특정 i에서 값이 큰 nois를 갖음\n\n\n\nFigure: Distributions on 3D shapes (non-Euclid data). This image is sourced from the Fall 2020 course website for Non-Euclidean Methods in Machine Learning (CS468), Stanford University\n\n\n\n\n3. 3D shape, Manifold\n\n도메인이 표면(고양이)이며, underlying function 이 색이라고 할 수 있다.\n\n\n\n\nFigure: Functions on manifolds (non-Euclid data). This image is sourced from the Fall 2020 course website for Non-Euclidean Methods in Machine Learning (CS468), Stanford University\n\n\n\n\n4. 3D shape, Manifold\n\n도메인이 표면이며, underlying function 이 색이다. graph로 볼 때 regular graph로 정의되지 않는다.\n\nreference\n\n\n\nFigure: General manifolds (non-Euclid data). This image is sourced from the (Fall 2020 course website for Non-Euclidean Methods in Machine Learning (CS468), Stanford University)\n\n\n\n\n5. Graph\n\n도메인이 노드인 graph. underlying function 은 정의할 수 없지만 굳이 따지자면 Classification work. 신경망 모양..\n\nreference\n\n\n\nFigure: Graphs networks (non-Euclid data). This image is sourced from the [Fall 2020 course website for Non-Euclidean Methods in Machine Learning (CS468), Stanford University]\n\n\n\n\n6. Graph(Manifold?)\n\n위의 정의 참고, 노드가 도메인인 graph. 색이 underlying function.\n\nSwiss roll (non-euclid data) from (Das and Pal 2021)\n\n\n\nFigure: Swiss roll (non-euclid data) from Das and Pal (2021)\n\nDas, Suchismita, and Nikhil R Pal. 2021. “Nonlinear Dimensionality Reduction for Data Visualization: An Unsupervised Fuzzy Rule-Based Approach.” IEEE Transactions on Fuzzy Systems 30 (7): 2157–69.\n\n\n\n\n7. Graph\n\n도메인이 노드이며, classification work\n\n\n\n\nFigure: Brain network (non-Euclid data) from Ginestet, Fournel, and Simmons (2014)\n\nGinestet, Cedric E, Arnaud P Fournel, and Andrew Simmons. 2014. “Statistical Network Analysis for Functional MRI: Summary Networks and Group Comparisons.” Frontiers in Computational Neuroscience 8: 51.\n\n\n\n\n8. Graph Signal\n\n도메인이 노드(택시 탄 장소)이며, underlying function 이 색(택시 픽업 얼마나 하는지를 나타냄, 많이 할 수록 레드쪽으로) regular graph로 정의되지 않는다.\n\n\n\n\nFigure: Taxi-pickup distribution in Manhattan (non-euclid data) from Ortega et al. (2018)\n\n\n\n\n9. Graph signal, spatiotemporal data\n\n도메인이 노드(sequence)이며, underlying function 이 regular graph로 정의되지 않는다.(파란색인 양의 signal, 검정색인 음의 signal로 mapping되어 있는 graph signal의 형태)\n\n\n\n\nFigure: Minnesota road graph (non-euclid data) from Shuman et al.(2013)\n\n\n\n\n10. Graph(Sequence), dynamic spatiotemporal data\n\n도메인이 표면(사람,motion을 sequence로 전달)이며, dynamic spatiotemporal data\n\n\n\n\nFigure: 3D point cloud sequence (non-euclid data) from (Ortega et al. 2018)\n\nOrtega, Antonio, Pascal Frossard, Jelena Kovačević, José MF Moura, and Pierre Vandergheynst. 2018. “Graph Signal Processing: Overview, Challenges, and Applications.” Proceedings of the IEEE 106 (5): 808–28."
  },
  {
    "objectID": "posts/3_Researches/ITTGNN/2023-05-18-Self Consistency toy ex.html",
    "href": "posts/3_Researches/ITTGNN/2023-05-18-Self Consistency toy ex.html",
    "title": "Self Consistency Toy ex",
    "section": "",
    "text": "Self Consistency\nRef: Self Consistency: A General Recipe for Wavelet Estimation With Irregularly-spaced and/or Incomplete Data\n\\[\\mathbb{E}(\\hat{f}_{com} | f = \\hat{f}_{obs}) = \\hat{f}_{obs}\\]"
  },
  {
    "objectID": "posts/3_Researches/ITTGNN/2023-05-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "href": "posts/3_Researches/ITTGNN/2023-05-18-Self Consistency toy ex.html#self-consistency-how-does-it-work",
    "title": "Self Consistency Toy ex",
    "section": "2 Self Consistency: How Does It Work?",
    "text": "2 Self Consistency: How Does It Work?\n\n2.1 Self-consistency: An Intuitive Principle\n책에서의 가정\n\n\\(x = 0,1,2,3,\\dots,16\\)으로 fixed 되어 있음.\n\\(y_0,\\dots, y_{13}\\)까지의 값을 알고 있는데 \\(y_{14},y_{15},y_{16}\\)의 값은 모른다.\n\n\\(y_i=\\beta x_i + \\epsilon_i, i=1,\\dots,n, \\epsilon_i \\sim \\text{i.i.d.}F(0,\\sigma^2)\\)\n\n\\(\\beta\\)의 최소제곱추정치\n\n\\(\\hat{\\beta}_n = \\hat{\\beta}_n(y_1 ,\\dots,y_n) = \\frac{\\sum^n_{i=1} y_i x_i}{\\sum^n_{i=1} x_i^2}\\)\n\n단, \\(m&lt;n\\) 이고, \\(\\sum ^n_{m+1} x_i^2 &gt; 0\\) 일 때,\n\n\\(E(\\hat{\\beta}_n|y_a, \\dots,y_m,;\\beta = \\hat{\\beta}_m) = \\hat{\\beta}_m\\)\nthe least-squares estimator has a (Martingale-like property)1, and reaches a perfect equilibrium in its projective properties\n1 확률 과정 중 과거의 정보를 알고 있다면 미래의 기댓값이 현재값과 동일한 과정참고;(위키백과)[https://ko.wikipedia.org/wiki/%EB%A7%88%ED%8C%85%EA%B2%8C%EC%9D%BC]\n\n\\(\\beta_n\\)을 구한다.\n\\(\\beta_n \\times x\\) 를 구한다.\nmissing 값이 있는 index만 대체한다.\n다시 \\(\\beta_n\\)을 구한다.\n.. 반복\n\n\\(\\beta\\)의 선형성 때문에 가능한 이론\n아래 계산하면 맞아야 함\n\\(\\hat{\\beta}_n = \\frac{\\sum_{i=1}^m y_i x_i + \\hat{\\beta}_m \\sum_{i=m+1}^n x_i^2}{\\sum_{i=1}^n x_i^2}\\)\n\n\n2.2 A Self–consistent Regression Estimator\n목적은 최적의 \\(\\hat{f}_{com}\\) 찾는 것, 일단 이 paper는 웨이블릿에 중점을 두고 비모수, 준모수 회귀로 확장 가능 누적 분포 함수 CDF 찾는 것이 목적"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-27-HCAM_study.html",
    "href": "posts/3_Researches/HCAM/2023-10-27-HCAM_study.html",
    "title": "[HCAM]Study",
    "section": "",
    "text": "CNN의 일반적인 구조 : Input layer - Conv Layers - FC layers\n\n\n\n완전 연결 계층; 한 뉴런이 다음 단계 뉴런과 모두 연결되어 있는 상태(= Dense Layer)\n\n예를 들어 flatten 해서 Relu 취하고 Softmax 취하면 이 세 과정이 다 fc layer에 포함된다.\n흑백 이미지 같은 경우에는 흑백으로 표현되어 1차 배열로 flatten 하는데 문제가 없지만 RGB를 모두 표현하는 색 있는 이미지 같은 경우에는 flatten하여 fc layers를 진횅시킨다면 정보 손실 등의 우려가 생긴다."
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-27-HCAM_study.html#fc-layer-fully-connected-layer",
    "href": "posts/3_Researches/HCAM/2023-10-27-HCAM_study.html#fc-layer-fully-connected-layer",
    "title": "[HCAM]Study",
    "section": "",
    "text": "완전 연결 계층; 한 뉴런이 다음 단계 뉴런과 모두 연결되어 있는 상태(= Dense Layer)\n\n예를 들어 flatten 해서 Relu 취하고 Softmax 취하면 이 세 과정이 다 fc layer에 포함된다.\n흑백 이미지 같은 경우에는 흑백으로 표현되어 1차 배열로 flatten 하는데 문제가 없지만 RGB를 모두 표현하는 색 있는 이미지 같은 경우에는 flatten하여 fc layers를 진횅시킨다면 정보 손실 등의 우려가 생긴다."
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html",
    "title": "[CAM]Other Methods",
    "section": "",
    "text": "https://pythonrepo.com/repo/jacobgil-pytorch-grad-cam\nhttps://github.com/jacobgil/pytorch-grad-cam"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAM",
    "text": "Cat_GradCAM\n\nCat_GradCAM_Original\n\ngradcam_original = GradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcam_original = gradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_GradCAM_Randombox\n\ngradcam_randombox = GradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcam_randombox = gradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_gradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAM",
    "text": "Dog_GradCAM\n\nDog_GradCAM_Original\n\ncam_dog_gradcam_original = gradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_GradCAM_Randombox\n\ncam_dog_gradcam_randombox = gradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Cat_HiResCAM",
    "text": "Cat_HiResCAM\n\nCat_HiResCAM_Original\n\nhirescam_original = HiResCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_hirescam_original = hirescam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_HiResCAM_Randombox\n\nhirescam_randombox = HiResCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_hirescam_randombox = hirescam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_hirescam",
    "title": "[CAM]Other Methods",
    "section": "Dog_HiResCAM",
    "text": "Dog_HiResCAM\n\nDog_HiResCAM_Original\n\ncam_dog_hirescam_original = hirescam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_HiResCAM_Random\n\ncam_dog_hirescam_randombox = hirescam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Cat_ScoreCAM",
    "text": "Cat_ScoreCAM\n\nCat_ScoreCAM_Original\n\nscorecam_original = ScoreCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_scorecam_original = scorecam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 32/32 [00:26&lt;00:00,  1.23it/s]\n100%|██████████| 32/32 [00:25&lt;00:00,  1.27it/s]\n100%|██████████| 32/32 [00:25&lt;00:00,  1.26it/s]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_ScoreCAM_Randombox\n\nscorecam_randombox = ScoreCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_scorecam_randombox = scorecam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 32/32 [00:25&lt;00:00,  1.25it/s]\n100%|██████████| 32/32 [00:25&lt;00:00,  1.26it/s]\n100%|██████████| 32/32 [00:25&lt;00:00,  1.26it/s]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_scorecam",
    "title": "[CAM]Other Methods",
    "section": "Dog_ScoreCAM",
    "text": "Dog_ScoreCAM\n\nDog_ScoreCAM_Original\n\ncam_dog_scorecam_original = scorecam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 32/32 [00:25&lt;00:00,  1.25it/s]\n100%|██████████| 32/32 [00:25&lt;00:00,  1.27it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_ScoreCAM_Randombox\n\ncam_dog_scorecam_randombox = scorecam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.30it/s]\n100%|██████████| 32/32 [00:24&lt;00:00,  1.29it/s]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Cat_GradCAMPlusPlus",
    "text": "Cat_GradCAMPlusPlus\n\nCat_GradCAMPlusPlus_Original\n\ngradcamplusplus_original = GradCAMPlusPlus(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_GradCAMPlusPlus_Randombox\n\ngradcamplusplus_randombox = GradCAMPlusPlus(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_gradcamplusplus",
    "title": "[CAM]Other Methods",
    "section": "Dog_GradCAMPlusPlus",
    "text": "Dog_GradCAMPlusPlus\n\nDog_GradCAMPlusPlus_Original\n\ncam_dog_gradcamplusplus_original = gradcamplusplus_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_GradCAMPlusPlus_Randombox\n\ncam_dog_gradcamplusplus_randombox = gradcamplusplus_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_AblationCAM",
    "text": "Cat_AblationCAM\n\nCat_AblationCAM_Original\n\nablationcam_original = AblationCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_ablationcam_original = ablationcam_original(input_tensor=x_cat,targets=None)\n\n100%|██████████| 16/16 [00:28&lt;00:00,  1.75s/it]\n100%|██████████| 16/16 [00:28&lt;00:00,  1.78s/it]\n100%|██████████| 16/16 [00:27&lt;00:00,  1.72s/it]\n\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_AblationCAM_Randombox\n\nablationcam_randombox = AblationCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_ablationcam_randombox = ablationcam_randombox(input_tensor=x_cat_r,targets=None)\n\n100%|██████████| 16/16 [00:26&lt;00:00,  1.63s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.60s/it]\n\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_ablationcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_AblationCAM",
    "text": "Dog_AblationCAM\n\nDog_AblationCAM_Original\n\ncam_dog_ablationcam_original = ablationcam_original(input_tensor=x_dog,targets=None)\n\n100%|██████████| 16/16 [00:25&lt;00:00,  1.61s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.58s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.58s/it]\n\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_AblationCAM_Randombox\n\ncam_dog_ablationcam_randombox = ablationcam_randombox(input_tensor=x_dog_r,targets=None)\n\n100%|██████████| 16/16 [00:25&lt;00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.60s/it]\n100%|██████████| 16/16 [00:25&lt;00:00,  1.59s/it]\n\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_XGradCAM",
    "text": "Cat_XGradCAM\n\nCat_XGradCAM_Original\n\nxgradcam_original = XGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_xgradcam_original = xgradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_XGradCAM_Randombox\n\nxgradcam_randombox = XGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_xgradcam_randombox = xgradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_xgradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_XGradCAM",
    "text": "Dog_XGradCAM\n\nDog_XGradCAM_Original\n\ncam_dog_xgradcam_original = xgradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_XGradCAM_Randombox\n\ncam_dog_xgradcam_randombox = xgradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenCAM",
    "text": "Cat_EigenCAM\n\nCat_EigenCAM_Original\n\neigencam_original = EigenCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigencam_original = eigencam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_EigenCAM_Randombox\n\neigencam_randombox = EigenCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigencam_randombox = eigencam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_eigencam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenCAM",
    "text": "Dog_EigenCAM\n\nDog_EigenCAM_Original\n\ncam_dog_eigencam_original = eigencam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_EigenCAM_Randombox\n\ncam_dog_eigencam_randombox = eigencam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Cat_FullGrad",
    "text": "Cat_FullGrad\n\nCat_FullGrad_Original\n\nfullgrad_original = FullGrad(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_original = fullgrad_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_FullGrad_Randombox\n\nfullgrad_randombox = FullGrad(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\nWarning: target_layers is ignored in FullGrad. All bias layers will be used instead\n\n\n\ncam_cat_fullgrad_randombox = fullgrad_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_fullgrad",
    "title": "[CAM]Other Methods",
    "section": "Dog_FullGrad",
    "text": "Dog_FullGrad\n\nDog_FullGrad_Original\n\ncam_dog_fullgrad_original = fullgrad_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_FullGrad_Randombox\n\ncam_dog_fullgrad_randombox = fullgrad_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Cat_EigenGradCAM",
    "text": "Cat_EigenGradCAM\n\nCat_EigenGradCAM_Original\n\neigengradcam_original = EigenGradCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_eigengradcam_original = eigengradcam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_EigenGradCAM_Randombox\n\neigengradcam_randombox = EigenGradCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_eigengradcam",
    "title": "[CAM]Other Methods",
    "section": "Dog_EigenGradCAM",
    "text": "Dog_EigenGradCAM\n\nDog_EigenGradCAM_Original\n\ncam_dog_eigengradcam_original = eigengradcam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nDog_EigenGradCAM_Randombox\n\ncam_dog_eigengradcam_randombox = eigengradcam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#cat_layercam",
    "title": "[CAM]Other Methods",
    "section": "Cat_LayerCAM",
    "text": "Cat_LayerCAM\n\nCat_LayerCAM_Original\n\nlayercam_original = LayerCAM(model=lrnr2.model.to('cpu'), target_layers=lrnr2.model[0][-1])\n\n\ncam_cat_layercam_original = layercam_original(input_tensor=x_cat,targets=None)\n\n\ndls.train.decode((x_cat,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\n\n\n\n\n\n\n\n\n\n\nCat_LayerCAM_Randombox\n\nlayercam_randombox = LayerCAM(model=lrnr2_r.model.to('cpu'), target_layers=lrnr2_r.model[0][-1])\n\n\ncam_cat_layercam_randombox = layercam_randombox(input_tensor=x_cat_r,targets=None)\n\n\ndls.train.decode((x_cat_r,))[0].squeeze().show()\nplt.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM",
    "text": "Dog_LayerCAM"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam_original",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Original",
    "text": "Dog_LayerCAM_Original\n\ncam_dog_layercam_original = layercam_original(input_tensor=x_dog,targets=None)\n\n\ndls.train.decode((x_dog,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#dog_layercam_randombox",
    "title": "[CAM]Other Methods",
    "section": "Dog_LayerCAM_Randombox",
    "text": "Dog_LayerCAM_Randombox\n\ncam_dog_layercam_randombox = layercam_randombox(input_tensor=x_dog_r,targets=None)\n\n\ndls.train.decode((x_dog_r,))[0].squeeze().show()\nplt.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#figure_original",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#figure_original",
    "title": "[CAM]Other Methods",
    "section": "Figure_Original",
    "text": "Figure_Original\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Original')\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_original.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_original.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_original.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_original.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_original.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_original.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_original.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_original.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_original.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_original.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_original.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_original.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_original.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_original.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_original.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_original.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_original.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_original.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_original.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_original.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "href": "posts/3_Researches/HCAM/2023-10-18-CAM_Other_Methods.html#figure_randombox",
    "title": "[CAM]Other Methods",
    "section": "Figure_Randombox",
    "text": "Figure_Randombox\n\nfig, ((ax1,ax2,ax3,ax4),\n      (ax5,ax6,ax7,ax8),\n      (ax9,ax10,ax11,ax12),\n      (ax13,ax14,ax15,ax16),\n     (ax17,ax18,ax19,ax20)) = plt.subplots(5,4) \nplt.title('Randombox')\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax1)\nax1.imshow(cam_cat_gradcam_randombox.squeeze(), alpha=0.7)\nax1.set_title(\"GradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax2)\nax2.imshow(cam_dog_gradcam_randombox.squeeze(), alpha=0.7)\nax2.set_title(\"GradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax3)\nax3.imshow(cam_cat_hirescam_randombox.squeeze(), alpha=0.7)\nax3.set_title(\"HiResCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax4)\nax4.imshow(cam_dog_hirescam_randombox.squeeze(), alpha=0.7)\nax4.set_title(\"HiResCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax5)\nax5.imshow(cam_cat_scorecam_randombox.squeeze(), alpha=0.7)\nax5.set_title(\"ScoreCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax6)\nax6.imshow(cam_dog_scorecam_randombox.squeeze(), alpha=0.7)\nax6.set_title(\"ScoreCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax7)\nax7.imshow(cam_cat_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax7.set_title(\"GradCAMPlusPlus CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax8)\nax8.imshow(cam_dog_gradcamplusplus_randombox.squeeze(), alpha=0.7)\nax8.set_title(\"GradCAMPlusPlus DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax9)\nax9.imshow(cam_cat_ablationcam_randombox.squeeze(), alpha=0.7)\nax9.set_title(\"AblationCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax10)\nax10.imshow(cam_dog_ablationcam_randombox.squeeze(), alpha=0.7)\nax10.set_title(\"AblationCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax11)\nax11.imshow(cam_cat_xgradcam_randombox.squeeze(), alpha=0.7)\nax11.set_title(\"XGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax12)\nax12.imshow(cam_dog_xgradcam_randombox.squeeze(), alpha=0.7)\nax12.set_title(\"XGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax13)\nax13.imshow(cam_cat_eigencam_randombox.squeeze(), alpha=0.7)\nax13.set_title(\"EigenCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax14)\nax14.imshow(cam_dog_eigencam_randombox.squeeze(), alpha=0.7)\nax14.set_title(\"EigenCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax15)\nax15.imshow(cam_cat_fullgrad_randombox.squeeze(), alpha=0.7)\nax15.set_title(\"FullGrad CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax16)\nax16.imshow(cam_dog_fullgrad_randombox.squeeze(), alpha=0.7)\nax16.set_title(\"FullGrad DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax17)\nax17.imshow(cam_cat_eigengradcam_randombox.squeeze(), alpha=0.7)\nax17.set_title(\"EigenGradCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax18)\nax18.imshow(cam_dog_eigengradcam_randombox.squeeze(), alpha=0.7)\nax18.set_title(\"EigenGradCAM DOG PART\")\n#\ndls.train.decode((x_cat_r,))[0].squeeze().show(ax=ax19)\nax19.imshow(cam_cat_layercam_randombox.squeeze(), alpha=0.7)\nax19.set_title(\"LayerCAM CAT PART\")\n#\ndls.train.decode((x_dog_r,))[0].squeeze().show(ax=ax20)\nax20.imshow(cam_dog_layercam_randombox.squeeze(), alpha=0.7)\nax20.set_title(\"LayerCAM DOG PART\")\n#\nfig.set_figwidth(20)            \nfig.set_figheight(20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/3_Researches/GODE/2023-07-01-NonEuclidean_data_of_GODE.html",
    "href": "posts/3_Researches/GODE/2023-07-01-NonEuclidean_data_of_GODE.html",
    "title": "Non-Euclidean data of GODE",
    "section": "",
    "text": "GODE에서 사용된 Graph signal 예제들에 대한 설명\n\n\nImport\n\nimport pickle\n\n\n\nEsmaple 1. Simple Linear\nData Information\n\n\\(V=\\{{\\boldsymbol v}_1,\\dots,{\\boldsymbol v}_n\\}:=\\{(x_1,y_2,z_3),\\dots,(x_n,y_n,z_n)\\}\\)\n\n\\(r_i= 5 + \\cos(\\frac{12\\pi (i - 1)}{n - 1})\\), \\(\\theta_i= -\\pi + \\frac{{\\pi(n-2)(i - 1)}}{n(n - 1)}\\)\n\\(x_i = r_i \\cos(\\theta_i)\\), \\(y_i = r_i \\sin(\\theta_i)\\), \\(z_i = 10 \\cdot \\sin(\\frac{{6\\pi \\cdot (i - 1)}}{{n - 1}})\\).\n\n\\(W_{i,j} = \\begin{cases} \\exp\\left(-\\frac{\\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2}{2\\theta^2}\\right) & \\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2 \\le \\kappa \\\\ 0 & o.w\\end{cases}\\)\n\n\nNote that \\({\\bf L}\\) is GSO, and in this case, GFT is just Discrete Fourier Transform also note that \\({\\cal G}_W\\) is a regular graph since \\({\\bf D}={\\bf I}\\). Thus this data is Euclidean data.\n\ngraph signal\n\\(y:V \\to \\mathbb{R}\\)\n\n\\(y_i=\\frac{10}{n}v_i+\\eta_i+\\epsilon_i\\)\n\\(\\epsilon_i \\sim N(\\mu,\\sigma^2)\\)\n\\(\\eta_i \\sim U^\\star\\) with sparsity \\(0.05\\) where \\(U^\\star\\) is mixture of \\(U(1.5,2)\\) and \\(U(-2,-1.5)\\).\n\n\nNote that \\({\\bf y}\\) is weakly stationary w.r.t. \\({\\bf L}\\).\n\nEuclidean Data\n\ndomain 이 \\(x\\)축(실수 \\(\\mathbb{R}\\)로 정의되는)인 유클리디안 데이터\nunderline이 선, 아래에서는 \\(y=5x\\)가 되겠다.\n\n1d-grid로 볼 수 있음.(non-euclidean vs euclidean 참고)\n\nunderliying function이 regular graph로 정의(regular graph 참고)\n\n\n\n\nFigure: First example of GODE\n\n\n\n\nEsmaple 2. Orbit\nData Information\n\\({\\cal G}_W=(V,E,{\\bf W})\\)\n\n\\(V=\\{{\\boldsymbol v}_1,\\dots,{\\boldsymbol v}_n\\}:=\\{(x_1,y_2,z_3),\\dots,(x_n,y_n,z_n)\\}\\)\n\n\\(r_i= 5 + \\cos(\\frac{12\\pi (i - 1)}{n - 1})\\), \\(\\theta_i= -\\pi + \\frac{{\\pi(n-2)(i - 1)}}{n(n - 1)}\\)\n\\(x_i = r_i \\cos(\\theta_i)\\), \\(y_i = r_i \\sin(\\theta_i)\\), \\(z_i = 10 \\cdot \\sin(\\frac{{6\\pi \\cdot (i - 1)}}{{n - 1}})\\).\n\n\\(W_{i,j} = \\begin{cases} \\exp\\left(-\\frac{\\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2}{2\\theta^2}\\right) & \\|{\\boldsymbol v}_i -{\\boldsymbol v}_j\\|^2 \\le \\kappa \\\\ 0 & o.w\\end{cases}\\)\n\nNon-Euclidean Data\n\n2D shape이다.\ndomain이 곡선인 논유클리디안 데이터\nunderlying function이 regular graph로 정의되지 않는다.(regular graph 참고)\n거리 계산을 유클리드 거리로 할 때, underline이 곡선이라 합리적이지 않다.\nweight은 유클리디안 거리로 정의되어 있지만, \\(\\kappa\\)로 hyperparameter 지정해주어 거리가 짧으면 유클리디안 거리로 정의하고, 멀면 0으로 연결을 끊는 행렬으로 정의.\n\n\n\n\n\n\n\nNote\n\n\n\n유클리디안으로 보고 싶다면??\n\n모든 연결 weight를 끊어버리면 된다.\n그러면 regular graph 로 정의 가능.\n하지만, d연구의 목적에 어긋남.\n\n\n\n\nNote that \\({\\bf W}\\) is GSO, since \\({\\bf W}^\\top = {\\bf W}\\). In this cases, \\({\\cal G}_W\\) is not regular since there does not exist \\(k\\) such that \\({\\bf D}=k{\\bf I}\\).\n\ngraph signal \\({\\bf y}:V \\to \\mathbb{R}^3\\)\n\n\\({\\bf y}_i={\\boldsymbol v}_i+{\\boldsymbol \\eta}_i+{\\boldsymbol \\epsilon}_i\\)\n\\({\\boldsymbol \\epsilon}_i \\sim N({\\boldsymbol \\mu},\\sigma^2{\\bf I})\\)\n\\({\\boldsymbol \\eta}_i \\sim U^\\star\\) with sparsity \\(0.05\\) where \\(U^\\star\\) is mixture of \\(U(5,7)\\) and \\(U(-7,-5)\\).\n\n\nClearly \\({\\bf y}\\) is stationary w.r.t. \\({\\bf W}\\) or \\({\\bf L}\\).\n\n\n\n\nFigure: Second example of GODE\n\n\n\n\nEsmaple 3. Stanford Bunny\nData Information\npygsp 라이브러리를 사용하여 데이터 가져옴, weight도!(mesh 로 색의 퍼짐 정도로 나타낸 것으로 간단 이해)\nNon-Euclidean Data\n\n3D shape\ndomain이 곡면이고, underline이 곡면인 넌유클리디안 데이터\nunderlying function 이 색\n\n아래를 설명해보자면, 연한 파란-연한 초록 점이 언더라인 펑션으로 형성되어 있을때, 진한 색의 점들이 noise로 형성되어 있음.\n\nunderline이 곡면이라 유클리디안 거리를 사용하는 것이 합리적이지 않다.\n\n\n\n\nFigure: Third example of GODE\n\n\n\n\nReal data. Earthquake\nData Information\nThis data is actual data collected from USGS1 during the period from 2010 to 2014.\n1 https://www.usgs.gov/programs/earthquake-hazards/lists-maps-and-statistics\\({\\cal G}=(V,E)\\)\n\n\\(V=\\{{\\boldsymbol v}_1,\\dots,{\\boldsymbol v}_n\\}\\) where \\({\\boldsymbol v}:=({\\tt Latitude},{\\tt Longitude})\\)\n\\(W_{i,j} = \\begin{cases} \\exp(-\\frac{\\rho(i,j)}{2\\theta^2}) & if \\rho(i,j) \\le \\kappa \\\\ 0 & o.w. \\end{cases}\\)\n\nHere, \\(\\rho(i,j)=hs({\\boldsymbol v}_i, {\\boldsymbol v}_j)\\) is Haversine distance between \\({\\boldsymbol v}_i, {\\boldsymbol v}_j\\).\n\n\\(y_i\\) = magnitude\n\nNon-Euclidean Data\n\ndomain이 곡면이고, underline이 곡면인 넌유클리디안 데이터\nunderlying function 이 magnitude(지진 강도)\nhaversine 이용하면 곡면 거리가 이미 포함되어 있지만, 자료가 너무 많아 거리가 먼 연결을 끊어주는 역할로 hyperparameter인 \\(\\kappa\\)사용하였다.\n\n\nwith open(\"Figs/GODE_earthquake.pkl\", \"rb\") as file:\n    loaded_object = pickle.load(file)\n\nloaded_object"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html",
    "title": "[ggplot3]With Non tidy Data",
    "section": "",
    "text": "데이터 출처 : https://github.com/nickhould/tidy-data-python\nhttps://partrita.github.io/posts/tidy-data/"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try1",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try1",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try1",
    "text": "try1\ncondition 부여 후 색 구분\n\nggplot() + point(mpg$displ,col='black') + point(mpg[(mpg$displ&lt;5&mpg$displ&gt;1),]$displ,col='red')"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try2",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try2",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try2",
    "text": "try2\ncondition 부여 후 절단\n\nggplot() + line(mpg$displ,col=2,label='a') + line(mpg[mpg$hwy&gt;20,]$hwy,col=3,label='b')"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try3",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try3",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try3",
    "text": "try3\n색 자동 지정은 label의 알파벳 순 혹은 그려진 순\n\nggplot() + point(label='blue',mpg$displ, mpg$hwy)|ggplot() + point(mpg$displ, mpg$hwy,label='clue')"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try4-열-이름이-값인-데이터",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try4-열-이름이-값인-데이터",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try4 열 이름이 값인 데이터",
    "text": "try4 열 이름이 값인 데이터\n\nhead(pew)\n\n\n\n\n\n\nreligion\nX..10k\nX.10.20k\nX.20.30k\nX.30.40k\nX.40.50k\nX.50.75k\n\n\n\n&lt;chr&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n\n\n\n\n1\nAgnostic\n27\n34\n60\n81\n76\n137\n\n\n2\nAtheist\n12\n27\n37\n52\n35\n70\n\n\n3\nBuddhist\n27\n21\n30\n34\n33\n58\n\n\n4\nCatholic\n418\n617\n732\n670\n638\n1116\n\n\n5\nDont know/refused\n15\n14\n15\n11\n10\n35\n\n\n6\nEvangelical Prot\n575\n869\n1064\n982\n881\n1486\n\n\n\nA data.frame: 6 × 7\n\n\nggplot() + point(colnames(pew)[2:7],t(pew[pew$religion=='Agnostic',])[2:7],label = 'Agnostic') +\n           point(colnames(pew)[2:7],t(pew[pew$religion=='Atheist',])[2:7],label = 'Atheist') +\n           point(colnames(pew)[2:7],t(pew[pew$religion=='Buddhist',])[2:7],label = 'Buddhist') +\n           point(colnames(pew)[2:7],t(pew[pew$religion=='Catholic',])[2:7],label = 'Catholic')\n\n\n\n\n\n\n\n\n\nggplot() + point(colnames(pew)[2:7],t(pew[pew$religion=='Agnostic',])[2:7],label = 'Agnostic')|ggplot() + point(colnames(pew)[2:7],t(pew[pew$religion=='Atheist',])[2:7],label = 'Atheist')"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try5-하나의-표에-여러가지-타입-존재하는-데이터",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try5-하나의-표에-여러가지-타입-존재하는-데이터",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try5 하나의 표에 여러가지 타입 존재하는 데이터",
    "text": "try5 하나의 표에 여러가지 타입 존재하는 데이터\n\nunique(billboard$genre)\n\n\n'Rock''Latin''Country''Rap''Pop''Electronica''Jazz''R&B''Reggae''Gospel'\n\n\n장르 별 1주차 빌보드 순위\n\nggplot() + point(billboard$x1st.week,label='all') + point(billboard[billboard$genre=='Rock',]$x1st.week,label='Rock') + point(billboard[billboard$genre=='Country',]$x1st.week,label='Country')\n\n\n\n\n\n\n\n\n\nhead(billboard)\n\n\n\n\n\n\nyear\nartist.inverted\ntrack\ntime\ngenre\ndate.entered\ndate.peaked\nx1st.week\nx2nd.week\nx3rd.week\n⋯\nx67th.week\nx68th.week\nx69th.week\nx70th.week\nx71st.week\nx72nd.week\nx73rd.week\nx74th.week\nx75th.week\nx76th.week\n\n\n\n&lt;int&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;chr&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n⋯\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n&lt;lgl&gt;\n\n\n\n\n1\n2000\nDestiny's Child\nIndependent Women Part I\n3:38\nRock\n2000-09-23\n2000-11-18\n78\n63\n49\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n2\n2000\nSantana\nMaria, Maria\n4:18\nRock\n2000-02-12\n2000-04-08\n15\n8\n6\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n3\n2000\nSavage Garden\nI Knew I Loved You\n4:07\nRock\n1999-10-23\n2000-01-29\n71\n48\n43\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n4\n2000\nMadonna\nMusic\n3:45\nRock\n2000-08-12\n2000-09-16\n41\n23\n18\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n5\n2000\nAguilera, Christina\nCome On Over Baby (All I Want Is You)\n3:38\nRock\n2000-08-05\n2000-10-14\n57\n47\n45\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n6\n2000\nJanet\nDoesn't Really Matter\n4:17\nRock\n2000-06-17\n2000-08-26\n59\n52\n43\n⋯\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\nNA\n\n\n\nA data.frame: 6 × 83\n\n곡 별로 빌보드 차트에 얼마나 있었나 line\n\nggplot() + line(t(billboard[1,c(8:length(billboard))])[,1], label=billboard$track[1]) +\nline(t(billboard[2,c(8:length(billboard))])[,1], label=billboard$track[2]) + \nline(t(billboard[3,c(8:length(billboard))])[,1], label=billboard$track[3]) + \nline(t(billboard[4,c(8:length(billboard))])[,1], label=billboard$track[4]) + \nline(t(billboard[5,c(8:length(billboard))])[,1], label=billboard$track[5])\n\nWarning message:\n“Removed 48 rows containing missing values (`geom_line()`).”\nWarning message:\n“Removed 50 rows containing missing values (`geom_line()`).”\nWarning message:\n“Removed 43 rows containing missing values (`geom_line()`).”\nWarning message:\n“Removed 52 rows containing missing values (`geom_line()`).”\nWarning message:\n“Removed 55 rows containing missing values (`geom_line()`).”\n\n\n\n\n\n\n\n\n\n\nggplot() + point(t(billboard[1,c(8:length(billboard))])[,1], label=billboard$track[1])\n\nWarning message:\n“Removed 48 rows containing missing values (`geom_point()`).”\n\n\n\n\n\n\n\n\n\n\nggplot() + geom_point(t(billboard[1,c(8:length(billboard))])[,1], label=billboard$track[1])\n\nERROR: Error in ggplot(): could not find function \"ggplot\""
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try6-다양한-변수가-하나의-열에-있는-데이터",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#try6-다양한-변수가-하나의-열에-있는-데이터",
    "title": "[ggplot3]With Non tidy Data",
    "section": "try6 다양한 변수가 하나의 열에 있는 데이터",
    "text": "try6 다양한 변수가 하나의 열에 있는 데이터\nWHO의 결핵환자 기록, m/f는 성별 슛저눈 나이대를 의미\n\nhead(tb)\n\n\n\n\n\n\ncountry\nyear\nm014\nm1524\nm2534\nm3544\nm4554\nm5564\nm65\nmu\nf014\n\n\n\n&lt;chr&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;int&gt;\n&lt;lgl&gt;\n&lt;int&gt;\n\n\n\n\n1\nAD\n2000\n0\n0\n1\n0\n0\n0\n0\nNA\nNA\n\n\n2\nAE\n2000\n2\n4\n4\n6\n5\n12\n10\nNA\n3\n\n\n3\nAF\n2000\n52\n228\n183\n149\n129\n94\n80\nNA\n93\n\n\n4\nAG\n2000\n0\n0\n0\n0\n0\n0\n1\nNA\n1\n\n\n5\nAL\n2000\n2\n19\n21\n14\n24\n19\n16\nNA\n3\n\n\n6\nAM\n2000\n2\n152\n130\n131\n63\n26\n21\nNA\n1\n\n\n\nA data.frame: 6 × 11\n\n\nggplot() + point(tb$country,subset(tb, select = grep(\"m\", names(tb))))\n\nWarning message:\n“Removed 15 rows containing missing values (`geom_point()`).”"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#section",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#section",
    "title": "[ggplot3]With Non tidy Data",
    "section": "1.",
    "text": "1.\n\nggplot() + point(mpg$displ,label='a')\n\n\n\n\n\n\n\n\n\nggplot() + point(mpg$displ,label='a',col=2)"
  },
  {
    "objectID": "posts/1_Note/2023-08-25-ggplot3_comparison.html#section-1",
    "href": "posts/1_Note/2023-08-25-ggplot3_comparison.html#section-1",
    "title": "[ggplot3]With Non tidy Data",
    "section": "2.",
    "text": "2.\n\nggplot() + point(label='blue',mpg$displ, mpg$hwy)|ggplot() + point(mpg$displ, mpg$hwy, col='blue')"
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "",
    "text": "- ls vs mc\n“ls”는 현재 디렉터리의 파일 및 폴더 목록을 표시하는 명령어이고, “mc”는 Midnight Commander라는 파일 관리자 프로그램\nmacOS (Homebrew를 통한 설치):\nbrew install mc\n- 파일 출력\ncat 파일이름\ncat example.txt"
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#large-file-관리",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#large-file-관리",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "large file 관리",
    "text": "large file 관리\n- Large file git push 가능하도록 하는 방법(100mb인가 넘으면 git push 오류남)\ngit lfs install\n\nGit Large File Storage (LFS)를 사용하도록 Git을 구성하는 명령어입니다.\nGit LFS는 대용량 파일을 효과적으로 관리할 수 있도록 도와주는 확장 기능\n\n- 사용법\ngit lfs track “*.npy\" \n\nnpy로 끝나는 파일 찾아서 large file 업로드 가능하도록 만들어서 push\n즉, 원하는 파일 확장자 다 large file git push 가능하도록 설정할 수 있다.\n원하는 파일만 큰 따옴표 안에 지정해서 large file git push 가능하도록 성정할 수 있다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#git-switch-maingh-pagesbranch-name",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#git-switch-maingh-pagesbranch-name",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "git switch main/gh-pages(branch name)",
    "text": "git switch main/gh-pages(branch name)\nquarto page 오류뜰때 사용할 수 있는 방법, 파일 지우는 과정 있어서 조심해서 코드 작성해야 함\n- main 브랜치\ngit switch main\n- gh-pages 브랜치\ngit switch gh-pages \n- step\n\ngit switch main으로 main으로 가서\n\ngit add .\ngit commit -m .\ngit push\n\ngit switch gh-pages 으로 gh-pages로 가서\n\n모든 파일 삭제.\n여기는 페이지의 파일이라 삭제해도 무방\nmain이 기본, gh-pages는 페이지를 만들기 위한 임시 공간으로서 여기 있는 파일 다 지워도 main에는 남아 있음\ngit add .\ngit commit -m .\ngit push 하고\n\ngit switch mainmain 다시 가서\n\ngit add .\ngit commit -m .\ngit push"
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#파일-삭제할때-사용",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#파일-삭제할때-사용",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "파일 삭제할때 사용!",
    "text": "파일 삭제할때 사용!\nrm -rf * \nrm -rf 파일명"
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#update",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#update",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "Update",
    "text": "Update\n1 다운로드 주소를 복사한다.\n2 코드를 입력한다.(wget 주소를 직접 얻어서 sudo 관리자권한으로 실행 순서), 아래는 예시임!\nwget https://github.com/quarto-dev/quarto-cli/releases/download/v1.4.315/quarto-1.4.315-linux-amd64.deb\nsudo dpkg -i quarto-1.4.315-linux-amd64.deb \n\nsudo: 명령어를 관리자 권한으로 실행하기 위한 명령어입니다.\ndpkg: Debian 패키지 관리자입니다.\n-i: 패키지를 설치하기 위한 옵션입니다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#presentation",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#presentation",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "Presentation",
    "text": "Presentation\n- 렌더링, latex의 build랑 같은 개념(문서화한다는 뜻으로 보면 될 듯)\nquarto render 파일이름.파일형식\n\nqmd, ipynb,…\n\n- 미리보기\nquarto preview 파일이름.파일형식 --no-browser --host 0.0.0.0\n\n--no-browser 안 쓰면 자동으로 브라우저 오픈된다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#nano",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#nano",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "nano",
    "text": "nano\n- 설치\nsudo apt-get install nano   # Debian/Ubuntu\nsudo yum install nano       # Red Hat/Fedora\n- 여는 법\nnano 파일이름.파일형식(nano ref.bib)\n- 사용법\n\n저장: Ctrl + O\n종료: Ctrl + X\n특수 문자: ^는 Ctrl을 나타냅니다. 예를 들어, ^G는 Ctrl + G를 의미합니다\n\n\nnano로 매크로같은 명령어 파일 만들기\n1 sh확장자 가진 push 파일을 만들기\nnano push.sh\n터미널에서 보면 파일명이 흰색임\n2 실행하고 싶은 명령어 입력\n\ngit add . / git commit -m . / git push 등 하고 싶은 명령어 넣고\n\n3 실행 권한 추가하기\nchmod +x push.sh\n터미널에서 보면 파일명이 녹색으로 바뀜\n\nchange mode, 실행권한을 추가하라(+x) push라는 sh 확장자를 가진 파일에\n\n4 시행\n\n이제 ~/push.sh 를 해당 quarto 블로그 들어가서 입력하여 시행만 하면 된다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#vim",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#vim",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "Vim",
    "text": "Vim\n- 설치\nsudo apt-get install vim   # Debian/Ubuntu\nsudo yum install vim       # Red Hat/Fedora\n- 여는 법\nvim 파일이름.파일형식\n- 사용법\n\n편집 모드로 전환: i 키를 누르기\n편집 완료 후 저장 및 종료: Esc 키를 누르고 :wq 입력 후 엔터\n\n수정하고 q만 누르면 에러 뜬다. 저장 할 게 있기 때문이다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#가상환경-관련",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#가상환경-관련",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "가상환경 관련",
    "text": "가상환경 관련\n- 가상환경 생성\nconda create -n my_python_env python==3.8\n\nconda create: Conda를 사용하여 가상 환경을 생성하는 명령어입니다.\n-n my_python_env: 가상 환경의 이름을 설정하는 옵션으로, 여기서는 “my_python_env”로 지정되었습니다.\npython==3.8: 생성할 가상 환경에 설치할 Python 버전을 지정하는 옵션으로, 여기서는 Python 3.8로 지정되었습니다.\n\n버전 지정 안 하면 최신 버전으로 지정된다.\n\n\n- 버전 확인\nconda –version\n\nconda --version: 현재 설치된 Conda의 버전을 확인하는 명령어입니다.\n\n- 가상환경 업데이트\nconda update\n\nConda 자체를 업데이트하는 명령어입니다. Conda를 최신 버전으로 업데이트합니다.\n\n- 가상환경 활성화\nconda activate YOUR_ENV_NAME\n\n생성한 가상 환경을 활성화하는 명령어입니다. YOUR_ENV_NAME 부분에는 실제 가상 환경의 이름이 들어갑니다.\n\n- 가상환경 비활성화\nconda deactivate\n\n현재 활성화된 가상 환경을 비활성화하는 명령어입니다.\n\n- 가상환경 목록 확인\nconda env list\nconda info --envs\n\n현재 시스템에 설치된 가상 환경 목록을 확인하는 명령어입니다.\n\n- 가상환경 삭제\nconda env remove --name YOUR_ENV_NAME --all\n\n지정된 가상 환경을 삭제하는 명령어입니다.\n--name YOUR_ENV_NAME: 삭제할 가상 환경의 이름을 지정하는 옵션입니다.\n--all: 가상 환경에 포함된 모든 패키지를 함께 제거하는 옵션입니다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#r-관련",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#r-관련",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "R 관련",
    "text": "R 관련\n- r 실행\nconda install -c conda-forge r-essentials \n\nconda install: Conda를 사용하여 패키지를 설치하는 명령어입니다.\n-c conda-forge: 패키지를 검색하고 가져올 채널을 지정하는 옵션입니다. 여기서는 conda-forge 채널에서 패키지를 찾아 가져오라는 의미입니다. conda-forge는 커뮤니티가 관리하는 Conda 패키지 저장소입니다.\nr-essentials: R 언어와 관련된 필수 패키지들을 묶어놓은 메타 패키지입니다. R 언어의 중요한 패키지들을 포함하고 있어, R을 사용하는데 필수적인 패키지들을 편리하게 설치할 수 있게 도와줍니다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#바로-설치되도록-환경-저장하는법",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#바로-설치되도록-환경-저장하는법",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "바로 설치되도록 환경 저장하는법",
    "text": "바로 설치되도록 환경 저장하는법\n1\npip freeze &gt; requirements.txt\n2\nconda list -e &gt; requirements_conda.txt\n\n이 명령어는 현재 Conda 환경에 설치된 패키지들과 그 버전을 나열하여 “requirements_conda.txt” 파일에 저장합니다.\n-e 옵션은 Conda 환경의 정확한 사양(specification)을 나열하도록 합니다. 이 또한 프로젝트의 의존성을 추적하고, 다른 환경에서 동일한 패키지를 설치하는 데 사용됩니다.\n결과 파일은 일반적으로 Conda 환경을 재현하는 데 사용됩니다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#파일-복사해서-이동하기",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#파일-복사해서-이동하기",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "파일 복사해서 이동하기",
    "text": "파일 복사해서 이동하기\nsummary.txt파일을 copy(cp)해서 ~/Dropbox 폴더로 옮기기\ncp summery.txt ~/Dropbox\n\ncp: “copy”의 약자로, 파일을 복사하는 명령어입니다.\nsummery.txt: 복사할 대상 파일의 이름입니다. 여기서는 “summery.txt” 파일을 대상으로 선택했습니다.\n~/Dropbox: ~는 홈 디렉토리를 나타내며, ~/Dropbox는 현재 사용자의 홈 디렉토리 내에 있는 “Dropbox” 디렉토리를 가리킵니다. 따라서 복사된 파일은 사용자의 Dropbox 디렉토리로 이동됩니다."
  },
  {
    "objectID": "posts/1_Note/2023-12-31-note_git_blog.html#nvidia-smi",
    "href": "posts/1_Note/2023-12-31-note_git_blog.html#nvidia-smi",
    "title": "[Note] Tips of Linux, Git and Blog",
    "section": "nvidia-smi",
    "text": "nvidia-smi\n일반적인 출력 결과 아래\n\n\n\n\n\n\n\n\nNVIDIA-SMI 460.39 Driver Version: 460.39 CUDA Version: 11.2 ——————————-+———————-+———————- GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | MIG M. ===============================+======================+====================== 0 Tesla K80 Off | 00000000:00:1E.0 Off | 0 N/A 52C P0 58W / 149W | 299MiB / 11441MiB | 0% Default | | N/A\n\n\n\n\n\n\nDriver Version: 현재 설치된 NVIDIA GPU 드라이버의 버전입니다.\nCUDA Version: 현재 설치된 CUDA (Compute Unified Device Architecture) 버전입니다.\nGPU Name: GPU의 모델명입니다.\nFan, Temp, Perf, Pwr: GPU의 팬 상태, 온도, 성능, 전력 사용량 등을 보여줍니다.\nMemory Usage: GPU 메모리 사용량 및 총 메모리 크기를 보여줍니다.\nGPU-Util: GPU의 사용률을 나타냅니다.\nCompute M.: 현재 GPU에서 사용 중인 컴퓨트 모드를 나타냅니다."
  },
  {
    "objectID": "posts/1_Note/2022-12-31-Space-study.html",
    "href": "posts/1_Note/2022-12-31-Space-study.html",
    "title": "Study for Spaces",
    "section": "",
    "text": "Spaces"
  },
  {
    "objectID": "posts/1_Note/2022-12-31-Space-study.html#내적공간",
    "href": "posts/1_Note/2022-12-31-Space-study.html#내적공간",
    "title": "Study for Spaces",
    "section": "내적공간",
    "text": "내적공간\n\\[|a||b| \\cos \\theta\\]\n\n길이 + 각의 개념\n\nProjection"
  },
  {
    "objectID": "posts/1_Note/2022-12-31-Space-study.html#바나흐공간",
    "href": "posts/1_Note/2022-12-31-Space-study.html#바나흐공간",
    "title": "Study for Spaces",
    "section": "바나흐공간",
    "text": "바나흐공간\n\\[|---|\\]\n\n길이 + 극한의 개념"
  },
  {
    "objectID": "posts/1_Note/2022-12-31-Space-study.html#노름공간",
    "href": "posts/1_Note/2022-12-31-Space-study.html#노름공간",
    "title": "Study for Spaces",
    "section": "노름공간",
    "text": "노름공간\n\\[|   |\\]\n\n길이의 개념"
  },
  {
    "objectID": "posts/1_Note/2022-12-31-Space-study.html#힐베르트공간유클리드-비유클리드-모두-존재",
    "href": "posts/1_Note/2022-12-31-Space-study.html#힐베르트공간유클리드-비유클리드-모두-존재",
    "title": "Study for Spaces",
    "section": "힐베르트공간(유클리드 + 비유클리드 모두 존재)",
    "text": "힐베르트공간(유클리드 + 비유클리드 모두 존재)\n퓨리에 해석 - 길이 + 각 + 극한의 개념"
  },
  {
    "objectID": "posts/1_Note/2022-03-28-(4주차) 3월28일.html",
    "href": "posts/1_Note/2022-03-28-(4주차) 3월28일.html",
    "title": "Introduction to Python 4wk",
    "section": "",
    "text": "개발환경의 변천사, 1세대 프로그래머부터 5세대 프로그래머까지\n\nhttps://guebin.github.io/IP2022/2022/03/28/(4%EC%A3%BC%EC%B0%A8)-3%EC%9B%9428%EC%9D%BC.html\n\n강의영상\n\nyoutube: https://youtube.com/playlist?list=PLQqh36zP38-zcnjAged1xIatgznRTy93c\n\n- (1/8) 파이썬이 어려웠던 이유\n- (2/8) 1세대 프로그래머\n- (3/8) 1세대 프로그래머의 삶 with python\n- (4/8) 1세대 프로그래머의 삶 with ipython\n- (5/8) 2세대 프로그래머, 3세대 프로그래머 (1)\n- (6/8) 3세대 프로그래머(2), 4세대 프로그래머\n- (7/8) 5세대 프로그래머\n- (8/8) 다양한 개발환경 구축방법 다시 리뷰, 숙제설명\n\n\n파이썬이 어려웠던 이유\n- 파이썬 배우는 초보자에게 가장 어려운것! - 선생님마다 설치하는 방법이 모두 다름\n- 왜 저렇게 설치방법이 다른가? 왜 다른 방법으로 각각 파이썬을 실행하는가? 이런것이 너무 어려움 - 방법1: 파이썬프로그램 다운로드 -&gt; 시작버튼 눌러서 설치 - 방법2: 아나콘다 설치 (그럼 자동으로 파이썬이 설치됨) - 방법3: 아나콘다 설치 + 가상환경 - …\n- 심지어 실행하는것도 다름 - 방법1: 파이썬 프롬프트 - 방법2: .py를 이용하여 실행? - 방법3: IDLE - 방법4: 파이참 - 방법5: 스파이더 - 방법6: Visual Studio Code - 방법7: 주피터노트북, 주피터랩 - 가상환경을 만들어서 해라.. - 아나콘다 네비게이터에 주피터가 있다.. - …\n- 머리아프니까 collab을 쓰라는 사람도 있음. 아니면 도커이미지를 줄테니까 그걸 쓰라는 사람도 있음. AWS를 쓰라는 사람도 있음.. \\(\\to\\) 이게 더 머리아픔\n- 핵심: 그냥 (1) 컴퓨터에 (2) 파이썬을 깔아서 (3) 실행하는 것임\n- 의문: 그런데 방법이 왜이렇게 많은가? 엑셀처럼 프로그램 설치하고 아이콘 더블클릭하면 끝나는 식으로 만들어야 하는것 아닌가?\n\n개발환경 구축방법이 많은 이유?\n- 파이썬 개발환경 구축은 수많은 방법이 있다.\n- 이는 마치 라면의 레시피를 검색하면 수많은 방법이 나오는것과 유사함. - 방법1: 스프를 먼저 넣고 끓인다음 라면을 넣어야 합니다. - 방법2: 양은냄비에 물넣고 물이 끊으면 라면과 스프를 같이 넣고 마지막에 계란을 넣는다. - 방법3: 먹다남은 삼겹살을 후라이팬에 볶은다음에 물을 붓고 라면을 넣는다. - 방법4: 용기에 라면+스프+뜨거운물 랩을 씌운뒤에 젓가락으로 구멍을 뚫고 전자렌지에 돌린다. - …\n- 우리는 모든 방법을 나열할 순 없지만 모든 방법을 이해할 수 있다. 왜냐하면 라면을 끓이는 공통적인 맥락을 우리는 알고 있으니까\n- 파이썬을 설치하는 다양한 방법 역시 공통맥락을 파악하면 이해하기 쉽다.\n- 제목적: 파이썬을 설치하고 실행하는 공통맥락을 설명하고 싶음\n- 설치하는 방법이 다양한 이유? 파이썬이 인기있음 + 다양한 방법을 설치를 하면 각자의 장점이 뚜렷해서\n\n\n\n1세대 프로그래머\n\npython\n- 윈도우에서 anaconda prompt 실행 -&gt; python\n(base) C:\\Users\\python&gt;python\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; [1,2,3]+[4]\n[1, 2, 3, 4]\n&gt;&gt;&gt; a=[1,2,3]+[4]\n&gt;&gt;&gt; a\n[1, 2, 3, 4]\n- 2개를 실행할 수도 있음. (두 환경은 각각 서로 독립적인 파이썬, 변수가 공유되지 않음) \\(\\star\\)\n- 아쉬운점: `?list’와 같이 도움말 기능이 동작하지 않음\n&gt;&gt;&gt; ?list\n  File \"&lt;stdin&gt;\", line 1\n    ?list\n    ^\nSyntaxError: invalid syntax\n&gt;&gt;&gt; \n\n\nipython\n- 윈도우에서 anaconda prompt 실행 -&gt; ipython\n(base) C:\\Users\\python&gt;ipython\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.29.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: a=[1,2,3]\n\nIn [2]: a\nOut[2]: [1, 2, 3]\n\nIn [3]: a+[4]\nOut[3]: [1, 2, 3, 4]\n- ?list가 가능\nIn [4]: ?list\nInit signature: list(iterable=(), /)\nDocstring:\nBuilt-in mutable sequence.\n\nIf no argument is given, the constructor creates a new empty list.\nThe argument must be an iterable if specified.\nType:           type\nSubclasses:     _HashedSeq, StackSummary, DeferredConfigList, SList, _ImmutableLineList, FormattedText, NodeList, _ExplodedList, Stack, _Accumulator, ...\n\n- 색깔이 알록달록해서 문법을 보기 편하다. (구문강조)\n\n\n1세대 프로그래머의 삶 with python\n- 1부터 10까지 합을 구하는 프로그램을 만들고 싶음\n- 시도1: python을 키고 아래와 같이 실행\n(base) C:\\Users\\python&gt;python\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; total = 0\n&gt;&gt;&gt; for i in range(10):\n...     total=total+i\n...\n&gt;&gt;&gt; total\n45\n&gt;&gt;&gt;\n- 반성: 정답은 55인데 45가 출력되었다! \\(\\to\\) range(10)을 range(1,11)으로 바꿔야겠다!\n- 시도2: range(1,11)을 바꿔야겠다고 생각하고 다시 입력하다가 오타가 발생\n&gt;&gt;&gt; total =0\n&gt;&gt;&gt; for i in range(1,11):\n...     total = totla +i\n...\n\n앗 totla이라고 잘못쳤다.\n\n- 반성: 다음에는 정신을 똑바로 차려야겠다.\n- 불편한점: … 다..\n\n\n1세대 프로그래머의 삶 with ipython\n- ipython을 사용한 프로그래머는 좀더 상황이 낫다\n(base) C:\\Users\\python&gt;ipython\nPython 3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\nType 'copyright', 'credits' or 'license' for more information\nIPython 7.29.0 -- An enhanced Interactive Python. Type '?' for help.\n\nIn [1]: total = 0\n\nIn [2]: for i in range(1,11):\n   ...:     total = total + i\n   ...:\n\nIn [3]: total\nOut[3]: 55\n\n편한점1: 자동으로 들여쓰기가 되어서 편함\n편한점2: 화살표를 이용해서 for문을 쓰는 도중에 위아래로 이동가능\n불편한점1: 화살표로 이동할수는 있는데 마우스로는 이동할 수 없다.\n불편한점2: 내가 작성한 코드를 관리하기 어렵다.\n\n\n\n\n2세대 프로그래머: 메모장 + anconda prompt를 이용 (.py를 이용한 python활용)\n- 메모장을 키고 아래의 내용을 적는다.\ntotal = 0 \nfor i in range(1,11): \n    total = total + i\nprint(total)\n- 파일이름을 mysum.py로 저장한다.\n- anaconda prompt에서 mysum.py파일이 저장된 폴더로 이동 -&gt; 실행\n(base) C:\\Users\\python&gt;cd Desktop\n\n(base) C:\\Users\\python\\Desktop&gt;dir\n C 드라이브의 볼륨에는 이름이 없습니다.\n 볼륨 일련 번호: 9AFD-A05F\n\n C:\\Users\\python\\Desktop 디렉터리\n\n2022-03-27  오전 11:32    &lt;DIR&gt;          .\n2022-03-27  오전 11:32    &lt;DIR&gt;          ..\n2022-03-27  오전 12:01             2,306 Chrome.lnk\n2022-03-26  오후 08:32             2,332 Microsoft Edge.lnk\n2022-03-27  오전 11:33                71 mysum.py\n               3개 파일               4,709 바이트\n               2개 디렉터리  743,643,467,776 바이트 남음\n\n(base) C:\\Users\\python\\Desktop&gt;python mysum.py\n55\n\n(base) C:\\Users\\python\\Desktop&gt;\n- 소감 - 편한점1: 마우스를 이용하여 이동가능 - 편한점2: 내가 작업한 내용은 바탕화면의 메모장에 저장이 되어있음 - 아쉬운점: ipython의 장점은 활용못함 (구문강조, 도움말기능)\n\n\n3세대 프로그래머: 메모장 + ipython\n- 전체적인 개발방식 - 메모장: 코드를 편집, 저장 - ipython: anaconda prompt처럼 메모장의 코드를 실행하고 결과를 확인 + 구문강조, 도움말확인기능 등을 이용하여 짧은 코드를 빠르게 작성\n- 기능 - ipython에서 !python mysum.py를 입력하면 anaconda prompt에서 python mysum.py를 입력한 것과 같은 효과 - ipython에서 %run mysum을 입력하면 메모장에서 mysum.py에 입력된 내용을 복사해서 ipython에 붙여넣어 실행한것과 같은 효과\n\n\n4세대 프로그래머: IDE(통합개발환경)를 사용\n- 메모장과 ipython을 하나로 통합한 프로그램이 등장! - jupyter notebook, jupyter lab - spyder - idle - VScode - …\n- 주피터의 트릭 (실제로 주피터는 ipython에 기생할 뿐 아무런 역할도 안해요)\n\n주피터를 실행\n새노트북을 생성 (파이썬으로 선택)\n\n\n컴퓨터는 내부적으로 ipython을 실행하고 그 ipython이랑 여러분이 방금만든 그 노트북과 연결\n\n\n처음보이는 cell에 1+1을 입력 -&gt; 쉬프트엔터 -&gt; 결과2가 출력\n\n\n처음보이는 cell하나 = 자동으로 열린 하나의 메모장\ncell 1+1을 입력 = 메모장에 1+1을 적음\n쉬프트+엔터후 결과2를 출력 = cell의 내용을 복사 -&gt; ipython에 붙여넣음 -&gt; ipython 계산된 결과를 복사 -&gt; cell로 돌아와 붙여넣기\n\n\n새로운 cell을 추가하고 2+2을 입력 -&gt; 쉬프트엔터 -&gt; 결과4가 출력\n\n\n새로운 cell을 추가 = 새로운 메모장 추가\ncell 2+2을 입력 = 새로운 메모장에 2+2를 적음\n쉬프트+엔터후 결과4를 출력 = cell의 내용을 복사 -&gt; ipython에 붙여넣음 -&gt; ipython 계산된 결과를 복사 -&gt; cell로 돌아와 붙여넣기\n\n- 중요한 사실들 - IDE는 내부적으로 연산을 수행하는 능력이 없다. (생각해볼것: 왜 R을 꼭 설치하고 Rstudio를 설치해야 했을까?) - 주피터에서 커널을 재시작한다는 의미는 메모장이 열린채로 ipython을 껐다가 다시 실행한다는 의미 - 주피터는 단순히 ’메모장의 내용을 복사하여 붙여넣는 기계’라고 볼 수 있다. 이렇게 생각하면 주피터는 꼭 ipython에 연결할 이유는 없다. 실제로 주피터에 R을 연결해서 쓸 수 있다. 즉 하나의 IDE가 여러개의 언어와 연결될 수 있다. - Jupyterlab이라는 프로그램은 크롬에 있는 내용과 ipython간의 통신을 제어하는 프로그램일 뿐이다.\n\n\n5세대 프로그래머: 가상컴퓨터(anaconda), 원격컴퓨터(server), 클라우드컴퓨터(colab)의 개념 등장\n- 지금까지는 ipython이 실행되는 컴퓨터와 크롬이 실행되는 컴퓨터가 동일하다는 전제였음.\n- 생각해보니까 어차피 ipython이 실행된 컴퓨터에서 내가 크롬에 입력한 명령 “전달”되기만 하면 되므로 꼭 같은 컴퓨터일 필요는 없다.\n\n모델1: 원격컴퓨터\n- 준비상태 - 전북대컴퓨터: ipython을 실행 + 이 컴퓨터는 인터넷 연결이 되어있어야함 - 우리집노트북: 크롬실행 + 이 컴퓨터도 인터넷이 연결되어 있어야함\n- 명령입력 - 우리집노트북 크롬에서 1+1을 입력하고 쉬프트 엔터를 누름\n- 우리집노트북 -&gt; 전북대컴퓨터 - 우리집 노트북의 내부의 어떤프로그램은 1+1이라는 명령을 복사하여 카카오톡으로 전북대 컴퓨터에 전달 - 전북대 컴퓨터의 내부의 어떤프로그램은 1+1이라는 명령을 카톡으로 받아서 그것을 ipython에게 전달\n- 전북대컴퓨터 -&gt; 우리집노트북 - 전북대컴퓨터 내부의 ipython은 2라는 출력결과를 계산함 - 전북대컴퓨터 내부의 어떤프로그램은 계산결과를 카톡으로 우리집 노트북에 알려줌 - 나는 우리집 노트북에서 계산결과를 받아볼 수 있다.\n\n\n모델2: 원격컴퓨터 + 가상컴퓨터\n- 준비상태 - 성능좋은 전북대 컴퓨터 1개 - 내 노트북 1개 (그냥 싸고 가벼운거) - 대학원생 아이패드 1개 (그냥 싸고 가벼운거)\n- 아이디어\n\n성능좋은 전북대 컴퓨터를 논리적으로 3개로 분리 \\(\\to\\) 이를 각각 (base) (py39jl17) (py38r40) 컴퓨터라고 하자.\n나는 (py39jl17)에 접속하여 파이썬 3.9와 줄리아 1.7을 설치한뒤 실습한다.\n대학원생은 (py38r40)에 접속하여 파이썬 3.8과 R 4.0을 설치하고 실습한다.\n(base)는 예비용으로 아무것도 설치안한 깨끗한 상태 유지\n내가 뭘 실수해서 (py39jl17)컴퓨터가 망가졌으나 (py38r40)은 아무 타격없다.\n나는 (py39jl17)를 삭제하고 (base)로 부터 다시 새로운 컴퓨터를 복사하여 (py39jl17)을 다시 만든다.\n\n\n\n모델3: 가상컴퓨터\n- 여러분들 사례 - 여러분들의 컴퓨터는 (base), (py39) 2개의 컴퓨터로 나누어져 있음 - 여러분들이 (py39)에만 주피터랩을 설치 - (py39)에 있는 ipython과 여러분의 크롬창이 서로 통신하면서 실습 - 장점: 서로 다른 환경에 서로다른 파이썬과 R등을 설치할 수 있다. \\(\\to\\) 패키지간의 충돌이 최소화 (파이썬 입문 수업을 듣고, 이후에 파이썬을 이용하는 어떤수업을 들음)\n\n\n모델4: 클라우드\n- 사례1 - 성능이 그저그런 컴퓨터 27개 - 대학원생을 포함하여 쓸 사람은 5명 - 한사람당 27/5(=5.4)대의 컴퓨터식 할당\n- 사례2: 구글코랩 - 구글에 여러가지 성능을 가진 컴퓨터가 \\(n\\)대 있음 - \\(m\\)명의 사람이 \\(n\\)대의 컴퓨터에 접속 - 적당히 컴퓨터 자언을 분배하여 사용\n\n\n\n요약 및 정리\n- 결국 (1) 컴퓨터에 (2) 파이썬을 설치하고 (3) 실행하는 과정은 생각보다 다양한 선택의 조합이 가능하다.\n\n그냥 내 노트북에 파이썬을 설치할지? 내 노트북안에 가상컴퓨터를 만들고 거기에 파이썬을 설치할지? 학교의 데스크탑에 파이썬을 설치하고 쓸지? 설치를 안하고 구글컴퓨터에 설치된 파이썬을 난 쓰기만 할지?\npython설치할지? ipython를 설치할지? 어차피 가상환경을 쓸꺼니가 anaconda를 설치할지? 아니면 코랩쓸꺼니까 설치안할지?\n어떤 IDE를 쓸지? IDE를 쓰지 않을지? 내가 IDE를 직접구성해서 만들지?\n\n하지만 공통적으로 관통하는 원리가 있다\n\n\n숙제\n- 주피터랩에서 ’myprod.py’파일을 만들고 1부터 5까지의 곱을 계산하는 코드를 작성후 %run myprod를 실행하여 출력결과를 확인"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html",
    "title": "[ggplot3]Original",
    "section": "",
    "text": "ggplot2 공부하다가 포기함\n그냥 ggplot2를 랩핑하여 내 스타일에 맞는 코드를 새로 만듬 (가칭 ggplot3)\n\nsource('ggplot3.R')\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n소스코드 다운로드: https://github.com/miruetoto/yechan3/blob/main/posts/1_Essays/ggplot3.R\n\n계속 업데이트할 예정"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#ggplot-line-point",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#ggplot-line-point",
    "title": "[ggplot3]Original",
    "section": "ggplot + line + point",
    "text": "ggplot + line + point\n\ny = rnorm(100)\n\n- 예시1\n\nggplot() + line(1:100, y, lty=2, col='gray60')\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot() + point(y,pch=2,col=2,cex=5)\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot() + point(y,pch=2,col=2,cex=5) + line(25:50, y[25:50], col=2, lwd=2)"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#ggplot2와-호환",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#ggplot2와-호환",
    "title": "[ggplot3]Original",
    "section": "ggplot2와 호환",
    "text": "ggplot2와 호환\n\ndf = data.frame(x=1:100,y=rnorm(100))\nhead(df)\n\n\nggplot(data=df) + \ngeom_point(aes(x=x,y=y)) + \nline(1:50,df$y[1:50],col=2,lty=2)\n\n\n\n\n\n\n\n\n\n완벽하게 호환가능"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#subplotting",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#subplotting",
    "title": "[ggplot3]Original",
    "section": "subplotting",
    "text": "subplotting\n\ny = rnorm(100)\np1 = ggplot() + line(y,lty=2,col='gray60')\np2 = ggplot() + point(y,pch=2,col=2,cex=5)\np3 = ggplot() + point(y,pch=2,col=2,cex=5) + line(25:50, y[25:50], col=2, lwd=2)\np4 = ggplot() + point(y) + line(1:50,y[1:50],col='orange')\n\n- 예시1: 좌우로 나란히\n\nfigsize(10,3)\np1|p2|p3|p4\nfigsize()\n\n\n\n\n\n\n\n\n- 예시2: 위아래로\n\nfigsize(10,5)\np1/p2/p3/p4\nfigsize()\n\n\n\n\n\n\n\n\n- 예시3: 그리드로!\n\nfigsize(10,5)\n(p1|p2)/(p3|p4)\nfigsize()\n\n\n\n\n\n\n\n\n- 예시4: 좀 더 난해한 모양으로 (1)\n\nfigsize(10,5)\n(p1|p2|p3)/p4\nfigsize()\n\n\n\n\n\n\n\n\n- 예시5: 좀 더 난해한 모양으로 (2)\n\nfigsize(10,5)\n(p1|p2|p3)/(p4|p1)\nfigsize()\n\n\n\n\n\n\n\n\n- 예시6: 좀 더 난해한 모양으로 (3)\n\nfigsize(10,5)\np1|(p2/p3/p4)\nfigsize()"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#ggtitle",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#ggtitle",
    "title": "[ggplot3]Original",
    "section": "ggtitle",
    "text": "ggtitle\n\ny = rnorm(100)\nggplot() + line(y,lty=2,col='gray60') + \nggtitle(\"(a) MY TITLE\")"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#xlab-ylab",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#xlab-ylab",
    "title": "[ggplot3]Original",
    "section": "xlab, ylab",
    "text": "xlab, ylab\n\ny = rnorm(100)\nggplot() + line(y,lty=2,col='gray60') + \nxlab(\"asdfasdfasdf\") + ylab(\"asdfasdfasdf\")"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#legends",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#legends",
    "title": "[ggplot3]Original",
    "section": "legends",
    "text": "legends\n\ny1 = rnorm(10)\ny2 = rnorm(10)\n\n\nggplot()+\nline(y1,label=\"y1\",lty=2)+point(y1,label=\"y1\",cex=3)+\nline(y2,label=\"y2\",lty=2)+point(y2,label=\"y2\",cex=3)"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#wide_y",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#wide_y",
    "title": "[ggplot3]Original",
    "section": "wide_y",
    "text": "wide_y\n- 예시1\n\ny1 = rnorm(10)\ny2 = rnorm(10)\n\n\nfigsize(6,4)\nggplot()+line(cbind(y1,y2),lty=2)+point(cbind(y1,y2),cex=3)\nfigsize()\n\n\n\n\n\n\n\n\n- 예시2\n\nx = 11:15\ny1 = rnorm(5)\ny2 = rnorm(5)\n\n\nfigsize(6,4)\nggplot()+line(x,cbind(y1,y2),lty=2)+point(x,cbind(y1,y2),cex=3)\nfigsize()"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#smooth",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#smooth",
    "title": "[ggplot3]Original",
    "section": "smooth",
    "text": "smooth\n\nx = 1:100/100\ny1 = 2*x + rnorm(100)*0.3\ny2 = -3*x + rnorm(100)*0.3 +3\n\n- 예시1\n\nggplot()+point(x,y1,alpha=0.5,col=\"gray60\") + smooth(x,y1,col=2)\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot()+point(x,y1,alpha=0.5,col=\"gray60\") +\nsmooth(x[1:60],y1[1:60],col=2) + \nsmooth(x[40:100],y1[40:100],col=4) \n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot()+point(x,cbind(y1,y2),alpha=0.5) +\nsmooth(x,cbind(y1,y2))\n\n`geom_smooth()` using method = 'loess' and formula = 'y ~ x'"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#area",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#area",
    "title": "[ggplot3]Original",
    "section": "area",
    "text": "area\n\ny1 = c(10,20,10,50)\ny2 = c(15,20,5,30)\n\n- 예시1\n\nggplot() + area(y1,fill=2)\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot() + area(cbind(y1,y2))"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#step",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#step",
    "title": "[ggplot3]Original",
    "section": "step",
    "text": "step\n\ny1 = cumsum(rnorm(100))\ny2 = cumsum(rnorm(100))\n\n- 예시1\n\nggplot() + step(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot() + step(cbind(y1,y2))"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#jitter",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#jitter",
    "title": "[ggplot3]Original",
    "section": "jitter",
    "text": "jitter\n\nx = sample(c(20,30,40,50),size=100,replace = TRUE)\ny = rnorm(100)\n\n\np1 = ggplot()+point(x,y)+ggtitle(\"geom_point\")\np2 = ggplot()+jitter(x,y,width = 1) + ggtitle(\"geom_jitter\")\nfigsize(10,5)\np1|p2\nfigsize()"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#histogram",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#histogram",
    "title": "[ggplot3]Original",
    "section": "histogram",
    "text": "histogram\n\ny1 = rnorm(1000)\ny2 = rnorm(1000)*0.5 + 3 \n\n- 예시1\n\nggplot()+histogram(c(y1,y2),fill=\"gray60\")\n\nWarning message:\n“`stat(density)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.”\n\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot()+histogram(y1,label=\"A\")+histogram(y2,label=\"B\")\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot()+histogram(cbind(y1,y2))"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#density",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#density",
    "title": "[ggplot3]Original",
    "section": "density",
    "text": "density\n\ny1 = rnorm(1000)\ny2 = rnorm(1000)*0.5 + 3 \n\n- 예시1\n\nggplot()+density(c(y1,y2))\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot()+density(y1,label=\"A\")+density(y2,label=\"B\")\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot()+density(cbind(y1,y2))\n\n\n\n\n\n\n\n\n- 예시4\n\nggplot()+histogram(cbind(y1,y2))+density(cbind(y1,y2))"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#qq",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#qq",
    "title": "[ggplot3]Original",
    "section": "qq",
    "text": "qq\n\ny1 = rnorm(100)\ny2 = rchisq(100,df=5)\n\n\nggplot()+\nqq(y1,label='y1')+qq_line(y1,label='y1')+\nqq(y2,label='y2')+qq_line(y2,label='y2')"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#col",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#col",
    "title": "[ggplot3]Original",
    "section": "col",
    "text": "col\n\ny1=c(1,2,3,5)\ny2=c(1,4,2,1)\n\n\nggplot()+col(y1,fill=2)\n\n\n\n\n\n\n\n\n\nggplot()+col(cbind(y1,y2))"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#boxplot",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#boxplot",
    "title": "[ggplot3]Original",
    "section": "boxplot",
    "text": "boxplot\n\ny1=rnorm(100)\ny2=rnorm(100)+3\n\n- 예시1\n\nggplot()+boxplot(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot()+boxplot(cbind(y1,y2))\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot()+boxplot(x='A',y1,label='A')+boxplot(x='B',y2,label='B')"
  },
  {
    "objectID": "posts/1_Note/2023-08-10-ggplot3.out.html#violin",
    "href": "posts/1_Note/2023-08-10-ggplot3.out.html#violin",
    "title": "[ggplot3]Original",
    "section": "violin",
    "text": "violin\n\ny1=rnorm(100)\ny2=rnorm(100)+3\n\n- 예시1\n\nggplot()+violin(y1)\n\n\n\n\n\n\n\n\n- 예시2\n\nggplot()+violin(cbind(y1,y2), color = \"transparent\")\n\n\n\n\n\n\n\n\n- 예시3\n\nggplot()+violin(x='A',y1,label='A')+violin(x='B',y2,label='B')"
  },
  {
    "objectID": "3_ittgnn.html",
    "href": "3_ittgnn.html",
    "title": "ITTGNN",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 18, 2023\n\n\nSelf Consistency Toy ex\n\n\nSEOYEON CHOI\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Lectures_ing",
      "**Researches**",
      "ITTGNN"
    ]
  },
  {
    "objectID": "2_graph.html",
    "href": "2_graph.html",
    "title": "Graph",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJul 2, 2023\n\n\nGraph Shift Operator\n\n\nSEOYEON CHOI\n\n\n\n\nJul 1, 2023\n\n\nNon-Euclidean vs Euclidean\n\n\nSEOYEON CHOI\n\n\n\n\nJun 30, 2023\n\n\nGraph Signal\n\n\nSEOYEON CHOI\n\n\n\n\nJun 30, 2023\n\n\nRegular Graph\n\n\nSEOYEON CHOI\n\n\n\n\nJan 15, 2023\n\n\n[CGSP] Chap 12.4: Node Subsampling for PSD Estimation\n\n\n신록예찬 \n\n\n\n\nDec 27, 2022\n\n\n[CGSP] Chap 12.2 ~ 3: Power Spectral Density and its Estimators\n\n\n신록예찬 \n\n\n\n\nDec 26, 2022\n\n\n[CGSP] Chap 12.2: Weakly Stationary Graph Processes\n\n\n신록예찬 \n\n\n\n\nDec 24, 2022\n\n\n[CGSP] Chap 8.3: Discrete Fourier Transform\n\n\n신록예찬 \n\n\n\n\n\nNo matching items",
    "crumbs": [
      "Lectures_ing",
      "**Studies**",
      "Graph"
    ]
  }
]