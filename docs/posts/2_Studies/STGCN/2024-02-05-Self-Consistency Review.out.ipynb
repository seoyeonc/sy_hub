{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Review: Self-Consistency: A Fundamental Concept in Statistics\n",
        "\n",
        "SEOYEON CHOI  \n",
        "2024-02-05\n",
        "\n",
        "**Y = Observed Data**\n",
        "\n",
        "**X = Completed Data**\n",
        "\n",
        "# 2. Self-Consistent Random Vectors\n",
        "\n",
        "Suppose we want to represent or approximate the distribution of a random\n",
        "vector $\\bf{X}$ by a random vector $\\bf{Y}$ whose structure is less\n",
        "complex.\n",
        "\n",
        "êµ¬ì¡°ê°€ ê°„ë‹¨í•œ(?) í™•ë¥ ë²¡í„° Yë¡œ í™•ë¥ ë²¡í„° Xì˜ ë¶„í¬ë¥¼ ê·¼ì‚¬í•˜ê±°ë‚˜ ë‚˜íƒ€ë‚´ë ¤\n",
        "í•œë‹¤ê³  í•˜ì.\n",
        "\n",
        "One measure of how well $\\bf{Y}$ approximates $\\bf{X}$ is the mean\n",
        "squared error $\\cal{E}||\\bf{X}-\\bf{Y}||^2$.\n",
        "\n",
        "Yë¡œ Xì˜ ê·¼ì‚¬ê°’ì„ ì˜ ì°¾ëŠ” í•œ ì¸¡ì •ì¹˜ëŠ” í‰ê· ì œê³±ì˜¤ì°¨ë¥¼ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.\n",
        "\n",
        "In terms of mean squarred error, the approximation of $\\bf{X}$ by\n",
        "$\\bf{Y}$ can always be improved using $\\cal{E} [\\bf{X}|\\bf{Y}]$ since,\n",
        "for any function $g$,\n",
        "$\\cal{E} ||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-g(\\bf{Y})||^2$.\n",
        "\n",
        "í‰ê· ì œê³±ì˜¤ì°¨ì— ê´€í•´ ë§í•˜ìë©´, Yì— ì˜í•´ Xì˜ ê·¼ì‚¬ì¹˜ëŠ” í•­ìƒ Y ê°€ ì£¼ì–´ì¡Œì„ë•Œ\n",
        "Xì˜ ê¸°ëŒ€ê°’ìœ¼ë¡œ ê°œì„ ë  ìˆ˜ ìˆëŠ”ë°, ì–´ëŠ í•¨ìˆ˜ gì— ëŒ€í•´ì„œë‚˜ ìœ„ì˜ ì‹ì´\n",
        "ì„±ë¦½í•œë‹¤.\n",
        "\n",
        "-   $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ ì´ê²Œ ìµœì†Ÿê°’ì´ë¼ëŠ” ëœ»\n",
        "\n",
        "Taking $g$ to be the identity gives\n",
        "$\\cal{E} || \\bf{X} - \\cal{E} [\\bf{X}|\\bf{Y}]||^2 \\le \\cal{E} ||\\bf{X}-\\bf{Y}||^2$.\n",
        "\n",
        "í•¨ìˆ˜ gì— Yë¥¼ ì£¼ë©´, ìœ„ì˜ ì‹ì´ ëœë‹¤.\n",
        "\n",
        "-   E\\[X\\|Y\\] =Yì¼ë•Œ Yê°€ Xì— ëŒ€í•´ self-cosistent í•˜ë‹¤ê³  í—€ìœ¼ë‹ˆê¹Œ í•¨ìˆ˜\n",
        "    g(Y) = Yë¼ í•œë‹¤ë©´?\n",
        "\n",
        "Thus the random vector $Y$ is locally optimal for approximating $\\bf{X}$\n",
        "if $\\bf{Y} = \\cal{E} [\\bf{X}|\\bf{Y}]$, in which case we call $Y$\n",
        "self-consistent for $\\bf{X}$.\n",
        "\n",
        "ë§Œì¼ Yê°€ Yê°€ ì£¼ì–´ì¡Œì„ë•Œ Xì˜ ê¸°ëŒ“ê°’ê³¼ ê°™ë‹¤ë©´, í™•ë¥ ë²¡í„° YëŠ” Xì— ê·¼ì‚¬í•˜ëŠ”ë°\n",
        "ìˆì–´ locally optimal í•˜ë‹¤. ì´ë•Œ, Yë¥¼ Xì— ëŒ€í•´ self-consistent í•˜ë‹¤ê³ \n",
        "ë¶€ë¥¸ë‹¤.\n",
        "\n",
        "-   $\\cal{E}$$||\\bf{X}-\\cal{E} [\\bf{X}|\\bf{Y}]||^2$ ê³„ì‚°í• ë•Œì—\n",
        "    ëŒ€í•´(locally) E(X\\|Y) = Yë¼ë©´, ìµœì ì˜ ê°’(ìµœì†Œì˜ ê°’, optimal)í•˜ë‹¤.\n",
        "\n",
        "<span style=\"background-color:#CCCCFF\"> **DEFINITION 2.1.** </span> For\n",
        "two jointly distributed random vectors $\\bf{X}$ and $\\bf{Y}$, we say\n",
        "that $\\bf{Y}$ is self-consistent for $\\bf{X}$ if\n",
        "$\\cal{E} (\\bf{X}|\\bf{Y}) = \\bf{Y}$ almost surely.\n",
        "\n",
        "ë‘ ê²°í•© ë¶„í¬ëœ í™•ë¥ ë²¡í„° Xì™€ Yì— ëŒ€í•´ Yê°€ ì£¼ì–´ì¡Œì„ë•Œ Xì˜ ê¸°ëŒ“ê°’ì´ Yì™€\n",
        "ë™ì¼í•˜ë‹¤ë©´ Yë¥¼ Xì— ëŒ€í•´ self-consistent í•˜ë‹¤ê³  í•œë‹¤.\n",
        "\n",
        "`1` $\\bf{Y} = \\bf{X} + \\epsilon$ $(\\epsilon \\sim i.i.d.)$ì´ë¼ë©´,\n",
        "$E(X|Y) = Y$ $Y$ëŠ” $X$ì— ëŒ€í•´ self-consistent í•˜ë‹¤.\n",
        "\n",
        "`2` $\\bar{X} = \\frac{1}{3}(x_1+x_2+x_3)$,\n",
        "$\\tilde{X} = \\frac{1}{3}(\\mu +x_2+x_3)$,\n",
        "$E(\\bar{X}|\\tilde{X}) = \\frac{1}{3}E(x_1) + \\tilde{X} - \\frac{1}{3}\\mu \\tilde{X} = \\tilde{X}$\n",
        "$\\tilde{X}$ëŠ” $\\bar{X}$ì— ëŒ€í•´ self-consistent í•˜ë‹¤.\n",
        "\n",
        "We will assume implicitly that moments exist as required.\n",
        "\n",
        "í•„ìš”ì— ë”°ë¼ ì´ëŸ° momentê°€ ì¡´ì¬í•œë‹¤ê³  ì•”ë¬µì ìœ¼ë¡œ ê°€ì •í•  ê²ƒì´ë‹¤.\n",
        "\n",
        "-   definitionì˜ ê²½ìš°ê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •í•œë‹¤..?\n",
        "\n",
        "The notion of self-consistency is not vacuous, as the two extreme cases\n",
        "demonstrate.\n",
        "\n",
        "ë‘ ê·¹ë‹¨ì ì¸ ê²½ìš°ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ë“¯ì´, self-consistencyëŠ” ëª¨í˜¸í•œ ê°œë…ì´\n",
        "ì•„ë‹ˆë‹¤.\n",
        "\n",
        "The random vector $\\bf{X}$ is self-consistent for $\\bf{X}$ and\n",
        "represents no loss of information.\n",
        "\n",
        "í™•ë¥  ë²¡í„° XëŠ” Xì— ëŒ€í•´ self-consistent í•˜ë©°, informationì˜ ì†ì‹¤ì´ ì „í˜€\n",
        "ì—†ë‹¤.\n",
        "\n",
        "$\\bf{Y} = \\cal{E} [\\bf{X}]$ is also self-consistent for $\\bf{X}$ and\n",
        "represents a total loss of information except for the location of the\n",
        "distribution.\n",
        "\n",
        "Y=E(X)ëŠ” Xì— ëŒ€í•´ self-consistent í•˜ë©°, ë¶„í¬ì˜ ìœ„ì¹˜ë¥¼ ì œì™¸í•˜ê³ \n",
        "informationì´ ì „ì²´ì ìœ¼ë¡œ ì†ì‹¤ëœë‹¤.\n",
        "\n",
        "Interesting self-consistent distributions range in between these two\n",
        "extremes.\n",
        "\n",
        "ì´ ë‘ ê·¹ë‹¨ì ì¸ ê²½ìš° ì‚¬ì´ì— self-consistent ë¶„í¬ë“¤ì´ ìˆë‹¤.\n",
        "\n",
        "`1` $\\bf{X}$ëŠ” information ì†ì‹¤ì´ ì—†ì§€ë§Œ, $\\bf{Y}=E(X)$ëŠ” $\\epsilon$ì„\n",
        "ìƒì–´ì„œ information ì†ì‹¤ì´ ìƒê¸´ë‹¤.\n",
        "\n",
        "`2` $\\bar{X}$ëŠ” information ì†ì‹¤ì´ ì—†ì§€ë§Œ, $\\tilde{X} = E(\\bar{X})$ëŠ”\n",
        "$x_1$ì´ $\\mu$ë¡œ ë°”ë€Œì–´ information ì†ì‹¤ì´ ìƒê¸´ë‹¤.\n",
        "\n",
        "Many relevant cases of self-consistency are obtained by taking\n",
        "conditional means over subsets of the sample space of $\\bf{X}$.\n",
        "\n",
        "self-consistencyì˜ ë§ì€ ê´€ë ¨ëœ ê²½ìš°ëŠ” ì§‘í•© ğ—ì˜ í‘œë³¸ ê³µê°„ì˜ ë¶€ë¶„ì§‘í•©ì—\n",
        "ëŒ€í•œ ì¡°ê±´ë¶€ í‰ê· ì„ ì·¨í•¨ìœ¼ë¡œì¨ êµ¬í•´ì§„ë‹¤.\n",
        "\n",
        "Another simple example of self-consistency is the following:\n",
        "\n",
        "ë˜ë‹¤ë¥¸ self-consistencyì˜ ë‹¨ìˆœí•œ ì˜ˆì œì´ë‹¤.\n",
        "\n",
        "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.1.** </span>\n",
        "*Partial sums.* Let $\\{X_n\\}$ denote a sequence of independent,\n",
        "mean-zero random variables, and let $S_n = \\sum^n_{i=1} X_i$.\n",
        "\n",
        "ë¶€ë¶„í•©, x_nì„ ë…ë¦½ì´ê³ , í‰ê· ì´ 0ì¸ í™•ë¥  ë³€ìˆ˜ë¼ê³  í•  ë•Œ, xì˜ í•©ì„ Snì´ë¼\n",
        "ë‘ì.\n",
        "\n",
        "Then\n",
        "$\\cal{E}$$[S_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}|S_n] = S_n + \\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] = S_n$.\n",
        "\n",
        "ê·¸ëŸ¬ë©´ ì´ ì‹ì´ ì„±ë¦½í•¨.\n",
        "\n",
        "`-` ì¦ëª…\n",
        "$\\cal{E}$$[S_{n+k}|S_n]=$$\\cal{E}$$[S_n + X_{n+1} + \\dots + X_{n+k}|S_n]=$$\\cal{E}$$[X_{1} + \\dots + X_n + X_{n+1} + \\dots +X_{n+k}|S_n]=$$\\cal{E}$$[X_{n+1} + \\dots + X_{n+k}] + S_n=S_n$\n",
        "\n",
        "Thus, $S_n$ is self-consistent for $S_{n+k}, k > 1$.\n",
        "\n",
        "ê·¸ë ¤ë©´ snì€ sn+kì— ëŒ€í•´ self-consistentí•˜ë‹¤ê³  í•¨.\n",
        "\n",
        "The same property holds more generally if $\\{S_n\\}_{n\\ge1}$ represents a\n",
        "martingale process.\n",
        "\n",
        "ë§Œì¼ ì € ì‹ì´ ë§ˆí‹´ê²Œì¼ í”„ë¡œì„¸ìŠ¤ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤ë©´ ë™ì¼í•œ íŠ¹ì„±ì´ ìœ ì§€ëœë‹¤.\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> martingale process ì˜ íŠ¹ì§•\n",
        ">\n",
        "> -   ê¸°ëŒ“ê°’ì˜ ì¼ì •ì„±\n",
        "> -   í™•ë¥ ë³€ìˆ˜ì˜ ë¶„í¬ ê³ ì •\n",
        "\n",
        "For a given $\\bf{X}$, a self-consistent approximation $\\bf{Y}$ can be\n",
        "generated by partitioning the sample space of $\\bf{X}$ and defining\n",
        "$\\bf{Y}$ as a random variable taking as values the conditional means, of\n",
        "subsets in the partition.\n",
        "\n",
        "ì£¼ì–´ì§„ í™•ë¥  ë³€ìˆ˜ $\\bf{X}$ì— ëŒ€í•œ self-consistent approximation\n",
        "$\\bf{Y}$ëŠ” $\\bf{X}$ì˜ í‘œë³¸ ê³µê°„ì„ ë¶„í• í•˜ì—¬ ê° ë¶„í• ëœ ë¶€ë¶„ì§‘í•©ì— ëŒ€í•œ\n",
        "ì¡°ê±´ë¶€ í‰ê· ì„ ê°’ìœ¼ë¡œ ê°€ì§€ëŠ” ëœë¤ ë³€ìˆ˜ë¡œ ì •ì˜ë  ìˆ˜ ìˆë‹¤.\n",
        "\n",
        "This is illustrated by our next example, in which the support of\n",
        "$\\bf{X}$ is partitioned into two half-planes.\n",
        "\n",
        "ë‹¤ìŒ ì˜ˆì œì—ì„œ í™•ë¥  ë³€ìˆ˜ $\\bf{X}$ì˜ support(ëª¨ë“  ê°’?)ê°€ ë‘ ê°œì˜ ë°˜\n",
        "í‰ë©´ìœ¼ë¡œ ë‚˜ë‰œë‹¤.(x1\\>0,x1\\<=0ì¸ë“¯?)\n",
        "\n",
        "<span style=\"background-color:#9966FF\"> **EXAMPLE 2.2.** </span> *Two\n",
        "principal points.* Let $\\bf{X} = (X_1, X_2)' \\sim N_2(0, I_2)$. Note\n",
        "that $\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{2/\\pi}$. Let\n",
        "$\\bf{Y} = (-\\sqrt{2/\\pi}, 0)'$ if $X_1 < 0$ and\n",
        "$\\bf{Y} = (\\sqrt{2/\\pi}, 0)'$ if $X_1 > 0$. Then $\\bf{Y}$ is\n",
        "self-consistent for $\\bf{X}$.\n",
        "\n",
        "$\\bf{Y} = \\begin{cases}(-\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 < 0 \\\\ (\\sqrt{\\frac{2}{\\pi}}, 0)' & if X_1 \\ge 0 \\end{cases}$,\n",
        "$\\cal{E}$$[X_1|X_1 \\ge 0] = \\sqrt{\\frac{2}{\\pi}}$\n",
        "\n",
        "See Section 6 for a definition of principal points, and see Figure 7 for\n",
        "a generalization of this example."
      ],
      "id": "092da8df-92a5-4290-a65b-8ffd19531a7e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<span style=\"background-color:#9966FF\"> </span>"
      ],
      "id": "45f4efb6-8e08-41c6-b288-1a955074f72d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "<span style=\"background-color:#9966FF\"> </span>"
      ],
      "id": "ff036d02-4623-4911-b16f-4652f7b997b0"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  }
}