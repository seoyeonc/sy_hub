<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.527">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="SEOYEON CHOI">
<meta name="dcterms.date" content="2024-07-31">

<title>Seoyeon’s Blog - EbayesThresh Torch</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-sidebar docked nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Seoyeon’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/md/"> 
<span class="menu-text">Lectures_ing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/chch/"> 
<span class="menu-text">Lectures_fastai</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/Research_area/"> 
<span class="menu-text">Research_ing</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/ms/"> 
<span class="menu-text">Research_fastai</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/GODE_blog/"> 
<span class="menu-text">GODE</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/HCAM_blog/"> 
<span class="menu-text">HCAM</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/ITTGNN_blog/"> 
<span class="menu-text">ITTGNN</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://seoyeonc.github.io/julia/"> 
<span class="menu-text">Julia</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/seoyeonc"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item">EbayesThresh Torch</li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">EbayesThresh Torch</h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>SEOYEON CHOI </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">July 31, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation docked overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../1_note.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><strong>Note</strong></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text"><strong>Studies</strong></span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_graph.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Graph</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_ept.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">EPT</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_stgcn.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">STGCN</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_linearalgebra.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Linear Algebra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../2_kan.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">KAN</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#import" id="toc-import" class="nav-link active" data-scroll-target="#import">Import</a>
  <ul class="collapse">
  <li><a href="#import-for-code-check" id="toc-import-for-code-check" class="nav-link" data-scroll-target="#import-for-code-check">import for code check</a></li>
  </ul></li>
  <li><a href="#beta.cauchy" id="toc-beta.cauchy" class="nav-link" data-scroll-target="#beta.cauchy">beta.cauchy</a></li>
  <li><a href="#beta.laplace" id="toc-beta.laplace" class="nav-link" data-scroll-target="#beta.laplace">beta.laplace</a></li>
  <li><a href="#cauchy_medzero" id="toc-cauchy_medzero" class="nav-link" data-scroll-target="#cauchy_medzero">cauchy_medzero</a></li>
  <li><a href="#cauchy_threshzero" id="toc-cauchy_threshzero" class="nav-link" data-scroll-target="#cauchy_threshzero">cauchy_threshzero</a></li>
  <li><a href="#ebayesthresh" id="toc-ebayesthresh" class="nav-link" data-scroll-target="#ebayesthresh">ebayesthresh</a></li>
  <li><a href="#isotone" id="toc-isotone" class="nav-link" data-scroll-target="#isotone">isotone</a></li>
  <li><a href="#laplace_threshzero" id="toc-laplace_threshzero" class="nav-link" data-scroll-target="#laplace_threshzero">laplace_threshzero</a></li>
  <li><a href="#negloglik_laplace" id="toc-negloglik_laplace" class="nav-link" data-scroll-target="#negloglik_laplace">negloglik_laplace</a></li>
  <li><a href="#postmean" id="toc-postmean" class="nav-link" data-scroll-target="#postmean">postmean</a></li>
  <li><a href="#postmean_cauchy" id="toc-postmean_cauchy" class="nav-link" data-scroll-target="#postmean_cauchy">postmean_cauchy</a></li>
  <li><a href="#postmean.laplace" id="toc-postmean.laplace" class="nav-link" data-scroll-target="#postmean.laplace">postmean.laplace</a></li>
  <li><a href="#postmed" id="toc-postmed" class="nav-link" data-scroll-target="#postmed">postmed</a></li>
  <li><a href="#postmed_cauchy" id="toc-postmed_cauchy" class="nav-link" data-scroll-target="#postmed_cauchy">postmed_cauchy</a></li>
  <li><a href="#postmed_laplace" id="toc-postmed_laplace" class="nav-link" data-scroll-target="#postmed_laplace">postmed_laplace</a></li>
  <li><a href="#threshld" id="toc-threshld" class="nav-link" data-scroll-target="#threshld">threshld</a></li>
  <li><a href="#wandafromx" id="toc-wandafromx" class="nav-link" data-scroll-target="#wandafromx">wandafromx</a></li>
  <li><a href="#madmedian-absolute-deviation" id="toc-madmedian-absolute-deviation" class="nav-link" data-scroll-target="#madmedian-absolute-deviation">Mad(Median Absolute Deviation)</a></li>
  <li><a href="#wfromt" id="toc-wfromt" class="nav-link" data-scroll-target="#wfromt">wfromt</a></li>
  <li><a href="#wfromx" id="toc-wfromx" class="nav-link" data-scroll-target="#wfromx">wfromx</a></li>
  <li><a href="#wmonfromx" id="toc-wmonfromx" class="nav-link" data-scroll-target="#wmonfromx">wmonfromx</a></li>
  <li><a href="#vecbinsolv" id="toc-vecbinsolv" class="nav-link" data-scroll-target="#vecbinsolv">vecbinsolv</a></li>
  <li><a href="#tfromw" id="toc-tfromw" class="nav-link" data-scroll-target="#tfromw">tfromw</a></li>
  <li><a href="#tfromx" id="toc-tfromx" class="nav-link" data-scroll-target="#tfromx">tfromx</a></li>
  <li><a href="#wpost_laplace" id="toc-wpost_laplace" class="nav-link" data-scroll-target="#wpost_laplace">wpost_laplace</a></li>
  <li><a href="#zetafromx" id="toc-zetafromx" class="nav-link" data-scroll-target="#zetafromx">zetafromx</a></li>
  <li><a href="#layer" id="toc-layer" class="nav-link" data-scroll-target="#layer">Layer</a></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="2024-07-31-EbayesThresh_Torch.out.ipynb" download="2024-07-31-EbayesThresh_Torch.out.ipynb"><i class="bi bi-journal-code"></i>Jupyter</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>ref</p>
<ul>
<li><a href="https://cran.r-project.org/web/packages/EbayesThresh/EbayesThresh.pdf">R_ebayesthresh</a></li>
<li><a href="https://guebin.github.io/STML2022/posts/II.%20DNN/2022-10-12-6wk.html#%EC%8B%9C%EB%B2%A4%EC%BD%94%EC%A0%95%EB%A6%AC">교수님 블로그</a></li>
</ul>
<section id="import" class="level1">
<h1>Import</h1>
<div id="7b74dbea-662a-4ddf-b71f-b5ad0edf1778" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> ebayesthresh_torch</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span></code></pre></div>
</div>
<div id="1fe09402-7ce3-430c-b8d9-7e47cedfc0e2" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>torch.set_printoptions(precision<span class="op">=</span><span class="dv">15</span>)</span></code></pre></div>
</div>
<section id="import-for-code-check" class="level2">
<h2 class="anchored" data-anchor-id="import-for-code-check">import for code check</h2>
<div id="f3cdc0d8-dd47-41bc-b885-310cb7df3bab" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> norm</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.optimize <span class="im">import</span> minimize</span></code></pre></div>
</div>
</section>
</section>
<section id="beta.cauchy" class="level1">
<h1>beta.cauchy</h1>
<blockquote class="blockquote">
<p>Function beta for the quasi-Cauchy prior</p>
</blockquote>
<ul>
<li>Description</li>
</ul>
<blockquote class="blockquote">
<p>Given a value or vector x of values, find the value(s) of the function <span class="math inline">\(\beta(x) = g(x)/\phi(x) − 1\)</span>, where <span class="math inline">\(g\)</span> is the convolution of the quasi-Cauchy with the normal density <span class="math inline">\(\phi(x)\)</span>.</p>
</blockquote>
<p><em>x가 입력되면 코시 분포와 정규 분포를 혼합해서 함수 베타 구하기</em></p>
<div id="6eda332f-56ae-45e3-83d0-60372bbb189d" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>],dtype<span class="op">=</span>torch.float64)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([-2.,  1.,  0., -4.,  8., 50.], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="fc668167-7b42-4d5b-8df7-f59dc9cc6f50" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>phix <span class="op">=</span> torch.tensor(norm.pdf(x, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>phix</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([5.399096651318805e-02, 2.419707245191434e-01, 3.989422804014327e-01,
        1.338302257648853e-04, 5.052271083536893e-15, 0.000000000000000e+00],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="3ba12ffc-e05c-44c1-813b-31a0e035f2a1" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>j <span class="op">=</span> (x <span class="op">!=</span> <span class="dv">0</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>j</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor([ True,  True, False,  True,  True,  True])</code></pre>
</div>
</div>
<div id="c266f6ca-5fe4-44f5-95d7-5b784baee24b" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> x.clone()</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>tensor([-2.,  1.,  0., -4.,  8., 50.], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="a4f36c1f-c89b-47bb-90ab-b7ba218ae245" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> torch.where(j <span class="op">==</span> <span class="va">False</span>, <span class="op">-</span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span>, beta)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([-2.000000000000000,  1.000000000000000, -0.500000000000000,
        -4.000000000000000,  8.000000000000000, 50.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="d64006bb-cfd1-4ef6-81db-fc0f3b4dfa6a" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>beta[j] <span class="op">=</span> (torch.tensor(norm.pdf(<span class="dv">0</span>, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">/</span> phix[j] <span class="op">-</span> <span class="dv">1</span>) <span class="op">/</span> (x[j] <span class="op">**</span> <span class="dv">2</span>) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([ 5.972640247326628e-01, -3.512787292998718e-01, -5.000000000000000e-01,
         1.852473741901080e+02,  1.233796252853370e+12,                    inf],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="eae54078-b79b-47a5-b7a2-87d34b27ff48" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([ 5.972640247326628e-01, -3.512787292998718e-01, -5.000000000000000e-01,
         1.852473741901080e+02,  1.233796252853370e+12,                    inf],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R code</li>
</ul>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>beta.cauchy <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   Find the function beta for the mixed normal prior with Cauchy</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   tails.  It is assumed that the noise variance is equal to one.</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    phix <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    j <span class="ot">&lt;-</span> (x <span class="sc">!=</span> <span class="dv">0</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    beta <span class="ot">&lt;-</span> x</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>    beta[<span class="sc">!</span>j] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">1</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>    beta[j] <span class="ot">&lt;-</span> (<span class="fu">dnorm</span>(<span class="dv">0</span>)<span class="sc">/</span>phix[j] <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">/</span>x[j]<span class="sc">^</span><span class="dv">2</span> <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(beta)</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><strong>결과</strong></p>
<ul>
<li>Python</li>
</ul>
<div id="bb4b9c53-44e8-45a2-9eb9-abc205f9729e" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.beta_cauchy(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x,dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([ 5.972640247326628e-01, -3.512787292998718e-01, -5.000000000000000e-01,
         1.852473741901080e+02,  1.233796252853370e+12,                    inf],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">beta.cauchy</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>))</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>]  <span class="fl">5.972640e-01</span> <span class="sc">-</span><span class="fl">3.512787e-01</span> <span class="sc">-</span><span class="fl">5.000000e-01</span>  <span class="fl">1.852474e+02</span>  <span class="fl">1.233796e+12</span>           <span class="cn">Inf</span></span></code></pre></div>
</section>
<section id="beta.laplace" class="level1">
<h1>beta.laplace</h1>
<blockquote class="blockquote">
<p>Function beta for the Laplace prior</p>
</blockquote>
<ul>
<li>Description</li>
</ul>
<blockquote class="blockquote">
<p>Given a single value or a vector of <span class="math inline">\(x\)</span> and <span class="math inline">\(s\)</span>, find the value(s) of the function <span class="math inline">\(\beta(x; s, a) = \frac{g(x; s, a)}{f_n(x; 0, s)}−1\)</span>, where <span class="math inline">\(f_n(x; 0, s)\)</span> is the normal density with mean <span class="math inline">\(0\)</span> and standard deviation <span class="math inline">\(s\)</span>, and <span class="math inline">\(g\)</span> is the convolution of the Laplace density with scale parameter a, <span class="math inline">\(γa(\mu)\)</span>, with the normal density <span class="math inline">\(f_n(x; µ, s)\)</span> with mean mu and standard deviation <span class="math inline">\(s\)</span>.</p>
</blockquote>
<p><em>평균이 <span class="math inline">\(\mu\)</span>이며, 스케일 파라메터 a를 가진 라플라스와 정규분포의 합성함수 <span class="math inline">\(g\)</span>와 평균이 0이고 표준편차가s인 f로 계산되는 함수 베타</em></p>
<div id="231edf1b-c02e-4e9d-bbeb-084b7b5a168e" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>])</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># x = torch.tensor([2.14])</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># s = 1</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> torch.arange(<span class="dv">1</span>, <span class="dv">7</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<ul>
<li>s는 표준편차</li>
<li>a는 Laplaxe prior모수, 이 값이 클수록 부포 모양이 뾰족해진다.</li>
</ul>
<div id="a1babd46-c8f0-4575-b3c8-8661ce672520" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.<span class="bu">abs</span>(x)</span></code></pre></div>
</div>
<div id="37c2e5bd-81aa-4365-9019-40d08310229a" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>xpa <span class="op">=</span> x <span class="op">/</span> s <span class="op">+</span> s <span class="op">*</span> a</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>xpa</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor([ 2.500000000000000,  1.500000000000000,  1.500000000000000,
         3.000000000000000,  4.099999904632568, 11.333333015441895])</code></pre>
</div>
</div>
<div id="3968f7d1-fc01-476e-b944-c8e231bdf91b" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> x <span class="op">/</span> s <span class="op">-</span> s <span class="op">*</span> a</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="27">
<pre><code>tensor([ 1.500000000000000, -0.500000000000000, -1.500000000000000,
        -1.000000000000000, -0.899999976158142,  5.333333015441895])</code></pre>
</div>
</div>
<div id="5710c404-5861-4a00-a1ce-10d12b47be56" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>rat1 <span class="op">=</span> torch.tensor(<span class="dv">1</span> <span class="op">/</span> xpa, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>rat1</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([0.400000005960464, 0.666666686534882, 0.666666686534882,
        0.333333343267441, 0.243902444839478, 0.088235296308994],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="208574c0-82c0-4fc2-a95a-38cc2b754c9a" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>rat1[xpa <span class="op">&lt;</span> <span class="dv">35</span>] <span class="op">=</span> torch.tensor(norm.cdf(<span class="op">-</span>xpa[xpa <span class="op">&lt;</span> <span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> norm.pdf(xpa[xpa <span class="op">&lt;</span> <span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a>rat1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([0.354265111329793, 0.515815638217963, 0.515815638217963,
        0.304590298710103, 0.231426437747953, 0.087563795564412],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="ba2da327-d276-4095-80fb-6a5a3889b065" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>rat2 <span class="op">=</span> torch.tensor(<span class="dv">1</span> <span class="op">/</span> torch.<span class="bu">abs</span>(xma), dtype<span class="op">=</span>torch.float64)</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a>rat2</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([0.666666686534882, 2.000000000000000, 0.666666686534882,
        1.000000000000000, 1.111111164093018, 0.187500014901161],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="3b5739ac-66c0-4c39-a573-0adae5b68942" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> torch.where(xma <span class="op">&gt;</span> <span class="dv">35</span>, torch.tensor(<span class="fl">35.0</span>), xma)</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([ 1.500000000000000, -0.500000000000000, -1.500000000000000,
        -1.000000000000000, -0.899999976158142,  5.333333015441895])</code></pre>
</div>
</div>
<div id="937fcc63-4dcd-4f69-8a7d-43f5a9b3be77" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>rat2[xma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>] <span class="op">=</span> torch.tensor(norm.cdf(xma[xma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>) <span class="op">/</span> norm.pdf(xma[xma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>rat2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([7.205143007274778e+00, 8.763644564536923e-01, 5.158156382179633e-01,
        6.556795424187986e-01, 6.917336748702121e-01, 3.764625749653171e+06],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="c92d8331-7aec-446d-a148-c0e89b610e13" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> (a <span class="op">*</span> s) <span class="op">/</span> <span class="dv">2</span> <span class="op">*</span> (rat1 <span class="op">+</span> rat2) <span class="op">-</span> <span class="dv">1</span></span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>tensor([ 8.898520296511427e-01, -3.039099526641722e-01, -2.262765426730551e-01,
        -3.973015887109854e-02,  1.539501407727066e-01,  5.646937755825450e+06],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R code</li>
</ul>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>beta.laplace <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  The function beta for the Laplace prior given parameter a and s (sd)</span></span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">abs</span>(x)</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>    xpa <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">+</span> s<span class="sc">*</span>a</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>    xma <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">-</span> s<span class="sc">*</span>a</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>    rat1 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>xpa</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>    rat1[xpa <span class="sc">&lt;</span> <span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="fu">pnorm</span>( <span class="sc">-</span> xpa[xpa <span class="sc">&lt;</span> <span class="dv">35</span>])<span class="sc">/</span><span class="fu">dnorm</span>(xpa[xpa <span class="sc">&lt;</span> <span class="dv">35</span>])</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>    rat2 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">abs</span>(xma)</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>    xma[xma <span class="sc">&gt;</span> <span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="dv">35</span></span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>    rat2[xma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(xma[xma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>])<span class="sc">/</span><span class="fu">dnorm</span>(xma[xma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>])</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>    beta <span class="ot">&lt;-</span> (a <span class="sc">*</span> s) <span class="sc">/</span> <span class="dv">2</span> <span class="sc">*</span> (rat1 <span class="sc">+</span> rat2) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb43-14"><a href="#cb43-14" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(beta)</span>
<span id="cb43-15"><a href="#cb43-15" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><strong>결과</strong></p>
<ul>
<li>Python</li>
</ul>
<div id="bb7f3af1-e452-4b76-ab27-56d9c1c2c5a8" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.beta_laplace(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]),s<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor([ 8.898520296511427e-01, -3.800417166060107e-01, -5.618177717731538e-01,
         2.854594666723506e+02,  1.026980615772411e+12, 6.344539544172600e+265],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="ab955f9b-2802-4199-9db5-2f9ee57a4cb7" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.beta_laplace(torch.tensor([<span class="op">-</span><span class="fl">2.0</span>]),s<span class="op">=</span><span class="dv">1</span>,a<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([0.889852029651143], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="032868a9-2856-4554-89af-3d63a0a30d85" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.beta_laplace(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]),s<span class="op">=</span>torch.arange(<span class="dv">1</span>, <span class="dv">7</span>),a <span class="op">=</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="36">
<pre><code>tensor([ 8.908210552068985e-01, -1.299192504522433e-01, -8.622910386969129e-02,
        -5.203193149163621e-03,  5.421370604118225e-02,  1.124934917993122e+02],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb50"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">beta.laplace</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>), <span class="at">s=</span><span class="dv">1</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>]   <span class="fl">8.898520e-01</span>  <span class="sc">-</span><span class="fl">3.800417e-01</span>  <span class="sc">-</span><span class="fl">5.618178e-01</span>   <span class="fl">2.854595e+02</span>   <span class="fl">1.026981e+12</span>  <span class="fl">6.344540e+265</span></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">beta.laplace</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="at">s=</span><span class="dv">1</span>, <span class="at">a=</span><span class="fl">0.5</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.889852</span></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">beta.laplace</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>), <span class="at">s=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, <span class="at">a=</span><span class="dv">1</span>)</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>]   <span class="fl">0.890821055</span>  <span class="sc">-</span><span class="fl">0.129919250</span>  <span class="sc">-</span><span class="fl">0.086229104</span>  <span class="sc">-</span><span class="fl">0.005203193</span>   <span class="fl">0.054213718</span> <span class="fl">112.493576777</span></span></code></pre></div>
</section>
<section id="cauchy_medzero" class="level1">
<h1>cauchy_medzero</h1>
<blockquote class="blockquote">
<p>the objective function that has to be zeroed, component by component, to find the posterior median when the quasi-Cauchy prior is used. x is the parameter vector, z is the data vector, w is the weight x and z may be scalars</p>
</blockquote>
<ul>
<li>quasi-Cauchy prior에서 사후 중앙값 찾기 위한 함수</li>
<li>x,z는 벡터일수도 있고, 스칼라일 수 도 있다.</li>
</ul>
<div id="110b1f7b-25e8-4439-b088-769895d8782c" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span>  torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>])</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a><span class="co"># x = torch.tensor(4)</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span>  torch.tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># z = torch.tensor(5)</span></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor(<span class="fl">0.5</span>)</span></code></pre></div>
</div>
<div id="54e20a49-11c3-47f5-9445-8dd770805f20" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>hh <span class="op">=</span> z <span class="op">-</span> x</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>hh</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([  3,  -1,   2,   7,  -9, -51])</code></pre>
</div>
</div>
<div id="a5a8b009-9314-4172-998c-a556c360699a" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb54"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb54-1"><a href="#cb54-1" aria-hidden="true" tabindex="-1"></a>dnhh <span class="op">=</span> torch.tensor(norm.pdf(hh, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb54-2"><a href="#cb54-2" aria-hidden="true" tabindex="-1"></a>dnhh</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([4.431848411938008e-03, 2.419707245191434e-01, 5.399096651318805e-02,
        9.134720408364595e-12, 1.027977357166892e-18, 0.000000000000000e+00],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="2033cd95-bf8c-43e6-af87-8a93e5a14918" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>norm.cdf(hh, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>array([9.98650102e-01, 1.58655254e-01, 9.77249868e-01, 1.00000000e+00,
       1.12858841e-19, 0.00000000e+00])</code></pre>
</div>
</div>
<div id="bb79c58a-1aeb-440c-ba8c-bee5d7ad70cf" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>yleft <span class="op">=</span> torch.tensor(norm.cdf(hh, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">-</span> z <span class="op">*</span> dnhh <span class="op">+</span> ((z <span class="op">*</span> x <span class="op">-</span> <span class="dv">1</span>) <span class="op">*</span> dnhh <span class="op">*</span> torch.tensor(norm.cdf(<span class="op">-</span>x, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>) )) <span class="op">/</span> torch.tensor(norm.pdf(x, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>yleft</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>tensor([7.535655913337148e-01, 0.000000000000000e+00, 8.016002934071383e-01,
        9.999991126709799e-01, 1.644366208342579e-21,                   nan],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="4db8a9db-3bd4-4b42-b93a-1a538efdcac0" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>yright2 <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> torch.exp(<span class="op">-</span>z<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="dv">2</span>) <span class="op">*</span> (z<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span><span class="op">/</span>w <span class="op">-</span> <span class="dv">1</span>) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>yright2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([1.000000000000000, 0.000000000000000, 1.406005859375000,
        1.088871955871582, 1.000000000000000, 1.000000000000000])</code></pre>
</div>
</div>
<div id="f33f3337-989a-4d7c-b3c0-4ee15d0f0653" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>yright2 <span class="op">/</span> <span class="dv">2</span> <span class="op">-</span> yleft</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([-0.253565591333715,  0.000000000000000, -0.098597363719638,
        -0.455563134735189,  0.500000000000000,                nan],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R코드</li>
</ul>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>cauchy.medzero <span class="ot">&lt;-</span> <span class="cf">function</span>(x, z, w) {</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a><span class="co"># the objective function that has to be zeroed, component by</span></span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a><span class="co"># component, to find the posterior median when the quasi-Cauchy prior</span></span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a><span class="co"># is used.  x is the parameter vector, z is the data vector, w is the</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a><span class="co"># weight x and z may be scalars</span></span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>    hh <span class="ot">&lt;-</span> z <span class="sc">-</span> x</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>    dnhh <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(hh)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>    yleft <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(hh) <span class="sc">-</span> z <span class="sc">*</span> dnhh <span class="sc">+</span> ((z <span class="sc">*</span> x <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">*</span> dnhh <span class="sc">*</span> <span class="fu">pnorm</span>( <span class="sc">-</span> x))<span class="sc">/</span></span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">dnorm</span>(x)</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>    yright2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>( <span class="sc">-</span> z<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> (z<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>w <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(yright2<span class="sc">/</span><span class="dv">2</span> <span class="sc">-</span> yleft)</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><strong>결과</strong></p>
<ul>
<li>Python
<ul>
<li>벡터, 스칼라일때 가능한지 확인</li>
</ul></li>
</ul>
<div id="33c5dc9e-402b-4973-af51-f7e503a389a6" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.cauchy_medzero(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]),torch.tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>]),<span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor([-0.253565591333715,  0.000000000000000, -0.098597363719638,
        -0.455563134735189,  0.500000000000000,                nan],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="b0033926-f009-4149-8701-c52b1a4fe29a" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.cauchy_medzero(torch.tensor(<span class="dv">4</span>),torch.tensor(<span class="dv">5</span>),torch.tensor(<span class="fl">0.5</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor(-0.219442442491987, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">cauchy.medzero</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>),<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>),<span class="fl">0.5</span>)</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.25356559</span>  <span class="fl">0.00000000</span> <span class="sc">-</span><span class="fl">0.09859737</span> <span class="sc">-</span><span class="fl">0.45556313</span>  <span class="fl">0.50000000</span>         <span class="cn">NaN</span></span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">cauchy.medzero</span>(<span class="dv">4</span>,<span class="dv">5</span>,<span class="fl">0.5</span>)</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.2194424</span></span></code></pre></div>
</section>
<section id="cauchy_threshzero" class="level1">
<h1>cauchy_threshzero</h1>
<ul>
<li>cauchy 임계값 찾기 위한 것</li>
<li>아래에서 반환되는 y가 0에 가깝도록 만들어주는 z를 찾는 과정</li>
</ul>
<div id="36371433-adf0-4635-9714-e244292d1e13" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>])</span>
<span id="cb70-2"><a href="#cb70-2" aria-hidden="true" tabindex="-1"></a><span class="co"># z = 0</span></span>
<span id="cb70-3"><a href="#cb70-3" aria-hidden="true" tabindex="-1"></a><span class="co"># w = 0.5</span></span>
<span id="cb70-4"><a href="#cb70-4" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor([<span class="fl">0.5</span>,<span class="fl">0.4</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,<span class="dv">0</span>,<span class="fl">0.1</span>])</span></code></pre></div>
</div>
<div id="4c60ce1b-e559-4fe9-b259-ab75997ba62c" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> (torch.tensor(norm.cdf(z, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">-</span> z <span class="op">*</span> torch.tensor(norm.pdf(z, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">-</span> <span class="fl">0.5</span> <span class="op">-</span> (z<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> torch.exp(<span class="op">-</span>z<span class="op">**</span><span class="dv">2</span> <span class="op">/</span> <span class="dv">2</span>) <span class="op">*</span> (<span class="dv">1</span><span class="op">/</span>w <span class="op">-</span> <span class="dv">1</span>)) <span class="op">/</span> <span class="dv">2</span>)</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>y</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([-0.203891311626260,  0.000000000000000, -0.262296682131538,
         0.285392626219174,               -inf, -2.828762020130332],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R 코드</li>
</ul>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>cauchy.threshzero <span class="ot">&lt;-</span> <span class="cf">function</span>(z, w) {</span>
<span id="cb73-2"><a href="#cb73-2" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb73-3"><a href="#cb73-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The objective function that has to be zeroed to find the Cauchy</span></span>
<span id="cb73-4"><a href="#cb73-4" aria-hidden="true" tabindex="-1"></a><span class="co"># threshold. z is the putative threshold vector, w is the weight w</span></span>
<span id="cb73-5"><a href="#cb73-5" aria-hidden="true" tabindex="-1"></a><span class="co"># can be a vector</span></span>
<span id="cb73-6"><a href="#cb73-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb73-7"><a href="#cb73-7" aria-hidden="true" tabindex="-1"></a>    y <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(z) <span class="sc">-</span> z <span class="sc">*</span> <span class="fu">dnorm</span>(z) <span class="sc">-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span> <span class="sc">-</span></span>
<span id="cb73-8"><a href="#cb73-8" aria-hidden="true" tabindex="-1"></a>         (z<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> <span class="fu">exp</span>( <span class="sc">-</span> z<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>w <span class="sc">-</span> <span class="dv">1</span>))<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb73-9"><a href="#cb73-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(y)</span>
<span id="cb73-10"><a href="#cb73-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p><strong>결과</strong></p>
<ul>
<li>Python</li>
</ul>
<div id="5096b23d-3dac-4a36-968b-ac979e3a9b9c" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.cauchy_threshzero(torch.tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>]),<span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([-0.203891311626260,  0.000000000000000,  0.098597372042885,
         0.435364074104210, -0.402639354725059, -0.402639354725059],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="8760aa06-b8c9-416e-9f54-6ab88be1496e" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.cauchy_threshzero(torch.tensor([<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="op">-</span><span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>]),torch.tensor([<span class="fl">0.5</span>,<span class="fl">0.4</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,<span class="dv">0</span>,<span class="fl">0.1</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([-0.203891311626260,  0.000000000000000, -0.262296682131538,
         0.285392626219174,               -inf, -2.828762020130332],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">cauchy.threshzero</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>),<span class="fl">0.5</span>)</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.20389131</span>  <span class="fl">0.00000000</span>  <span class="fl">0.09859737</span>  <span class="fl">0.43536407</span> <span class="sc">-</span><span class="fl">0.40263935</span> <span class="sc">-</span><span class="fl">0.40263935</span></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="fu">cauchy.threshzero</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">0</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="sc">-</span><span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>), <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.4</span>,<span class="fl">0.3</span>,<span class="fl">0.2</span>,<span class="dv">0</span>,<span class="fl">0.1</span>))</span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.2038913</span>  <span class="fl">0.0000000</span> <span class="sc">-</span><span class="fl">0.2622967</span>  <span class="fl">0.2853926</span>       <span class="sc">-</span><span class="cn">Inf</span> <span class="sc">-</span><span class="fl">2.8287620</span></span></code></pre></div>
</section>
<section id="ebayesthresh" class="level1">
<h1>ebayesthresh</h1>
<div id="c1c750ca-c019-4374-9cd7-e488433cd744" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb79"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.normal(torch.tensor([<span class="dv">0</span>] <span class="op">*</span> <span class="dv">90</span> <span class="op">+</span> [<span class="dv">5</span>] <span class="op">*</span> <span class="dv">10</span>, dtype<span class="op">=</span>torch.float32), torch.ones(<span class="dv">100</span>, dtype<span class="op">=</span>torch.float32))</span>
<span id="cb79-2"><a href="#cb79-2" aria-hidden="true" tabindex="-1"></a><span class="co"># sdev = None</span></span>
<span id="cb79-3"><a href="#cb79-3" aria-hidden="true" tabindex="-1"></a>sdev <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb79-4"><a href="#cb79-4" aria-hidden="true" tabindex="-1"></a>prior<span class="op">=</span><span class="st">"laplace"</span></span>
<span id="cb79-5"><a href="#cb79-5" aria-hidden="true" tabindex="-1"></a>a<span class="op">=</span><span class="fl">0.5</span></span>
<span id="cb79-6"><a href="#cb79-6" aria-hidden="true" tabindex="-1"></a>bayesfac<span class="op">=</span><span class="va">False</span></span>
<span id="cb79-7"><a href="#cb79-7" aria-hidden="true" tabindex="-1"></a>verbose<span class="op">=</span><span class="va">False</span></span>
<span id="cb79-8"><a href="#cb79-8" aria-hidden="true" tabindex="-1"></a>threshrule<span class="op">=</span><span class="st">"median"</span></span>
<span id="cb79-9"><a href="#cb79-9" aria-hidden="true" tabindex="-1"></a>universalthresh<span class="op">=</span><span class="va">True</span></span>
<span id="cb79-10"><a href="#cb79-10" aria-hidden="true" tabindex="-1"></a>stabadjustment<span class="op">=</span><span class="va">None</span></span></code></pre></div>
</div>
<div id="dec7ed08-f20b-46d0-832d-929bddc4c829" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb80-2"><a href="#cb80-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="87436f5e-e0bd-4f19-ae2e-6d8bcde1b4aa" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> sdev <span class="kw">is</span> <span class="va">None</span>: sdev <span class="op">=</span> torch.tensor([<span class="bu">float</span>(<span class="st">'nan'</span>)])</span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>: sdev <span class="op">=</span> torch.tensor([sdev])</span></code></pre></div>
</div>
<div id="3ade65fb-0502-4adb-82cf-e6573c1381f1" class="cell" data-tags="[]" data-execution_count="6">
<div class="sourceCode cell-code" id="cb83"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(sdev) <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> stabadjustment <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Argument stabadjustment is not applicable when variances are homogeneous."</span>)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.isnan(sdev):</span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>        sdev <span class="op">=</span> ebayesthresh_torch.mad(x, center<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    stabadjustment_condition <span class="op">=</span> <span class="va">True</span></span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb83-9"><a href="#cb83-9" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Standard deviation has to be homogeneous for Cauchy prior."</span>)</span>
<span id="cb83-10"><a href="#cb83-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> sdev.numel() <span class="op">!=</span> x.numel():</span>
<span id="cb83-11"><a href="#cb83-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Standard deviation has to be homogeneous or have the same length as observations."</span>)</span>
<span id="cb83-12"><a href="#cb83-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> stabadjustment <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb83-13"><a href="#cb83-13" aria-hidden="true" tabindex="-1"></a>        stabadjustment <span class="op">=</span> <span class="va">False</span></span>
<span id="cb83-14"><a href="#cb83-14" aria-hidden="true" tabindex="-1"></a>    stabadjustment_condition <span class="op">=</span> stabadjustment</span></code></pre></div>
</div>
<div id="42fac8b9-65d2-4fdd-9723-04e481b474fe" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> stabadjustment_condition:</span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a>    sdev <span class="op">=</span> sdev.<span class="bu">float</span>()</span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>    m_sdev <span class="op">=</span> torch.mean(sdev) </span>
<span id="cb84-4"><a href="#cb84-4" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> sdev <span class="op">/</span> m_sdev</span>
<span id="cb84-5"><a href="#cb84-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x <span class="op">/</span> m_sdev</span>
<span id="cb84-6"><a href="#cb84-6" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb84-7"><a href="#cb84-7" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> sdev</span></code></pre></div>
</div>
<div id="ebdb4559-7001-4af4-97ee-a062d2f6e894" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb85"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span> <span class="kw">and</span> a <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb85-2"><a href="#cb85-2" aria-hidden="true" tabindex="-1"></a>    pp <span class="op">=</span> ebayesthresh_torch.wandafromx(x, s, universalthresh)</span>
<span id="cb85-3"><a href="#cb85-3" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> pp[<span class="st">"w"</span>]</span>
<span id="cb85-4"><a href="#cb85-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> pp[<span class="st">"a"</span>]</span>
<span id="cb85-5"><a href="#cb85-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb85-6"><a href="#cb85-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> ebayesthresh_torch.wfromx(x, s, prior, a, universalthresh)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:584: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  s = torch.tensor(s, dtype=torch.float)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
</div>
<div id="b771d6ca-8b27-4096-a55d-39e750aa32cb" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb87"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">!=</span> <span class="st">"m"</span> <span class="kw">or</span> verbose:</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a>    tt <span class="op">=</span> ebayesthresh_torch.tfromw(w, s, prior<span class="op">=</span>prior, bayesfac<span class="op">=</span>bayesfac, a<span class="op">=</span>a)[<span class="dv">0</span>]</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> stabadjustment_condition:</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a>        tcor <span class="op">=</span> tt <span class="op">*</span> m_sdev</span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>        tcor <span class="op">=</span> tt</span></code></pre></div>
</div>
<div id="f89246d9-fae4-4b09-9d21-ddfcffc8c205" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> threshrule <span class="op">==</span> <span class="st">"median"</span>:</span>
<span id="cb88-2"><a href="#cb88-2" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.postmed(x, s, w, prior<span class="op">=</span>prior, a<span class="op">=</span>a)</span>
<span id="cb88-3"><a href="#cb88-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> threshrule <span class="op">==</span> <span class="st">"mean"</span>:</span>
<span id="cb88-4"><a href="#cb88-4" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.postmean(x, s, w, prior<span class="op">=</span>prior, a<span class="op">=</span>a)</span>
<span id="cb88-5"><a href="#cb88-5" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> threshrule <span class="op">==</span> <span class="st">"hard"</span>:</span>
<span id="cb88-6"><a href="#cb88-6" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.threshld(x, tt)</span>
<span id="cb88-7"><a href="#cb88-7" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> threshrule <span class="op">==</span> <span class="st">"soft"</span>:</span>
<span id="cb88-8"><a href="#cb88-8" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.threshld(x, tt, hard<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb88-9"><a href="#cb88-9" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> threshrule <span class="op">==</span> <span class="st">"none"</span>:</span>
<span id="cb88-10"><a href="#cb88-10" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> <span class="va">None</span></span>
<span id="cb88-11"><a href="#cb88-11" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb88-12"><a href="#cb88-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown threshold rule: </span><span class="sc">{</span>threshrule<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
</div>
<div id="9995f6bf-1e89-4391-9951-b6f345cb5bfa" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb89"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([-0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000, -2.355090516079502,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
         0.000000000000000, -0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
         0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.601967078633394, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         5.241351903941335,  5.814674129368262,  5.452610016379445,
         4.281001471635368,  0.000000000000000,  3.760714547874182,
         3.599737415541837,  5.760071891039154,  5.703448301737690,
         3.821304799487197], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="bb7976e6-6a25-4bfd-a03f-2f3ad34d2b88" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb91"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> stabadjustment_condition:</span>
<span id="cb91-2"><a href="#cb91-2" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> muhat <span class="op">*</span> m_sdev</span></code></pre></div>
</div>
<div id="4f829f40-61e9-4190-9611-af03923a2c41" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([-0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000, -2.355090516079502,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
         0.000000000000000, -0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000, -0.000000000000000,
         0.000000000000000,  0.000000000000000,  0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
         0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.000000000000000,  0.000000000000000,
        -0.000000000000000, -0.601967078633394, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000,  0.000000000000000, -0.000000000000000,
         5.241351903941335,  5.814674129368262,  5.452610016379445,
         4.281001471635368,  0.000000000000000,  3.760714547874182,
         3.599737415541837,  5.760071891039154,  5.703448301737690,
         3.821304799487197], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="901491d0-4d0e-4e87-a68d-432dfa56ea54" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb94"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> verbose:</span>
<span id="cb94-2"><a href="#cb94-2" aria-hidden="true" tabindex="-1"></a>    muhat</span>
<span id="cb94-3"><a href="#cb94-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb94-4"><a href="#cb94-4" aria-hidden="true" tabindex="-1"></a>    retlist <span class="op">=</span> {</span>
<span id="cb94-5"><a href="#cb94-5" aria-hidden="true" tabindex="-1"></a>        <span class="st">'muhat'</span>: muhat,</span>
<span id="cb94-6"><a href="#cb94-6" aria-hidden="true" tabindex="-1"></a>        <span class="st">'x'</span>: x,</span>
<span id="cb94-7"><a href="#cb94-7" aria-hidden="true" tabindex="-1"></a>        <span class="st">'threshold.sdevscale'</span>: tt,</span>
<span id="cb94-8"><a href="#cb94-8" aria-hidden="true" tabindex="-1"></a>        <span class="st">'threshold.origscale'</span>: tcor,</span>
<span id="cb94-9"><a href="#cb94-9" aria-hidden="true" tabindex="-1"></a>        <span class="st">'prior'</span>: prior,</span>
<span id="cb94-10"><a href="#cb94-10" aria-hidden="true" tabindex="-1"></a>        <span class="st">'w'</span>: w,</span>
<span id="cb94-11"><a href="#cb94-11" aria-hidden="true" tabindex="-1"></a>        <span class="st">'a'</span>: a,</span>
<span id="cb94-12"><a href="#cb94-12" aria-hidden="true" tabindex="-1"></a>        <span class="st">'bayesfac'</span>: bayesfac,</span>
<span id="cb94-13"><a href="#cb94-13" aria-hidden="true" tabindex="-1"></a>        <span class="st">'sdev'</span>: sdev,</span>
<span id="cb94-14"><a href="#cb94-14" aria-hidden="true" tabindex="-1"></a>        <span class="st">'threshrule'</span>: threshrule</span>
<span id="cb94-15"><a href="#cb94-15" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb94-16"><a href="#cb94-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb94-17"><a href="#cb94-17" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> retlist[<span class="st">'a'</span>]</span>
<span id="cb94-18"><a href="#cb94-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> threshrule <span class="op">==</span> <span class="st">"none"</span>:</span>
<span id="cb94-19"><a href="#cb94-19" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> retlist[<span class="st">'muhat'</span>]</span>
<span id="cb94-20"><a href="#cb94-20" aria-hidden="true" tabindex="-1"></a>    retlist</span></code></pre></div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh <span class="ot">&lt;-</span> <span class="cf">function</span> (x, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>, <span class="at">bayesfac =</span> <span class="cn">FALSE</span>,</span>
<span id="cb95-2"><a href="#cb95-2" aria-hidden="true" tabindex="-1"></a>                          <span class="at">sdev =</span> <span class="cn">NA</span>, <span class="at">verbose =</span> <span class="cn">FALSE</span>, <span class="at">threshrule =</span> <span class="st">"median"</span>,</span>
<span id="cb95-3"><a href="#cb95-3" aria-hidden="true" tabindex="-1"></a>                          <span class="at">universalthresh =</span> <span class="cn">TRUE</span>, stabadjustment) {</span>
<span id="cb95-4"><a href="#cb95-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  </span></span>
<span id="cb95-5"><a href="#cb95-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  Given a vector of data x, find the marginal maximum likelihood</span></span>
<span id="cb95-6"><a href="#cb95-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  estimator of the mixing weight w, and apply an appropriate</span></span>
<span id="cb95-7"><a href="#cb95-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  thresholding rule using this weight.</span></span>
<span id="cb95-8"><a href="#cb95-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb95-9"><a href="#cb95-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  If the prior is laplace and a=NA, then the inverse scale parameter</span></span>
<span id="cb95-10"><a href="#cb95-10" aria-hidden="true" tabindex="-1"></a><span class="co">#  is also found by MML.</span></span>
<span id="cb95-11"><a href="#cb95-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb95-12"><a href="#cb95-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  Standard deviation sdev can be a vector (heterogeneous variance) or</span></span>
<span id="cb95-13"><a href="#cb95-13" aria-hidden="true" tabindex="-1"></a><span class="co">#  a single value (homogeneous variance). If sdev=NA, then it is</span></span>
<span id="cb95-14"><a href="#cb95-14" aria-hidden="true" tabindex="-1"></a><span class="co">#  estimated using the function mad(x). Heterogeneous variance is</span></span>
<span id="cb95-15"><a href="#cb95-15" aria-hidden="true" tabindex="-1"></a><span class="co">#  allowed only for laplace prior currently.</span></span>
<span id="cb95-16"><a href="#cb95-16" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb95-17"><a href="#cb95-17" aria-hidden="true" tabindex="-1"></a><span class="co">#  The thresholding rules allowed are "median", "mean", "hard", "soft"</span></span>
<span id="cb95-18"><a href="#cb95-18" aria-hidden="true" tabindex="-1"></a><span class="co">#  and "none"; if "none" is used, then only the parameters are worked</span></span>
<span id="cb95-19"><a href="#cb95-19" aria-hidden="true" tabindex="-1"></a><span class="co">#  out.</span></span>
<span id="cb95-20"><a href="#cb95-20" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb95-21"><a href="#cb95-21" aria-hidden="true" tabindex="-1"></a><span class="co">#  If hard or soft thresholding is used, the argument "bayesfac"</span></span>
<span id="cb95-22"><a href="#cb95-22" aria-hidden="true" tabindex="-1"></a><span class="co">#  specifies whether to use the bayes factor threshold or the</span></span>
<span id="cb95-23"><a href="#cb95-23" aria-hidden="true" tabindex="-1"></a><span class="co">#  posterior median threshold.</span></span>
<span id="cb95-24"><a href="#cb95-24" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb95-25"><a href="#cb95-25" aria-hidden="true" tabindex="-1"></a><span class="co">#  If universalthresh=TRUE, the thresholds will be upper bounded by</span></span>
<span id="cb95-26"><a href="#cb95-26" aria-hidden="true" tabindex="-1"></a><span class="co">#  universal threshold adjusted by standard deviation; otherwise,</span></span>
<span id="cb95-27"><a href="#cb95-27" aria-hidden="true" tabindex="-1"></a><span class="co">#  weight w will be searched in [0, 1].</span></span>
<span id="cb95-28"><a href="#cb95-28" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb95-29"><a href="#cb95-29" aria-hidden="true" tabindex="-1"></a><span class="co">#  If stabadjustment=TRUE, the observations and standard deviations</span></span>
<span id="cb95-30"><a href="#cb95-30" aria-hidden="true" tabindex="-1"></a><span class="co">#  will be first divided by the mean of all given standard deviations</span></span>
<span id="cb95-31"><a href="#cb95-31" aria-hidden="true" tabindex="-1"></a><span class="co">#  in case of inefficiency due to large value of standard</span></span>
<span id="cb95-32"><a href="#cb95-32" aria-hidden="true" tabindex="-1"></a><span class="co">#  deviation. In the case of homogeneous variance, the standard</span></span>
<span id="cb95-33"><a href="#cb95-33" aria-hidden="true" tabindex="-1"></a><span class="co">#  deviations will be normalized to 1 automatically.</span></span>
<span id="cb95-34"><a href="#cb95-34" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb95-35"><a href="#cb95-35" aria-hidden="true" tabindex="-1"></a><span class="co">#  If verbose=TRUE then the routine returns a list with several</span></span>
<span id="cb95-36"><a href="#cb95-36" aria-hidden="true" tabindex="-1"></a><span class="co">#  arguments, including muhat which is the result of the</span></span>
<span id="cb95-37"><a href="#cb95-37" aria-hidden="true" tabindex="-1"></a><span class="co">#  thresholding. If verbose=FALSE then only muhat is returned.</span></span>
<span id="cb95-38"><a href="#cb95-38" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb95-39"><a href="#cb95-39" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb95-40"><a href="#cb95-40" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Find the standard deviation if necessary and estimate the parameters</span></span>
<span id="cb95-41"><a href="#cb95-41" aria-hidden="true" tabindex="-1"></a>  pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb95-42"><a href="#cb95-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-43"><a href="#cb95-43" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(<span class="fu">length</span>(sdev) <span class="sc">==</span> <span class="dv">1</span>) {</span>
<span id="cb95-44"><a href="#cb95-44" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(<span class="sc">!</span><span class="fu">missing</span>(stabadjustment))</span>
<span id="cb95-45"><a href="#cb95-45" aria-hidden="true" tabindex="-1"></a>        <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Argument stabadjustment is not applicable when"</span>,</span>
<span id="cb95-46"><a href="#cb95-46" aria-hidden="true" tabindex="-1"></a>                   <span class="st">"variances are homogeneous."</span>))</span>
<span id="cb95-47"><a href="#cb95-47" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(<span class="fu">is.na</span>(sdev)) {</span>
<span id="cb95-48"><a href="#cb95-48" aria-hidden="true" tabindex="-1"></a>          sdev <span class="ot">&lt;-</span> <span class="fu">mad</span>(x, <span class="at">center =</span> <span class="dv">0</span>)</span>
<span id="cb95-49"><a href="#cb95-49" aria-hidden="true" tabindex="-1"></a>      }</span>
<span id="cb95-50"><a href="#cb95-50" aria-hidden="true" tabindex="-1"></a>      stabadjustment_condition <span class="ot">=</span> <span class="cn">TRUE</span></span>
<span id="cb95-51"><a href="#cb95-51" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span>{</span>
<span id="cb95-52"><a href="#cb95-52" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb95-53"><a href="#cb95-53" aria-hidden="true" tabindex="-1"></a>      <span class="fu">stop</span>(<span class="st">"Standard deviation has to be homogeneous for Cauchy prior."</span>)</span>
<span id="cb95-54"><a href="#cb95-54" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">length</span>(sdev) <span class="sc">!=</span> <span class="fu">length</span>(x))</span>
<span id="cb95-55"><a href="#cb95-55" aria-hidden="true" tabindex="-1"></a>      <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Standard deviation has to be homogeneous or has the"</span>,</span>
<span id="cb95-56"><a href="#cb95-56" aria-hidden="true" tabindex="-1"></a>                 <span class="st">"same length as observations."</span>))</span>
<span id="cb95-57"><a href="#cb95-57" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">missing</span>(stabadjustment))</span>
<span id="cb95-58"><a href="#cb95-58" aria-hidden="true" tabindex="-1"></a>      stabadjustment <span class="ot">&lt;-</span> <span class="cn">FALSE</span></span>
<span id="cb95-59"><a href="#cb95-59" aria-hidden="true" tabindex="-1"></a>    stabadjustment_condition <span class="ot">=</span> stabadjustment</span>
<span id="cb95-60"><a href="#cb95-60" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb95-61"><a href="#cb95-61" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb95-62"><a href="#cb95-62" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> (stabadjustment_condition) {</span>
<span id="cb95-63"><a href="#cb95-63" aria-hidden="true" tabindex="-1"></a>    m_sdev <span class="ot">&lt;-</span> <span class="fu">mean</span>(sdev)</span>
<span id="cb95-64"><a href="#cb95-64" aria-hidden="true" tabindex="-1"></a>    s <span class="ot">&lt;-</span> sdev<span class="sc">/</span>m_sdev</span>
<span id="cb95-65"><a href="#cb95-65" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x<span class="sc">/</span>m_sdev</span>
<span id="cb95-66"><a href="#cb95-66" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span> { s <span class="ot">&lt;-</span> sdev }</span>
<span id="cb95-67"><a href="#cb95-67" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb95-68"><a href="#cb95-68" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ((pr <span class="sc">==</span> <span class="st">"l"</span>) <span class="sc">&amp;</span> <span class="fu">is.na</span>(a)) {</span>
<span id="cb95-69"><a href="#cb95-69" aria-hidden="true" tabindex="-1"></a>      pp <span class="ot">&lt;-</span> <span class="fu">wandafromx</span>(x, s, universalthresh)</span>
<span id="cb95-70"><a href="#cb95-70" aria-hidden="true" tabindex="-1"></a>          w  <span class="ot">&lt;-</span> pp<span class="sc">$</span>w</span>
<span id="cb95-71"><a href="#cb95-71" aria-hidden="true" tabindex="-1"></a>          a  <span class="ot">&lt;-</span> pp<span class="sc">$</span>a</span>
<span id="cb95-72"><a href="#cb95-72" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb95-73"><a href="#cb95-73" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span></span>
<span id="cb95-74"><a href="#cb95-74" aria-hidden="true" tabindex="-1"></a>          w <span class="ot">&lt;-</span> <span class="fu">wfromx</span>(x, s, <span class="at">prior =</span> prior, <span class="at">a =</span> a, universalthresh)</span>
<span id="cb95-75"><a href="#cb95-75" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">!=</span> <span class="st">"m"</span> <span class="sc">|</span> verbose) {</span>
<span id="cb95-76"><a href="#cb95-76" aria-hidden="true" tabindex="-1"></a>      tt <span class="ot">&lt;-</span> <span class="fu">tfromw</span>(w, s, <span class="at">prior =</span> prior, <span class="at">bayesfac =</span> bayesfac, <span class="at">a =</span> a)</span>
<span id="cb95-77"><a href="#cb95-77" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(stabadjustment_condition) {</span>
<span id="cb95-78"><a href="#cb95-78" aria-hidden="true" tabindex="-1"></a>        tcor <span class="ot">&lt;-</span> tt <span class="sc">*</span> m_sdev</span>
<span id="cb95-79"><a href="#cb95-79" aria-hidden="true" tabindex="-1"></a>          } <span class="cf">else</span> {</span>
<span id="cb95-80"><a href="#cb95-80" aria-hidden="true" tabindex="-1"></a>            tcor <span class="ot">&lt;-</span> tt</span>
<span id="cb95-81"><a href="#cb95-81" aria-hidden="true" tabindex="-1"></a>          }</span>
<span id="cb95-82"><a href="#cb95-82" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb95-83"><a href="#cb95-83" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"median"</span>)</span>
<span id="cb95-84"><a href="#cb95-84" aria-hidden="true" tabindex="-1"></a>        muhat <span class="ot">&lt;-</span> <span class="fu">postmed</span>(x, s, w, <span class="at">prior =</span> prior, <span class="at">a =</span> a)</span>
<span id="cb95-85"><a href="#cb95-85" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"mean"</span>)</span>
<span id="cb95-86"><a href="#cb95-86" aria-hidden="true" tabindex="-1"></a>    muhat <span class="ot">&lt;-</span> <span class="fu">postmean</span>(x, s, w, <span class="at">prior =</span> prior, <span class="at">a =</span> a)</span>
<span id="cb95-87"><a href="#cb95-87" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"hard"</span>)</span>
<span id="cb95-88"><a href="#cb95-88" aria-hidden="true" tabindex="-1"></a>        muhat <span class="ot">&lt;-</span> <span class="fu">threshld</span>(x, tt)</span>
<span id="cb95-89"><a href="#cb95-89" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"soft"</span>)</span>
<span id="cb95-90"><a href="#cb95-90" aria-hidden="true" tabindex="-1"></a>        muhat <span class="ot">&lt;-</span> <span class="fu">threshld</span>(x, tt, <span class="at">hard =</span> <span class="cn">FALSE</span>)</span>
<span id="cb95-91"><a href="#cb95-91" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"none"</span>)</span>
<span id="cb95-92"><a href="#cb95-92" aria-hidden="true" tabindex="-1"></a>                muhat <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb95-93"><a href="#cb95-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb95-94"><a href="#cb95-94" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Now return desired output</span></span>
<span id="cb95-95"><a href="#cb95-95" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(stabadjustment_condition) {</span>
<span id="cb95-96"><a href="#cb95-96" aria-hidden="true" tabindex="-1"></a>      muhat <span class="ot">&lt;-</span> muhat <span class="sc">*</span> m_sdev</span>
<span id="cb95-97"><a href="#cb95-97" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb95-98"><a href="#cb95-98" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="sc">!</span>verbose)</span>
<span id="cb95-99"><a href="#cb95-99" aria-hidden="true" tabindex="-1"></a>            <span class="fu">return</span>(muhat)</span>
<span id="cb95-100"><a href="#cb95-100" aria-hidden="true" tabindex="-1"></a>    retlist <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">muhat =</span> muhat, <span class="at">x =</span> x, <span class="at">threshold.sdevscale =</span> tt, </span>
<span id="cb95-101"><a href="#cb95-101" aria-hidden="true" tabindex="-1"></a>                        <span class="at">threshold.origscale =</span> tcor, <span class="at">prior =</span> prior, <span class="at">w =</span> w,</span>
<span id="cb95-102"><a href="#cb95-102" aria-hidden="true" tabindex="-1"></a>                        <span class="at">a =</span> a, <span class="at">bayesfac =</span> bayesfac, <span class="at">sdev =</span> sdev,</span>
<span id="cb95-103"><a href="#cb95-103" aria-hidden="true" tabindex="-1"></a>                        <span class="at">threshrule =</span> threshrule)</span>
<span id="cb95-104"><a href="#cb95-104" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb95-105"><a href="#cb95-105" aria-hidden="true" tabindex="-1"></a>        retlist <span class="ot">&lt;-</span> retlist[<span class="sc">-</span><span class="dv">7</span>]</span>
<span id="cb95-106"><a href="#cb95-106" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(threshrule <span class="sc">==</span> <span class="st">"none"</span>)</span>
<span id="cb95-107"><a href="#cb95-107" aria-hidden="true" tabindex="-1"></a>        retlist <span class="ot">&lt;-</span> retlist[<span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb95-108"><a href="#cb95-108" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(retlist)</span>
<span id="cb95-109"><a href="#cb95-109" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="dd53fa2b-eeb8-4be6-ad1b-379fbe0c0657" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb96"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.ebayesthresh(x<span class="op">=</span>torch.normal(torch.tensor([<span class="dv">0</span>] <span class="op">*</span> <span class="dv">90</span> <span class="op">+</span> [<span class="dv">5</span>] <span class="op">*</span> <span class="dv">10</span>, dtype<span class="op">=</span>torch.float32), torch.ones(<span class="dv">100</span>, dtype<span class="op">=</span>torch.float32)), sdev <span class="op">=</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  if torch.isnan(torch.tensor(sdev)):</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([-0.000000000000000, -0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, 0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        0.000000000000000, 0.000000000000000, 0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, 0.000000000000000,
        -0.000000000000000, 0.000000000000000, 0.000000000000000,
        0.000000000000000, -0.000000000000000, 0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        0.000000000000000, 0.000000000000000, 0.000000000000000,
        -0.000000000000000, -0.000000000000000, 0.000000000000000,
        0.000000000000000, -0.000000000000000, 0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, -0.000000000000000, 0.000000000000000,
        -0.000000000000000, 0.000000000000000, 0.000000000000000,
        0.000000000000000, 0.000000000000000, 0.000000000000000,
        0.000000000000000, 0.000000000000000, -0.000000000000000,
        -0.000000000000000, 0.000000000000000, -0.000000000000000,
        0.000000000000000, 0.000000000000000, 0.000000000000000,
        0.000000000000000, 0.000000000000000, -0.000000000000000,
        0.000000000000000, -0.000000000000000, -0.000000000000000,
        0.000000000000000, 1.954613398388517, 0.000000000000000,
        -0.000000000000000, -0.000000000000000, -0.000000000000000,
        0.000000000000000, -0.000000000000000, 0.000000000000000,
        0.000000000000000, -0.000000000000000, -0.000000000000000,
        0.000000000000000, 0.732271537889088, -0.000000000000000,
        5.014218914983013, 4.277265850178829, 4.820524749212368,
        3.796867893018724, 3.538953086545616, 4.003283151235995,
        4.853340377507240, 3.414067134079617, 2.554817258538065,
        4.421466422111199], dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb99"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">ebayesthresh</span>(<span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">90</span>), <span class="fu">rep</span>(<span class="dv">5</span>,<span class="dv">10</span>))),</span>
<span id="cb99-2"><a href="#cb99-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>              <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">sdev =</span> <span class="dv">1</span>)</span>
<span id="cb99-3"><a href="#cb99-3" aria-hidden="true" tabindex="-1"></a>  [<span class="dv">1</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span></span>
<span id="cb99-4"><a href="#cb99-4" aria-hidden="true" tabindex="-1"></a> [<span class="dv">15</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span></span>
<span id="cb99-5"><a href="#cb99-5" aria-hidden="true" tabindex="-1"></a> [<span class="dv">29</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span></span>
<span id="cb99-6"><a href="#cb99-6" aria-hidden="true" tabindex="-1"></a> [<span class="dv">43</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span></span>
<span id="cb99-7"><a href="#cb99-7" aria-hidden="true" tabindex="-1"></a> [<span class="dv">57</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span></span>
<span id="cb99-8"><a href="#cb99-8" aria-hidden="true" tabindex="-1"></a> [<span class="dv">71</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span> <span class="sc">-</span><span class="fl">0.4480064</span></span>
<span id="cb99-9"><a href="#cb99-9" aria-hidden="true" tabindex="-1"></a> [<span class="dv">85</span>]  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">0.0000000</span>  <span class="fl">5.1534865</span>  <span class="fl">6.2732386</span>  <span class="fl">4.4612851</span>  <span class="fl">5.9931848</span>  <span class="fl">4.5828731</span>  <span class="fl">4.6154038</span>  <span class="fl">4.8247775</span>  <span class="fl">3.6219544</span></span>
<span id="cb99-10"><a href="#cb99-10" aria-hidden="true" tabindex="-1"></a> [<span class="dv">99</span>]  <span class="fl">4.4480080</span>  <span class="fl">5.4084453</span></span></code></pre></div>
</section>
<section id="isotone" class="level1">
<h1>isotone</h1>
<blockquote class="blockquote">
<p>Isotonic Regression은 입력 변수에 따른 출력 변수의 단조 증가(monotonic increasing) 또는 감소(monotonic decreasing) 패턴을 찾는 방법</p>
</blockquote>
<div id="8ef6ca18-5787-45bd-8b12-7e8102dd08e9" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb100"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> ebayesthresh_torch.beta_cauchy(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>]))</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.ones(<span class="bu">len</span>(beta))</span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>aa <span class="op">=</span> w <span class="op">+</span> <span class="dv">1</span><span class="op">/</span>beta</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> w <span class="op">+</span> aa</span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>wt <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>aa<span class="op">**</span><span class="dv">2</span></span>
<span id="cb100-6"><a href="#cb100-6" aria-hidden="true" tabindex="-1"></a>increasing <span class="op">=</span> <span class="va">False</span></span></code></pre></div>
</div>
<div id="7743bfc7-0119-4965-864b-90ab2429cdd7" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> wt <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb101-2"><a href="#cb101-2" aria-hidden="true" tabindex="-1"></a>        wt <span class="op">=</span> torch.ones_like(x)</span></code></pre></div>
</div>
<div id="c963e95a-799e-49a8-b454-dfb0a57ea5f8" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb102"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>nn <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb102-2"><a href="#cb102-2" aria-hidden="true" tabindex="-1"></a>nn</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>4</code></pre>
</div>
</div>
<div id="49eb804c-2911-4703-8c2c-ab63f7434ac8" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb104"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb104-1"><a href="#cb104-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.beta_cauchy(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([  0.597264024732663,  -0.351278729299872,  -0.500000000000000,
        185.247374190108047], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="69ea0bef-29a0-4e7d-aca4-f5b551488271" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb106"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> nn <span class="op">==</span> <span class="dv">1</span>:</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> x</span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> increasing:</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a>    x <span class="op">=</span> <span class="op">-</span>x</span></code></pre></div>
</div>
<div id="ab575be4-9a95-4277-82b7-c719a9c81d79" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a>ip <span class="op">=</span> torch.arange(nn)</span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>ip</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([0, 1, 2, 3])</code></pre>
</div>
</div>
<div id="86c27adc-045f-4fb9-8617-a653bdab4cf9" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a>dx <span class="op">=</span> torch.diff(x)</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>dx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([ 4.521043661450835, -0.846742249361595, -2.005398187177399],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="081129ac-e09b-4fb4-b5ec-30b7980ae6fe" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>nx <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb111-2"><a href="#cb111-2" aria-hidden="true" tabindex="-1"></a>nx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>4</code></pre>
</div>
</div>
<div id="277539d1-d067-4e74-a725-e72bbe1f04cd" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="cf">while</span> (nx <span class="op">&gt;</span> <span class="dv">1</span>) <span class="kw">and</span> (torch.<span class="bu">min</span>(dx) <span class="op">&lt;</span> <span class="dv">0</span>):</span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a>        jmax <span class="op">=</span> torch.where((torch.cat([dx <span class="op">&lt;=</span> <span class="dv">0</span>, torch.tensor([<span class="va">False</span>])]) <span class="op">&amp;</span> torch.cat([torch.tensor([<span class="va">True</span>]), dx <span class="op">&gt;</span> <span class="dv">0</span>])))[<span class="dv">0</span>]</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>        jmin <span class="op">=</span> torch.where((torch.cat([dx <span class="op">&gt;</span> <span class="dv">0</span>, torch.tensor([<span class="va">True</span>])]) <span class="op">&amp;</span> torch.cat([torch.tensor([<span class="va">False</span>]), dx <span class="op">&lt;=</span> <span class="dv">0</span>])))[<span class="dv">0</span>]</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> jb <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(jmax)):</span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>            ind <span class="op">=</span> torch.arange(jmax[jb], jmin[jb] <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>            wtn <span class="op">=</span> torch.<span class="bu">sum</span>(wt[ind])</span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>            x[jmax[jb]] <span class="op">=</span> torch.<span class="bu">sum</span>(wt[ind] <span class="op">*</span> x[ind]) <span class="op">/</span> wtn</span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>            wt[jmax[jb]] <span class="op">=</span> wtn</span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>            x[jmax[jb] <span class="op">+</span> <span class="dv">1</span>:jmin[jb] <span class="op">+</span> <span class="dv">1</span>] <span class="op">=</span> torch.nan</span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>        ind <span class="op">=</span> <span class="op">~</span>torch.isnan(x)</span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>        x <span class="op">=</span> x[ind]</span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>        wt <span class="op">=</span> wt[ind]</span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>        ip <span class="op">=</span> ip[ind]</span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>        dx <span class="op">=</span> torch.diff(x)</span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>        nx <span class="op">=</span> <span class="bu">len</span>(x)</span></code></pre></div>
</div>
<div id="184f9682-5cdd-4dcb-8330-fec4da3294fc" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a>jj <span class="op">=</span> torch.zeros(nn, dtype<span class="op">=</span>torch.int32)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a>jj</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([0, 0, 0, 0], dtype=torch.int32)</code></pre>
</div>
</div>
<div id="3da8e458-724a-4efc-b615-fcf19160dd10" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb116"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb116-1"><a href="#cb116-1" aria-hidden="true" tabindex="-1"></a>jj[ip] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb116-2"><a href="#cb116-2" aria-hidden="true" tabindex="-1"></a>jj</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor([1, 1, 0, 0], dtype=torch.int32)</code></pre>
</div>
</div>
<div id="85b92589-03dc-4a1a-9f9f-19bf75ee36fc" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> x[torch.cumsum(jj, dim<span class="op">=</span><span class="dv">0</span>) <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="61">
<pre><code>tensor([-3.674301412089240, -0.760411047043364, -0.760411047043364,
        -0.760411047043364], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="0d602022-3f52-4bbd-9213-b29b468f746a" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb120"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb120-1"><a href="#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> increasing:</span>
<span id="cb120-2"><a href="#cb120-2" aria-hidden="true" tabindex="-1"></a>        z <span class="op">=</span> <span class="op">-</span>z</span></code></pre></div>
</div>
<div id="56e2ae5c-c1b7-4ae0-82dc-1b2fac51c035" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb121"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb121-1"><a href="#cb121-1" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor([3.674301412089240, 0.760411047043364, 0.760411047043364,
        0.760411047043364], dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="#cb123-1" aria-hidden="true" tabindex="-1"></a>isotone <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">wt =</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">length</span>(x)), <span class="at">increasing =</span> <span class="cn">FALSE</span>) {</span>
<span id="cb123-2"><a href="#cb123-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-3"><a href="#cb123-3" aria-hidden="true" tabindex="-1"></a><span class="co">#   find the weighted least squares isotone fit to the </span></span>
<span id="cb123-4"><a href="#cb123-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   sequence x, the weights given by the sequence wt</span></span>
<span id="cb123-5"><a href="#cb123-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-6"><a href="#cb123-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   if increasing == TRUE the curve is set to be increasing, </span></span>
<span id="cb123-7"><a href="#cb123-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   otherwise to be decreasing</span></span>
<span id="cb123-8"><a href="#cb123-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-9"><a href="#cb123-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   the vector ip contains the indices on the original scale of the</span></span>
<span id="cb123-10"><a href="#cb123-10" aria-hidden="true" tabindex="-1"></a><span class="co">#   breaks in the regression at each stage</span></span>
<span id="cb123-11"><a href="#cb123-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-12"><a href="#cb123-12" aria-hidden="true" tabindex="-1"></a>    nn <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb123-13"><a href="#cb123-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(nn <span class="sc">==</span> <span class="dv">1</span>)</span>
<span id="cb123-14"><a href="#cb123-14" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(x)</span>
<span id="cb123-15"><a href="#cb123-15" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="sc">!</span>increasing)</span>
<span id="cb123-16"><a href="#cb123-16" aria-hidden="true" tabindex="-1"></a>        x <span class="ot">&lt;-</span>  <span class="sc">-</span> x</span>
<span id="cb123-17"><a href="#cb123-17" aria-hidden="true" tabindex="-1"></a>    ip <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span>nn)</span>
<span id="cb123-18"><a href="#cb123-18" aria-hidden="true" tabindex="-1"></a>    dx <span class="ot">&lt;-</span> <span class="fu">diff</span>(x)</span>
<span id="cb123-19"><a href="#cb123-19" aria-hidden="true" tabindex="-1"></a>    nx <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb123-20"><a href="#cb123-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">while</span>((nx <span class="sc">&gt;</span> <span class="dv">1</span>) <span class="sc">&amp;&amp;</span> (<span class="fu">min</span>(dx) <span class="sc">&lt;</span> <span class="dv">0</span>)) {</span>
<span id="cb123-21"><a href="#cb123-21" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-22"><a href="#cb123-22" aria-hidden="true" tabindex="-1"></a><span class="co">#  do single pool-adjacent-violators step</span></span>
<span id="cb123-23"><a href="#cb123-23" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-24"><a href="#cb123-24" aria-hidden="true" tabindex="-1"></a><span class="co">#  find all local minima and maxima</span></span>
<span id="cb123-25"><a href="#cb123-25" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-26"><a href="#cb123-26" aria-hidden="true" tabindex="-1"></a>        jmax <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span>nx)[<span class="fu">c</span>(dx <span class="sc">&lt;=</span> <span class="dv">0</span>, <span class="cn">FALSE</span>) <span class="sc">&amp;</span> <span class="fu">c</span>(<span class="cn">TRUE</span>, dx <span class="sc">&gt;</span> <span class="dv">0</span>)]</span>
<span id="cb123-27"><a href="#cb123-27" aria-hidden="true" tabindex="-1"></a>        jmin <span class="ot">&lt;-</span> (<span class="dv">1</span><span class="sc">:</span>nx)[<span class="fu">c</span>(dx <span class="sc">&gt;</span> <span class="dv">0</span>, <span class="cn">TRUE</span>) <span class="sc">&amp;</span> <span class="fu">c</span>(<span class="cn">FALSE</span>, dx <span class="sc">&lt;=</span> <span class="dv">0</span>)]</span>
<span id="cb123-28"><a href="#cb123-28" aria-hidden="true" tabindex="-1"></a><span class="co">#  do pav step for each pair of maxima and minima</span></span>
<span id="cb123-29"><a href="#cb123-29" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-30"><a href="#cb123-30" aria-hidden="true" tabindex="-1"></a><span class="co">#  add up weights within subsequence that is pooled</span></span>
<span id="cb123-31"><a href="#cb123-31" aria-hidden="true" tabindex="-1"></a><span class="co">#  set first element of subsequence to the weighted average</span></span>
<span id="cb123-32"><a href="#cb123-32" aria-hidden="true" tabindex="-1"></a><span class="co">#  the first weight to the sum of the weights within the subsequence</span></span>
<span id="cb123-33"><a href="#cb123-33" aria-hidden="true" tabindex="-1"></a><span class="co">#    and remainder of the subsequence to NA</span></span>
<span id="cb123-34"><a href="#cb123-34" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-35"><a href="#cb123-35" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span>(jb <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(jmax))) {</span>
<span id="cb123-36"><a href="#cb123-36" aria-hidden="true" tabindex="-1"></a>            ind <span class="ot">&lt;-</span> (jmax[jb]<span class="sc">:</span>jmin[jb])</span>
<span id="cb123-37"><a href="#cb123-37" aria-hidden="true" tabindex="-1"></a>            wtn <span class="ot">&lt;-</span> <span class="fu">sum</span>(wt[ind])</span>
<span id="cb123-38"><a href="#cb123-38" aria-hidden="true" tabindex="-1"></a>            x[jmax[jb]] <span class="ot">&lt;-</span> <span class="fu">sum</span>(wt[ind] <span class="sc">*</span> x[ind])<span class="sc">/</span>wtn</span>
<span id="cb123-39"><a href="#cb123-39" aria-hidden="true" tabindex="-1"></a>            wt[jmax[jb]] <span class="ot">&lt;-</span> wtn</span>
<span id="cb123-40"><a href="#cb123-40" aria-hidden="true" tabindex="-1"></a>            x[(jmax[jb] <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>jmin[jb]] <span class="ot">&lt;-</span> <span class="cn">NA</span></span>
<span id="cb123-41"><a href="#cb123-41" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb123-42"><a href="#cb123-42" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-43"><a href="#cb123-43" aria-hidden="true" tabindex="-1"></a><span class="co">#  clean up within iteration, eliminating the parts of sequences that</span></span>
<span id="cb123-44"><a href="#cb123-44" aria-hidden="true" tabindex="-1"></a><span class="co">#  were set to NA</span></span>
<span id="cb123-45"><a href="#cb123-45" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-46"><a href="#cb123-46" aria-hidden="true" tabindex="-1"></a>        ind <span class="ot">&lt;-</span> <span class="sc">!</span><span class="fu">is.na</span>(x)</span>
<span id="cb123-47"><a href="#cb123-47" aria-hidden="true" tabindex="-1"></a>        x <span class="ot">&lt;-</span> x[ind]</span>
<span id="cb123-48"><a href="#cb123-48" aria-hidden="true" tabindex="-1"></a>        wt <span class="ot">&lt;-</span> wt[ind]</span>
<span id="cb123-49"><a href="#cb123-49" aria-hidden="true" tabindex="-1"></a>        ip <span class="ot">&lt;-</span> ip[ind]</span>
<span id="cb123-50"><a href="#cb123-50" aria-hidden="true" tabindex="-1"></a>        dx <span class="ot">&lt;-</span> <span class="fu">diff</span>(x)</span>
<span id="cb123-51"><a href="#cb123-51" aria-hidden="true" tabindex="-1"></a>        nx <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb123-52"><a href="#cb123-52" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb123-53"><a href="#cb123-53" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb123-54"><a href="#cb123-54" aria-hidden="true" tabindex="-1"></a><span class="co">#  final cleanup: reconstruct z at all points by repeating the pooled</span></span>
<span id="cb123-55"><a href="#cb123-55" aria-hidden="true" tabindex="-1"></a><span class="co">#    values the appropriate number of times</span></span>
<span id="cb123-56"><a href="#cb123-56" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb123-57"><a href="#cb123-57" aria-hidden="true" tabindex="-1"></a>    jj <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, nn)</span>
<span id="cb123-58"><a href="#cb123-58" aria-hidden="true" tabindex="-1"></a>    jj[ip] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb123-59"><a href="#cb123-59" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> x[<span class="fu">cumsum</span>(jj)]</span>
<span id="cb123-60"><a href="#cb123-60" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="sc">!</span>increasing)</span>
<span id="cb123-61"><a href="#cb123-61" aria-hidden="true" tabindex="-1"></a>        z <span class="ot">&lt;-</span>  <span class="sc">-</span> z</span>
<span id="cb123-62"><a href="#cb123-62" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(z)</span>
<span id="cb123-63"><a href="#cb123-63" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="50d3f97e-3039-4325-98ab-205c5eacc612" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb124"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb124-1"><a href="#cb124-1" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> ebayesthresh_torch.beta_cauchy(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>]))</span>
<span id="cb124-2"><a href="#cb124-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.ones(<span class="bu">len</span>(beta))</span>
<span id="cb124-3"><a href="#cb124-3" aria-hidden="true" tabindex="-1"></a>aa <span class="op">=</span> w <span class="op">+</span> <span class="dv">1</span><span class="op">/</span>beta</span>
<span id="cb124-4"><a href="#cb124-4" aria-hidden="true" tabindex="-1"></a>ps <span class="op">=</span> w <span class="op">+</span> aa</span>
<span id="cb124-5"><a href="#cb124-5" aria-hidden="true" tabindex="-1"></a>ww <span class="op">=</span> <span class="dv">1</span><span class="op">/</span>aa<span class="op">**</span><span class="dv">2</span></span>
<span id="cb124-6"><a href="#cb124-6" aria-hidden="true" tabindex="-1"></a>wnew <span class="op">=</span> ebayesthresh_torch.isotone(ps, ww, increasing <span class="op">=</span> <span class="va">False</span>)</span>
<span id="cb124-7"><a href="#cb124-7" aria-hidden="true" tabindex="-1"></a>wnew</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>[3.67430141208924, 0.760411047043364, 0.760411047043364, 0.760411047043364]</code></pre>
</div>
</div>
<p>R</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="#cb126-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> beta <span class="ot">&lt;-</span> <span class="fu">beta.cauchy</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>))</span>
<span id="cb126-2"><a href="#cb126-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> w <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">1</span>, <span class="fu">length</span>(x))</span>
<span id="cb126-3"><a href="#cb126-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> aa <span class="ot">=</span> w <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>beta</span>
<span id="cb126-4"><a href="#cb126-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ps <span class="ot">=</span> w <span class="sc">+</span> aa</span>
<span id="cb126-5"><a href="#cb126-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ww <span class="ot">=</span> <span class="dv">1</span><span class="sc">/</span>aa<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb126-6"><a href="#cb126-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> wnew <span class="ot">=</span> <span class="fu">isotone</span>(ps, ww, <span class="at">increasing =</span> <span class="cn">FALSE</span>)</span>
<span id="cb126-7"><a href="#cb126-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> wnew</span>
<span id="cb126-8"><a href="#cb126-8" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">3.674301</span> <span class="fl">0.760411</span> <span class="fl">0.760411</span> <span class="fl">0.760411</span></span></code></pre></div>
</section>
<section id="laplace_threshzero" class="level1">
<h1>laplace_threshzero</h1>
<div id="ffeb41db-c3fd-44d7-926d-da05b1cde637" class="cell" data-execution_count="65">
<div class="sourceCode cell-code" id="cb127"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb127-1"><a href="#cb127-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>])</span>
<span id="cb127-2"><a href="#cb127-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb127-3"><a href="#cb127-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb127-4"><a href="#cb127-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="526d78ea-bb08-4464-a2e8-403f601f30ab" class="cell" data-execution_count="66">
<div class="sourceCode cell-code" id="cb128"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb128-1"><a href="#cb128-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="bu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb128-2"><a href="#cb128-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="66">
<pre><code>0.5</code></pre>
</div>
</div>
<div id="ff18e35c-d7e9-4616-951f-9fddcc411160" class="cell" data-execution_count="67">
<div class="sourceCode cell-code" id="cb130"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb130-1"><a href="#cb130-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> x <span class="op">/</span> s <span class="op">-</span> s <span class="op">*</span> a</span>
<span id="cb130-2"><a href="#cb130-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="67">
<pre><code>tensor([-2.500000000000000,  0.500000000000000, -0.500000000000000,
        -4.500000000000000,  7.500000000000000, 49.500000000000000])</code></pre>
</div>
</div>
<div id="9f271ff4-7b00-4919-8fbf-874166f7b669" class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb132"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb132-1"><a href="#cb132-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> torch.tensor(norm.cdf(xma, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">-</span> (<span class="dv">1</span> <span class="op">/</span> a) <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> s <span class="op">*</span> torch.tensor(norm.pdf(xma, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))) <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> w <span class="op">+</span> ebayesthresh_torch.beta_laplace(x, s, a))</span>
<span id="cb132-2"><a href="#cb132-2" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="68">
<pre><code>tensor([-0.095098724189572, -0.449199823501264, -0.704130653528599,
        -0.009185957714915,  0.499999999999483,  1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="#cb134-1" aria-hidden="true" tabindex="-1"></a>laplace.threshzero <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb134-2"><a href="#cb134-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb134-3"><a href="#cb134-3" aria-hidden="true" tabindex="-1"></a><span class="co"># The function that has to be zeroed to find the threshold with the</span></span>
<span id="cb134-4"><a href="#cb134-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Laplace prior.  Only allow a &lt; 20 for input value.</span></span>
<span id="cb134-5"><a href="#cb134-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb134-6"><a href="#cb134-6" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb134-7"><a href="#cb134-7" aria-hidden="true" tabindex="-1"></a>  xma <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">-</span> s<span class="sc">*</span>a</span>
<span id="cb134-8"><a href="#cb134-8" aria-hidden="true" tabindex="-1"></a>  z <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(xma) <span class="sc">-</span> <span class="dv">1</span><span class="sc">/</span>a <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>s<span class="sc">*</span><span class="fu">dnorm</span>(xma)) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>w <span class="sc">+</span> <span class="fu">beta.laplace</span>(x, s, a))</span>
<span id="cb134-9"><a href="#cb134-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">return</span>(z)</span>
<span id="cb134-10"><a href="#cb134-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="8d2636a6-4869-4b72-960b-cb6ade162743" class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb135"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb135-1"><a href="#cb135-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.laplace_threshzero(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]), s <span class="op">=</span> <span class="dv">1</span>, w <span class="op">=</span> <span class="fl">0.5</span>, a <span class="op">=</span> <span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>tensor([-0.095098724189572, -0.449199823501264, -0.704130653528599,
        -0.009185957714915,  0.499999999999483,  1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="fefaea0b-02df-4fe4-9d43-4ebb991938d0" class="cell" data-execution_count="70">
<div class="sourceCode cell-code" id="cb137"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb137-1"><a href="#cb137-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.laplace_threshzero(torch.tensor(<span class="op">-</span><span class="dv">5</span>), s <span class="op">=</span> <span class="dv">1</span>, w <span class="op">=</span> <span class="fl">0.5</span>, a <span class="op">=</span> <span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="70">
<pre><code>tensor(-0.003369167953292, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="#cb139-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">laplace.threshzero</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>), <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>)</span>
<span id="cb139-2"><a href="#cb139-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.095098724</span> <span class="sc">-</span><span class="fl">0.449199824</span> <span class="sc">-</span><span class="fl">0.704130654</span> <span class="sc">-</span><span class="fl">0.009185958</span>  <span class="fl">0.500000000</span>  <span class="fl">1.000000000</span></span>
<span id="cb139-3"><a href="#cb139-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">laplace.threshzero</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>)</span>
<span id="cb139-4"><a href="#cb139-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.003369168</span></span></code></pre></div>
</section>
<section id="negloglik_laplace" class="level1">
<h1>negloglik_laplace</h1>
<blockquote class="blockquote">
<p>Marginal negative log likelihood function for laplace prior.</p>
</blockquote>
<ul>
<li>라플라스 프라이어에 대한 한계음의로그우도함수 계산</li>
</ul>
<div id="3388f296-4220-41f8-ac14-38c7e1639ed9" class="cell" data-execution_count="71">
<div class="sourceCode cell-code" id="cb140"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb140-1"><a href="#cb140-1" aria-hidden="true" tabindex="-1"></a>xpar <span class="op">=</span> torch.tensor([<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.3</span>])</span>
<span id="cb140-2"><a href="#cb140-2" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>])</span>
<span id="cb140-3"><a href="#cb140-3" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> torch.tensor([<span class="dv">1</span>])</span>
<span id="cb140-4"><a href="#cb140-4" aria-hidden="true" tabindex="-1"></a>tlo <span class="op">=</span> torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(<span class="bu">len</span>([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>])).<span class="bu">float</span>())) <span class="op">*</span> <span class="dv">1</span></span>
<span id="cb140-5"><a href="#cb140-5" aria-hidden="true" tabindex="-1"></a>thi <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>,<span class="fl">0.0</span>,<span class="fl">0.0</span>])</span></code></pre></div>
</div>
<div id="692068d6-1f41-4e88-b044-a299ea64c0db" class="cell" data-execution_count="72">
<div class="sourceCode cell-code" id="cb141"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb141-1"><a href="#cb141-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> xpar[<span class="dv">1</span>]</span>
<span id="cb141-2"><a href="#cb141-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="72">
<pre><code>tensor(0.600000023841858)</code></pre>
</div>
</div>
<div id="9a273e60-cedf-413b-90bc-19b3881052b4" class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb143"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb143-1"><a href="#cb143-1" aria-hidden="true" tabindex="-1"></a>wlo <span class="op">=</span> ebayesthresh_torch.wfromt(thi, ss, a<span class="op">=</span>a)</span>
<span id="cb143-2"><a href="#cb143-2" aria-hidden="true" tabindex="-1"></a>wlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>tensor([1., 1., 1.], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="d61d4985-4bb7-4639-9e4c-9f310233a3f8" class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb145"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb145-1"><a href="#cb145-1" aria-hidden="true" tabindex="-1"></a>whi <span class="op">=</span> ebayesthresh_torch.wfromt(tlo, ss, a<span class="op">=</span>a)</span>
<span id="cb145-2"><a href="#cb145-2" aria-hidden="true" tabindex="-1"></a>whi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="74">
<pre><code>tensor([0.445282361582141], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="43489205-88aa-4de5-9ff2-2b147d852227" class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb147"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb147-1"><a href="#cb147-1" aria-hidden="true" tabindex="-1"></a>wlo <span class="op">=</span> torch.<span class="bu">max</span>(wlo)</span>
<span id="cb147-2"><a href="#cb147-2" aria-hidden="true" tabindex="-1"></a>wlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>tensor(1., dtype=torch.float64)</code></pre>
</div>
</div>
<div id="af55411c-cb15-45c5-b82a-f94a0c4ee7b5" class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb149"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb149-1"><a href="#cb149-1" aria-hidden="true" tabindex="-1"></a>whi <span class="op">=</span> torch.<span class="bu">min</span>(whi)</span>
<span id="cb149-2"><a href="#cb149-2" aria-hidden="true" tabindex="-1"></a>whi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>tensor(0.445282361582141, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="eb553ee4-84b8-4d66-b320-058ff0d8f33c" class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb151"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb151-1"><a href="#cb151-1" aria-hidden="true" tabindex="-1"></a>loglik <span class="op">=</span> torch.<span class="bu">sum</span>(torch.log(<span class="dv">1</span> <span class="op">+</span> (xpar[<span class="dv">0</span>] <span class="op">*</span> (whi <span class="op">-</span> wlo) <span class="op">+</span> wlo) <span class="op">*</span></span>
<span id="cb151-2"><a href="#cb151-2" aria-hidden="true" tabindex="-1"></a>                           ebayesthresh_torch.beta_laplace(xx, ss, a)))</span>
<span id="cb151-3"><a href="#cb151-3" aria-hidden="true" tabindex="-1"></a><span class="op">-</span>loglik</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>tensor(-16.797274811699509, dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="#cb153-1" aria-hidden="true" tabindex="-1"></a>negloglik.laplace <span class="ot">&lt;-</span> <span class="cf">function</span>(xpar, xx, ss, tlo, thi) {</span>
<span id="cb153-2"><a href="#cb153-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb153-3"><a href="#cb153-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Marginal negative log likelihood function for laplace prior. </span></span>
<span id="cb153-4"><a href="#cb153-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   Constraints for thresholds need to be passed externally.</span></span>
<span id="cb153-5"><a href="#cb153-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  </span></span>
<span id="cb153-6"><a href="#cb153-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  xx   :data</span></span>
<span id="cb153-7"><a href="#cb153-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  xpar :vector of two parameters:</span></span>
<span id="cb153-8"><a href="#cb153-8" aria-hidden="true" tabindex="-1"></a><span class="co">#      xpar[1] : a value between [0, 1] which will be adjusted to range of w </span></span>
<span id="cb153-9"><a href="#cb153-9" aria-hidden="true" tabindex="-1"></a><span class="co">#      xpar[2] : inverse scale (rate) parameter ("a")</span></span>
<span id="cb153-10"><a href="#cb153-10" aria-hidden="true" tabindex="-1"></a><span class="co">#  ss   :vector of standard deviations</span></span>
<span id="cb153-11"><a href="#cb153-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  tlo  :lower bound of thresholds</span></span>
<span id="cb153-12"><a href="#cb153-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  thi  :upper bound of thresholds</span></span>
<span id="cb153-13"><a href="#cb153-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb153-14"><a href="#cb153-14" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">&lt;-</span> xpar[<span class="dv">2</span>]</span>
<span id="cb153-15"><a href="#cb153-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb153-16"><a href="#cb153-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Calculate the range of w given a, using negative monotonicity</span></span>
<span id="cb153-17"><a href="#cb153-17" aria-hidden="true" tabindex="-1"></a>        <span class="co"># between w and t</span></span>
<span id="cb153-18"><a href="#cb153-18" aria-hidden="true" tabindex="-1"></a>    wlo <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(thi, ss, <span class="at">a =</span> a)</span>
<span id="cb153-19"><a href="#cb153-19" aria-hidden="true" tabindex="-1"></a>    whi <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(tlo, ss, <span class="at">a =</span> a)</span>
<span id="cb153-20"><a href="#cb153-20" aria-hidden="true" tabindex="-1"></a>    wlo <span class="ot">&lt;-</span> <span class="fu">max</span>(wlo)</span>
<span id="cb153-21"><a href="#cb153-21" aria-hidden="true" tabindex="-1"></a>    whi <span class="ot">&lt;-</span> <span class="fu">min</span>(whi)</span>
<span id="cb153-22"><a href="#cb153-22" aria-hidden="true" tabindex="-1"></a>    loglik <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> (xpar[<span class="dv">1</span>] <span class="sc">*</span> (whi <span class="sc">-</span> wlo) <span class="sc">+</span> wlo) <span class="sc">*</span></span>
<span id="cb153-23"><a href="#cb153-23" aria-hidden="true" tabindex="-1"></a>                          <span class="fu">beta.laplace</span>(xx, ss, a)))</span>
<span id="cb153-24"><a href="#cb153-24" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="sc">-</span>loglik)</span>
<span id="cb153-25"><a href="#cb153-25" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="fa6f36cd-c343-4a35-8e77-bdb85fd10f44" class="cell" data-execution_count="78">
<div class="sourceCode cell-code" id="cb154"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb154-1"><a href="#cb154-1" aria-hidden="true" tabindex="-1"></a>xpar <span class="op">=</span> torch.tensor([<span class="fl">0.5</span>,<span class="fl">0.6</span>,<span class="fl">0.3</span>])</span>
<span id="cb154-2"><a href="#cb154-2" aria-hidden="true" tabindex="-1"></a>xx <span class="op">=</span> torch.tensor([<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>])</span>
<span id="cb154-3"><a href="#cb154-3" aria-hidden="true" tabindex="-1"></a>ss <span class="op">=</span> torch.tensor([<span class="dv">1</span>])</span>
<span id="cb154-4"><a href="#cb154-4" aria-hidden="true" tabindex="-1"></a>tlo <span class="op">=</span> torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(<span class="bu">len</span>([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>])).<span class="bu">float</span>())) <span class="op">*</span> <span class="dv">1</span></span>
<span id="cb154-5"><a href="#cb154-5" aria-hidden="true" tabindex="-1"></a>thi <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>,<span class="fl">0.0</span>,<span class="fl">0.0</span>])</span></code></pre></div>
</div>
<div id="9afd8514-1c47-4e5d-b70f-a94490fd04a2" class="cell" data-execution_count="79">
<div class="sourceCode cell-code" id="cb155"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb155-1"><a href="#cb155-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.negloglik_laplace(xpar, xx, ss, tlo, thi)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="79">
<pre><code>tensor(-16.797274811699509, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="#cb157-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xpar <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.6</span>, <span class="fl">0.3</span>)</span>
<span id="cb157-2"><a href="#cb157-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> xx <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)</span>
<span id="cb157-3"><a href="#cb157-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> ss <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>)</span>
<span id="cb157-4"><a href="#cb157-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tlo <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">length</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">5</span>)))) <span class="sc">*</span> <span class="dv">1</span></span>
<span id="cb157-5"><a href="#cb157-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> thi <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>)</span>
<span id="cb157-6"><a href="#cb157-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">negloglik.laplace</span>(xpar, xx, ss, tlo, thi)</span>
<span id="cb157-7"><a href="#cb157-7" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">16.79727</span></span></code></pre></div>
</section>
<section id="postmean" class="level1">
<h1>postmean</h1>
<blockquote class="blockquote">
<p>Given a single value or a vector of data and sampling standard deviations (sd equals 1 for Cauchy prior), find the corresponding posterior mean estimate(s) of the underlying signal value(s).</p>
</blockquote>
<ul>
<li>적절한 사후 평균 찾기</li>
</ul>
<div id="4db78d4f-ee39-42a2-85aa-8b3fd298169d" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb158"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb158-1"><a href="#cb158-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>])</span>
<span id="cb158-2"><a href="#cb158-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>])</span>
<span id="cb158-3"><a href="#cb158-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor([<span class="fl">0.5</span>])</span>
<span id="cb158-4"><a href="#cb158-4" aria-hidden="true" tabindex="-1"></a><span class="co"># prior = "cauchy"</span></span>
<span id="cb158-5"><a href="#cb158-5" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">"laplace"</span></span>
<span id="cb158-6"><a href="#cb158-6" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="47751138-2876-4ba8-baaa-825aa496a264" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb159"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb159-1"><a href="#cb159-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb159-2"><a href="#cb159-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="fd9e3780-6672-4054-bab8-d389dd1515ad" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb161"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb161-1"><a href="#cb161-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb161-2"><a href="#cb161-2" aria-hidden="true" tabindex="-1"></a>    mutilde <span class="op">=</span> ebayesthresh_torch.postmean_laplace(x, s, w, a<span class="op">=</span>a)</span>
<span id="cb161-3"><a href="#cb161-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb161-4"><a href="#cb161-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> torch.<span class="bu">any</span>(s <span class="op">!=</span> <span class="dv">1</span>):</span>
<span id="cb161-5"><a href="#cb161-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Only standard deviation of 1 is allowed for Cauchy prior."</span>)</span>
<span id="cb161-6"><a href="#cb161-6" aria-hidden="true" tabindex="-1"></a>    mutilde <span class="op">=</span> ebayesthresh_torch.postmean_cauchy(x, w)</span>
<span id="cb161-7"><a href="#cb161-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb161-8"><a href="#cb161-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Unknown prior type."</span>)</span></code></pre></div>
</div>
<div id="b0c298aa-dc02-4eb3-9e6e-dbf56036ffb2" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb162"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb162-1"><a href="#cb162-1" aria-hidden="true" tabindex="-1"></a>mutilde</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>tensor([-1.011589622421743,  0.270953303334685,  0.000000000000000,
        -3.488009240410718,  7.499999999992725, 49.500000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="#cb164-1" aria-hidden="true" tabindex="-1"></a>postmean <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb164-2"><a href="#cb164-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb164-3"><a href="#cb164-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the posterior mean for the appropriate prior for </span></span>
<span id="cb164-4"><a href="#cb164-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   given x, s (sd), w and a.</span></span>
<span id="cb164-5"><a href="#cb164-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb164-6"><a href="#cb164-6" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb164-7"><a href="#cb164-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>)</span>
<span id="cb164-8"><a href="#cb164-8" aria-hidden="true" tabindex="-1"></a>        mutilde <span class="ot">&lt;-</span> <span class="fu">postmean.laplace</span>(x, s, w, <span class="at">a =</span> a)</span>
<span id="cb164-9"><a href="#cb164-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>){</span>
<span id="cb164-10"><a href="#cb164-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="fu">any</span>(s <span class="sc">!=</span> <span class="dv">1</span>))</span>
<span id="cb164-11"><a href="#cb164-11" aria-hidden="true" tabindex="-1"></a>                <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Only standard deviation of 1 is allowed"</span>,</span>
<span id="cb164-12"><a href="#cb164-12" aria-hidden="true" tabindex="-1"></a>                           <span class="st">"for Cauchy prior."</span>))</span>
<span id="cb164-13"><a href="#cb164-13" aria-hidden="true" tabindex="-1"></a>        mutilde <span class="ot">&lt;-</span> <span class="fu">postmean.cauchy</span>(x, w)</span>
<span id="cb164-14"><a href="#cb164-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb164-15"><a href="#cb164-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(mutilde)</span>
<span id="cb164-16"><a href="#cb164-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="4f6ec048-878a-4dde-bbd2-bcaefbd09b1c" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb165"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb165-1"><a href="#cb165-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmean(torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>]), s<span class="op">=</span><span class="dv">1</span>, w <span class="op">=</span> <span class="fl">0.5</span>, prior <span class="op">=</span> <span class="st">"laplace"</span>, a <span class="op">=</span> <span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>tensor([-1.011589622421743,  0.270953303334685,  0.000000000000000,
        -3.488009240410718,  7.499999999992725, 49.500000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="#cb167-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">postmean</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>), <span class="at">s=</span><span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>)</span>
<span id="cb167-2"><a href="#cb167-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">1.0115896</span>  <span class="fl">0.2709533</span>  <span class="fl">0.0000000</span> <span class="sc">-</span><span class="fl">3.4880092</span>  <span class="fl">7.5000000</span> <span class="fl">49.5000000</span></span></code></pre></div>
</section>
<section id="postmean_cauchy" class="level1">
<h1>postmean_cauchy</h1>
<blockquote class="blockquote">
<p>Find the posterior mean for the quasi-Cauchy prior with mixing weight w given data x, which may be a scalar or a vector.</p>
</blockquote>
<ul>
<li>quasi-Cauch에 대한 사후 평균 구하기</li>
</ul>
<div id="b74b235e-0245-475b-bc8b-52e5c04e9d8f" class="cell" data-execution_count="84">
<div class="sourceCode cell-code" id="cb168"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb168-1"><a href="#cb168-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span>torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>], dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb168-2"><a href="#cb168-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="fd533bef-cbb8-4c97-93ee-8de4725109a5" class="cell" data-execution_count="85">
<div class="sourceCode cell-code" id="cb169"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb169-1"><a href="#cb169-1" aria-hidden="true" tabindex="-1"></a>ind <span class="op">=</span> torch.nonzero(x <span class="op">==</span> <span class="dv">0</span>)</span>
<span id="cb169-2"><a href="#cb169-2" aria-hidden="true" tabindex="-1"></a>ind</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="85">
<pre><code>tensor([[2]])</code></pre>
</div>
</div>
<div id="939db8fc-7cbd-480a-b50a-7f8dab1e4d3a" class="cell" data-execution_count="86">
<div class="sourceCode cell-code" id="cb171"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb171-1"><a href="#cb171-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x[x <span class="op">!=</span> <span class="dv">0</span>] </span>
<span id="cb171-2"><a href="#cb171-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="86">
<pre><code>tensor([-2.,  1., -4.,  8., 50.], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="aae66d69-d31b-4618-b979-f3d2d5f869a0" class="cell" data-execution_count="87">
<div class="sourceCode cell-code" id="cb173"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb173-1"><a href="#cb173-1" aria-hidden="true" tabindex="-1"></a>ex <span class="op">=</span> torch.exp(<span class="op">-</span>x<span class="op">**</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)</span>
<span id="cb173-2"><a href="#cb173-2" aria-hidden="true" tabindex="-1"></a>ex</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="87">
<pre><code>tensor([1.353352832366127e-01, 6.065306597126334e-01, 3.354626279025119e-04,
        1.266416554909418e-14, 0.000000000000000e+00], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="33da9bfa-9ab0-4e93-80c8-84df66133df4" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb175"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb175-1"><a href="#cb175-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> w <span class="op">*</span> (x <span class="op">-</span> (<span class="dv">2</span> <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> ex))<span class="op">/</span>x)</span>
<span id="cb175-2"><a href="#cb175-2" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>tensor([-0.567667641618306,  0.106530659712633, -1.750083865656976,
         3.875000000000002, 24.980000000000000], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="81ccd9c6-b4b6-404d-ab81-1dbbfaf1f871" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb177"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb177-1"><a href="#cb177-1" aria-hidden="true" tabindex="-1"></a>z <span class="op">=</span> z <span class="op">/</span> (w <span class="op">*</span> (<span class="dv">1</span> <span class="op">-</span> ex) <span class="op">+</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">*</span> ex <span class="op">*</span> x<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb177-2"><a href="#cb177-2" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>tensor([-0.807489729485063,  0.213061319425267, -3.482643281306042,
         7.749999999993821, 49.960000000000001], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="2491ebf3-5174-4162-ae66-433e8e138ba1" class="cell" data-execution_count="90">
<div class="sourceCode cell-code" id="cb179"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb179-1"><a href="#cb179-1" aria-hidden="true" tabindex="-1"></a>muhat <span class="op">=</span> z</span>
<span id="cb179-2"><a href="#cb179-2" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="90">
<pre><code>tensor([-0.807489729485063,  0.213061319425267, -3.482643281306042,
         7.749999999993821, 49.960000000000001], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="0e3b52be-59ff-4388-b680-d04ee8f1bef2" class="cell" data-execution_count="91">
<div class="sourceCode cell-code" id="cb181"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb181-1"><a href="#cb181-1" aria-hidden="true" tabindex="-1"></a>muhat[ind] <span class="op">=</span> torch.tensor([<span class="fl">0.0</span>], dtype<span class="op">=</span><span class="bu">float</span>)</span></code></pre></div>
</div>
<div id="b60469d4-ef1e-42c5-880b-bbe8429e6b0b" class="cell" data-execution_count="92">
<div class="sourceCode cell-code" id="cb182"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb182-1"><a href="#cb182-1" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="92">
<pre><code>tensor([-0.807489729485063,  0.213061319425267,  0.000000000000000,
         7.749999999993821, 49.960000000000001], dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="#cb184-1" aria-hidden="true" tabindex="-1"></a>postmean.cauchy <span class="ot">&lt;-</span> <span class="cf">function</span>(x, w) {</span>
<span id="cb184-2"><a href="#cb184-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb184-3"><a href="#cb184-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the posterior mean for the quasi-Cauchy prior with mixing</span></span>
<span id="cb184-4"><a href="#cb184-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   weight w given data x, which may be a scalar or a vector.</span></span>
<span id="cb184-5"><a href="#cb184-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb184-6"><a href="#cb184-6" aria-hidden="true" tabindex="-1"></a>    muhat <span class="ot">&lt;-</span> x</span>
<span id="cb184-7"><a href="#cb184-7" aria-hidden="true" tabindex="-1"></a>    ind <span class="ot">&lt;-</span> (x <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb184-8"><a href="#cb184-8" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> x[<span class="sc">!</span>ind]</span>
<span id="cb184-9"><a href="#cb184-9" aria-hidden="true" tabindex="-1"></a>    ex <span class="ot">&lt;-</span> <span class="fu">exp</span>( <span class="sc">-</span> x<span class="sc">^</span><span class="dv">2</span><span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb184-10"><a href="#cb184-10" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> w <span class="sc">*</span> (x <span class="sc">-</span> (<span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> ex))<span class="sc">/</span>x)</span>
<span id="cb184-11"><a href="#cb184-11" aria-hidden="true" tabindex="-1"></a>    z <span class="ot">&lt;-</span> z<span class="sc">/</span>(w <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> ex) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> w) <span class="sc">*</span> ex <span class="sc">*</span> x<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb184-12"><a href="#cb184-12" aria-hidden="true" tabindex="-1"></a>    muhat[<span class="sc">!</span>ind] <span class="ot">&lt;-</span> z</span>
<span id="cb184-13"><a href="#cb184-13" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(muhat)</span>
<span id="cb184-14"><a href="#cb184-14" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="e30de365-f9cf-45bc-87a6-b7b9d89ab545" class="cell" data-execution_count="93">
<div class="sourceCode cell-code" id="cb185"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb185-1"><a href="#cb185-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmean_cauchy(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]),<span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="93">
<pre><code>tensor([-0.807489693164825,  0.213061332702637,  0.000000000000000,
         7.750000000000000, 49.959999084472656])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="#cb187-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">postmean.cauchy</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>),<span class="fl">0.5</span>)</span>
<span id="cb187-2"><a href="#cb187-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">0.8074897</span>  <span class="fl">0.2130613</span>  <span class="fl">0.0000000</span> <span class="sc">-</span><span class="fl">3.4826433</span>  <span class="fl">7.7500000</span> <span class="fl">49.9600000</span></span></code></pre></div>
</section>
<section id="postmean.laplace" class="level1">
<h1>postmean.laplace</h1>
<blockquote class="blockquote">
<p>Find the posterior mean for the double exponential prior for given <span class="math inline">\(x, s (sd), w\)</span>, and <span class="math inline">\(a\)</span>.</p>
</blockquote>
<ul>
<li>이전 지수 분포에 대한 사후 평균</li>
</ul>
<div id="a8126ddd-5f06-4aea-814c-766bb7dd4b21" class="cell" data-execution_count="105">
<div class="sourceCode cell-code" id="cb188"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb188-1"><a href="#cb188-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>])</span>
<span id="cb188-2"><a href="#cb188-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb188-3"><a href="#cb188-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb188-4"><a href="#cb188-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="36407eb7-23ff-4d23-bf8e-6194e6da4cd5" class="cell" data-execution_count="106">
<div class="sourceCode cell-code" id="cb189"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb189-1"><a href="#cb189-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="bu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb189-2"><a href="#cb189-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="106">
<pre><code>0.5</code></pre>
</div>
</div>
<div id="896face3-440e-48c0-ba29-5fceebcdfe8d" class="cell" data-execution_count="107">
<div class="sourceCode cell-code" id="cb191"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb191-1"><a href="#cb191-1" aria-hidden="true" tabindex="-1"></a>w_post <span class="op">=</span> ebayesthresh_torch.wpost_laplace(w, x, s, a)</span>
<span id="cb191-2"><a href="#cb191-2" aria-hidden="true" tabindex="-1"></a>w_post</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="107">
<pre><code>tensor([0.653961521302972, 0.382700153299694, 0.304677821507423,
        0.996521248676984, 0.999999999999026, 1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="ad1a9277-496e-4836-b57e-bbb31c3ea02a" class="cell" data-execution_count="108">
<div class="sourceCode cell-code" id="cb193"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb193-1"><a href="#cb193-1" aria-hidden="true" tabindex="-1"></a>sx <span class="op">=</span> torch.sign(x)</span>
<span id="cb193-2"><a href="#cb193-2" aria-hidden="true" tabindex="-1"></a>sx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="108">
<pre><code>tensor([-1,  1,  0, -1,  1,  1])</code></pre>
</div>
</div>
<div id="ea0b5e59-14c4-4945-8fd4-1507581e3017" class="cell" data-execution_count="109">
<div class="sourceCode cell-code" id="cb195"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb195-1"><a href="#cb195-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.<span class="bu">abs</span>(x)</span>
<span id="cb195-2"><a href="#cb195-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="109">
<pre><code>tensor([ 2,  1,  0,  4,  8, 50])</code></pre>
</div>
</div>
<div id="2d44dfa2-a725-4379-9502-8ee8d33191de" class="cell" data-execution_count="110">
<div class="sourceCode cell-code" id="cb197"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb197-1"><a href="#cb197-1" aria-hidden="true" tabindex="-1"></a>xpa <span class="op">=</span> x <span class="op">/</span> s <span class="op">+</span> s <span class="op">*</span> a</span>
<span id="cb197-2"><a href="#cb197-2" aria-hidden="true" tabindex="-1"></a>xpa</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor([ 2.500000000000000,  1.500000000000000,  0.500000000000000,
         4.500000000000000,  8.500000000000000, 50.500000000000000])</code></pre>
</div>
</div>
<div id="09cb6c5b-0bc8-429c-8745-06361ddef666" class="cell" data-execution_count="111">
<div class="sourceCode cell-code" id="cb199"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb199-1"><a href="#cb199-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> x <span class="op">/</span> s <span class="op">-</span> s <span class="op">*</span> a</span>
<span id="cb199-2"><a href="#cb199-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="111">
<pre><code>tensor([ 1.500000000000000,  0.500000000000000, -0.500000000000000,
         3.500000000000000,  7.500000000000000, 49.500000000000000])</code></pre>
</div>
</div>
<div id="ed72eaa6-281a-4a4f-a527-4517aea9b286" class="cell" data-execution_count="112">
<div class="sourceCode cell-code" id="cb201"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb201-1"><a href="#cb201-1" aria-hidden="true" tabindex="-1"></a>xpa <span class="op">=</span> torch.minimum(xpa, torch.tensor(<span class="fl">35.0</span>))</span>
<span id="cb201-2"><a href="#cb201-2" aria-hidden="true" tabindex="-1"></a>xpa</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="112">
<pre><code>tensor([ 2.500000000000000,  1.500000000000000,  0.500000000000000,
         4.500000000000000,  8.500000000000000, 35.000000000000000])</code></pre>
</div>
</div>
<div id="a9d03d5b-468e-4ec9-8bd0-88b82d891e1c" class="cell" data-execution_count="113">
<div class="sourceCode cell-code" id="cb203"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb203-1"><a href="#cb203-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> torch.maximum(xma, torch.tensor(<span class="op">-</span><span class="fl">35.0</span>))</span>
<span id="cb203-2"><a href="#cb203-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="113">
<pre><code>tensor([ 1.500000000000000,  0.500000000000000, -0.500000000000000,
         3.500000000000000,  7.500000000000000, 49.500000000000000])</code></pre>
</div>
</div>
<div id="60251628-d8e8-4437-b7b5-cf20b05268c2" class="cell" data-execution_count="119">
<div class="sourceCode cell-code" id="cb205"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb205-1"><a href="#cb205-1" aria-hidden="true" tabindex="-1"></a>cp1 <span class="op">=</span> torch.tensor(norm.cdf(xma, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb205-2"><a href="#cb205-2" aria-hidden="true" tabindex="-1"></a>cp1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="119">
<pre><code>tensor([0.933192798731142, 0.691462461274013, 0.308537538725987,
        0.999767370920964, 0.999999999999968, 1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="c47208de-54e8-4452-8b6a-b09fc8dfa13e" class="cell" data-execution_count="121">
<div class="sourceCode cell-code" id="cb207"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb207-1"><a href="#cb207-1" aria-hidden="true" tabindex="-1"></a>cp2 <span class="op">=</span> torch.tensor(norm.cdf(<span class="op">-</span>xpa, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb207-2"><a href="#cb207-2" aria-hidden="true" tabindex="-1"></a>cp2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="121">
<pre><code>tensor([ 6.209665325776132e-03,  6.680720126885807e-02,  3.085375387259869e-01,
         3.397673124730053e-06,  9.479534822203250e-18, 1.124910706472406e-268],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="d40fe4d9-ec1f-42b5-97b3-cf4b46015df9" class="cell" data-execution_count="122">
<div class="sourceCode cell-code" id="cb209"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb209-1"><a href="#cb209-1" aria-hidden="true" tabindex="-1"></a>ef <span class="op">=</span> torch.exp(torch.minimum(<span class="dv">2</span> <span class="op">*</span> a <span class="op">*</span> x, torch.tensor(<span class="fl">100.0</span>, dtype<span class="op">=</span>torch.float32)))</span>
<span id="cb209-2"><a href="#cb209-2" aria-hidden="true" tabindex="-1"></a>ef</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="122">
<pre><code>tensor([7.389056205749512e+00, 2.718281745910645e+00, 1.000000000000000e+00,
        5.459814834594727e+01, 2.980958007812500e+03, 5.184705457665547e+21])</code></pre>
</div>
</div>
<div id="c2fe42ae-862c-4cfb-849c-212a7d3dc534" class="cell" data-execution_count="123">
<div class="sourceCode cell-code" id="cb211"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb211-1"><a href="#cb211-1" aria-hidden="true" tabindex="-1"></a>postmean_cond <span class="op">=</span> x <span class="op">-</span> a <span class="op">*</span> s<span class="op">**</span><span class="dv">2</span> <span class="op">*</span> (<span class="dv">2</span> <span class="op">*</span> cp1 <span class="op">/</span> (cp1 <span class="op">+</span> ef <span class="op">*</span> cp2) <span class="op">-</span> <span class="dv">1</span>)</span>
<span id="cb211-2"><a href="#cb211-2" aria-hidden="true" tabindex="-1"></a>postmean_cond</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="123">
<pre><code>tensor([ 1.546864134156123,  0.708004167227234,  0.000000000000000,
         3.500185515403230,  7.500000000000028, 49.500000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="a6dd63a1-132c-44fa-84d5-1443dc2af6b2" class="cell" data-execution_count="124">
<div class="sourceCode cell-code" id="cb213"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb213-1"><a href="#cb213-1" aria-hidden="true" tabindex="-1"></a>sx <span class="op">*</span> w_post <span class="op">*</span> postmean_cond</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="124">
<pre><code>tensor([-1.011589622421743,  0.270953303334685,  0.000000000000000,
        -3.488009240410718,  7.499999999992725, 49.500000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb215"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb215-1"><a href="#cb215-1" aria-hidden="true" tabindex="-1"></a>postmean.laplace <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb215-2"><a href="#cb215-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb215-3"><a href="#cb215-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the posterior mean for the double exponential prior for </span></span>
<span id="cb215-4"><a href="#cb215-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   given x, s (sd), w and a.</span></span>
<span id="cb215-5"><a href="#cb215-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb215-6"><a href="#cb215-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb215-7"><a href="#cb215-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Only allow a &lt; 20 for input value.</span></span>
<span id="cb215-8"><a href="#cb215-8" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb215-9"><a href="#cb215-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb215-10"><a href="#cb215-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># First find the probability of being non-zero</span></span>
<span id="cb215-11"><a href="#cb215-11" aria-hidden="true" tabindex="-1"></a>    wpost <span class="ot">&lt;-</span> <span class="fu">wpost.laplace</span>(w, x, s, a)</span>
<span id="cb215-12"><a href="#cb215-12" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb215-13"><a href="#cb215-13" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Now find the posterior mean conditional on being non-zero</span></span>
<span id="cb215-14"><a href="#cb215-14" aria-hidden="true" tabindex="-1"></a>    sx <span class="ot">&lt;-</span> <span class="fu">sign</span>(x)</span>
<span id="cb215-15"><a href="#cb215-15" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">abs</span>(x)</span>
<span id="cb215-16"><a href="#cb215-16" aria-hidden="true" tabindex="-1"></a>    xpa <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">+</span> s<span class="sc">*</span>a</span>
<span id="cb215-17"><a href="#cb215-17" aria-hidden="true" tabindex="-1"></a>    xma <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">-</span> s<span class="sc">*</span>a</span>
<span id="cb215-18"><a href="#cb215-18" aria-hidden="true" tabindex="-1"></a>    xpa[xpa <span class="sc">&gt;</span> <span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="dv">35</span></span>
<span id="cb215-19"><a href="#cb215-19" aria-hidden="true" tabindex="-1"></a>    xma[xma <span class="sc">&lt;</span> <span class="sc">-</span><span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="sc">-</span><span class="dv">35</span></span>
<span id="cb215-20"><a href="#cb215-20" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb215-21"><a href="#cb215-21" aria-hidden="true" tabindex="-1"></a>    cp1 <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(xma)</span>
<span id="cb215-22"><a href="#cb215-22" aria-hidden="true" tabindex="-1"></a>    cp2 <span class="ot">&lt;-</span> <span class="fu">pnorm</span>( <span class="sc">-</span> xpa)</span>
<span id="cb215-23"><a href="#cb215-23" aria-hidden="true" tabindex="-1"></a>    ef <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="fu">pmin</span>(<span class="dv">2</span> <span class="sc">*</span> a <span class="sc">*</span> x, <span class="dv">100</span>))</span>
<span id="cb215-24"><a href="#cb215-24" aria-hidden="true" tabindex="-1"></a>    postmeancond <span class="ot">&lt;-</span> x <span class="sc">-</span> a <span class="sc">*</span> s<span class="sc">^</span><span class="dv">2</span> <span class="sc">*</span> ( <span class="dv">2</span> <span class="sc">*</span> cp1<span class="sc">/</span>(cp1 <span class="sc">+</span> ef <span class="sc">*</span> cp2) <span class="sc">-</span> <span class="dv">1</span>)</span>
<span id="cb215-25"><a href="#cb215-25" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb215-26"><a href="#cb215-26" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Calculate posterior mean and return</span></span>
<span id="cb215-27"><a href="#cb215-27" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(sx <span class="sc">*</span> wpost <span class="sc">*</span> postmeancond)</span>
<span id="cb215-28"><a href="#cb215-28" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="82b4fc5b-6d08-44d8-bc18-ba08d4f510c4" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb216"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb216-1"><a href="#cb216-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmean_laplace(torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([-1.011589622421743,  0.270953303334685,  0.000000000000000,
        -3.488009240410718,  7.499999999992725, 49.500000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="#cb218-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">postmean.laplace</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>))</span>
<span id="cb218-2"><a href="#cb218-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="sc">-</span><span class="fl">1.0115896</span>  <span class="fl">0.2709533</span>  <span class="fl">0.0000000</span> <span class="sc">-</span><span class="fl">3.4880092</span>  <span class="fl">7.5000000</span> <span class="fl">49.5000000</span></span></code></pre></div>
</section>
<section id="postmed" class="level1">
<h1>postmed</h1>
<p>Description</p>
<blockquote class="blockquote">
<p>Given a single value or a vector of data and sampling standard deviations (sd is 1 for Cauchy prior), find the corresponding posterior median estimate(s) of the underlying signal value(s).</p>
</blockquote>
<p>사후 확률 중앙값 추정치 구하기</p>
<div id="1fbbb2e1-969d-40a5-bf88-6f6998ccd12f" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb219"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb219-1"><a href="#cb219-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>])</span>
<span id="cb219-2"><a href="#cb219-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb219-3"><a href="#cb219-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb219-4"><a href="#cb219-4" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">"laplace"</span></span>
<span id="cb219-5"><a href="#cb219-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="7115ed8e-67d6-4935-88ef-288149d0701c" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb220"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb220-1"><a href="#cb220-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb220-2"><a href="#cb220-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="20cfcfd2-c4d4-4c98-9c4b-d1ec25a94f7a" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb222"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb222-1"><a href="#cb222-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb222-2"><a href="#cb222-2" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.postmed_laplace(x, s, w, a)</span>
<span id="cb222-3"><a href="#cb222-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb222-4"><a href="#cb222-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> np.<span class="bu">any</span>(s <span class="op">!=</span> <span class="dv">1</span>):</span>
<span id="cb222-5"><a href="#cb222-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Only standard deviation of 1 is allowed for Cauchy prior."</span>)</span>
<span id="cb222-6"><a href="#cb222-6" aria-hidden="true" tabindex="-1"></a>    muhat <span class="op">=</span> ebayesthresh_torch.postmed_cauchy(x, w)</span>
<span id="cb222-7"><a href="#cb222-7" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb222-8"><a href="#cb222-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="ss">f"Unknown prior: </span><span class="sc">{</span>prior<span class="sc">}</span><span class="ss">"</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
</div>
<div id="419c63f7-b1a4-4091-a991-5522da2b08d6" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb224"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb224-1"><a href="#cb224-1" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([0.000000000000000, 1.734132351356471, 2.978157631290933],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="#cb226-1" aria-hidden="true" tabindex="-1"></a>postmed <span class="ot">&lt;-</span> <span class="cf">function</span> (x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb226-2"><a href="#cb226-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb226-3"><a href="#cb226-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the posterior median for the appropriate prior for </span></span>
<span id="cb226-4"><a href="#cb226-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   given x, s (sd), w and a. </span></span>
<span id="cb226-5"><a href="#cb226-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb226-6"><a href="#cb226-6" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb226-7"><a href="#cb226-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>)</span>
<span id="cb226-8"><a href="#cb226-8" aria-hidden="true" tabindex="-1"></a>        muhat <span class="ot">&lt;-</span> <span class="fu">postmed.laplace</span>(x, s, w, a)</span>
<span id="cb226-9"><a href="#cb226-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>) {</span>
<span id="cb226-10"><a href="#cb226-10" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span>(<span class="fu">any</span>(s <span class="sc">!=</span> <span class="dv">1</span>))</span>
<span id="cb226-11"><a href="#cb226-11" aria-hidden="true" tabindex="-1"></a>                <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Only standard deviation of 1 is allowed"</span>,</span>
<span id="cb226-12"><a href="#cb226-12" aria-hidden="true" tabindex="-1"></a>                           <span class="st">"for Cauchy prior."</span>))</span>
<span id="cb226-13"><a href="#cb226-13" aria-hidden="true" tabindex="-1"></a>        muhat <span class="ot">&lt;-</span> <span class="fu">postmed.cauchy</span>(x, w)</span>
<span id="cb226-14"><a href="#cb226-14" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb226-15"><a href="#cb226-15" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(muhat)</span>
<span id="cb226-16"><a href="#cb226-16" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="fc3e6794-fdce-4ecd-a076-d656508773b8" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb227"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb227-1"><a href="#cb227-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmed(x <span class="op">=</span> torch.tensor([<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([0.000000000000000, 1.734132351356471, 2.978157631290933],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="#cb229-1" aria-hidden="true" tabindex="-1"></a> <span class="fu">postmed</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>))</span>
<span id="cb229-2"><a href="#cb229-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.000000</span> <span class="fl">1.734132</span> <span class="fl">2.978158</span></span></code></pre></div>
</section>
<section id="postmed_cauchy" class="level1">
<h1>postmed_cauchy</h1>
<div id="6b3d3220-3956-4e81-885f-9d9787608323" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb230"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb230-1"><a href="#cb230-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>])</span>
<span id="cb230-2"><a href="#cb230-2" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="1ba01671-d551-4f44-86a5-588fa0df51c8" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb231"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb231-1"><a href="#cb231-1" aria-hidden="true" tabindex="-1"></a>nx <span class="op">=</span> <span class="bu">len</span>(x)</span>
<span id="cb231-2"><a href="#cb231-2" aria-hidden="true" tabindex="-1"></a>nx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>4</code></pre>
</div>
</div>
<div id="1b6fe68c-c2d7-4737-9f4e-7e1a703c56b7" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb233"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb233-1"><a href="#cb233-1" aria-hidden="true" tabindex="-1"></a>zest <span class="op">=</span> torch.full((nx,), <span class="bu">float</span>(<span class="st">'nan'</span>))</span>
<span id="cb233-2"><a href="#cb233-2" aria-hidden="true" tabindex="-1"></a>zest</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>tensor([nan, nan, nan, nan])</code></pre>
</div>
</div>
<div id="a9eb118a-86b1-4422-b6ff-15551cb502c8" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb235"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb235-1"><a href="#cb235-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.full((nx,), w)</span>
<span id="cb235-2"><a href="#cb235-2" aria-hidden="true" tabindex="-1"></a>w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="21">
<pre><code>tensor([0.500000000000000, 0.500000000000000, 0.500000000000000,
        0.500000000000000])</code></pre>
</div>
</div>
<div id="5865aedc-29d2-46f0-aa50-f335c059cca4" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb237"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb237-1"><a href="#cb237-1" aria-hidden="true" tabindex="-1"></a>ax <span class="op">=</span> torch.<span class="bu">abs</span>(x)</span>
<span id="cb237-2"><a href="#cb237-2" aria-hidden="true" tabindex="-1"></a>ax</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="22">
<pre><code>tensor([10, 15, 20, 25])</code></pre>
</div>
</div>
<div id="eefa743b-8d90-49e1-ad39-277fabd5ea82" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb239"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb239-1"><a href="#cb239-1" aria-hidden="true" tabindex="-1"></a>j <span class="op">=</span> ax <span class="op">&lt;</span> <span class="dv">20</span></span>
<span id="cb239-2"><a href="#cb239-2" aria-hidden="true" tabindex="-1"></a>j</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>tensor([ True,  True, False, False])</code></pre>
</div>
</div>
<div id="8ab6b946-a281-46b8-a4bc-0a9af1aae8ec" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb241"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb241-1"><a href="#cb241-1" aria-hidden="true" tabindex="-1"></a>zest[<span class="op">~</span>j] <span class="op">=</span> ax[<span class="op">~</span>j] <span class="op">-</span> <span class="dv">2</span> <span class="op">/</span> ax[<span class="op">~</span>j]</span>
<span id="cb241-2"><a href="#cb241-2" aria-hidden="true" tabindex="-1"></a>zest</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>tensor([               nan,                nan, 19.899999618530273,
        24.920000076293945])</code></pre>
</div>
</div>
<div id="5f5205a0-2b22-432d-9091-8312a93e5970" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb243"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb243-1"><a href="#cb243-1" aria-hidden="true" tabindex="-1"></a>torch.zeros(torch.<span class="bu">sum</span>(j))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="25">
<pre><code>tensor([0., 0.])</code></pre>
</div>
</div>
<div id="ba175e06-8b65-463d-8452-ecb452edad85" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb245"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb245-1"><a href="#cb245-1" aria-hidden="true" tabindex="-1"></a>torch.zeros(torch.<span class="bu">sum</span>(j)).shape[<span class="dv">0</span>]</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>2</code></pre>
</div>
</div>
<div id="4706058f-925f-4b75-acfb-55e5dc7d96fc" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb247"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb247-1"><a href="#cb247-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.<span class="bu">sum</span>(j) <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb247-2"><a href="#cb247-2" aria-hidden="true" tabindex="-1"></a>    zest[j] <span class="op">=</span> ebayesthresh_torch.vecbinsolv(zf<span class="op">=</span>torch.zeros(torch.<span class="bu">sum</span>(j)),</span>
<span id="cb247-3"><a href="#cb247-3" aria-hidden="true" tabindex="-1"></a>                                            fun<span class="op">=</span>ebayesthresh_torch.cauchy_medzero,</span>
<span id="cb247-4"><a href="#cb247-4" aria-hidden="true" tabindex="-1"></a>                                             tlo<span class="op">=</span><span class="dv">0</span>, thi<span class="op">=</span>torch.<span class="bu">max</span>(ax[j]), z<span class="op">=</span>ax[j], w<span class="op">=</span>w[j])</span></code></pre></div>
</div>
<div id="636973b1-2556-4d08-aa24-05df45ea3152" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb248"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb248-1"><a href="#cb248-1" aria-hidden="true" tabindex="-1"></a>zest[zest <span class="op">&lt;</span> <span class="fl">1e-7</span>] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb248-2"><a href="#cb248-2" aria-hidden="true" tabindex="-1"></a>zest</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([ 9.800643920898438, 14.866861343383789, 19.899999618530273,
        24.920000076293945])</code></pre>
</div>
</div>
<div id="55ebc905-121b-4708-a6cd-dff8706fbef6" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb250"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb250-1"><a href="#cb250-1" aria-hidden="true" tabindex="-1"></a>zest <span class="op">=</span> torch.sign(x) <span class="op">*</span> zest</span>
<span id="cb250-2"><a href="#cb250-2" aria-hidden="true" tabindex="-1"></a>zest</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([ 9.800643920898438, 14.866861343383789, 19.899999618530273,
        24.920000076293945])</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb252"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb252-1"><a href="#cb252-1" aria-hidden="true" tabindex="-1"></a>postmed.cauchy <span class="ot">&lt;-</span> <span class="cf">function</span>(x, w) {</span>
<span id="cb252-2"><a href="#cb252-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb252-3"><a href="#cb252-3" aria-hidden="true" tabindex="-1"></a><span class="co"># find the posterior median of the Cauchy prior with mixing weight w,</span></span>
<span id="cb252-4"><a href="#cb252-4" aria-hidden="true" tabindex="-1"></a><span class="co"># pointwise for each of the data points x</span></span>
<span id="cb252-5"><a href="#cb252-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb252-6"><a href="#cb252-6" aria-hidden="true" tabindex="-1"></a>    nx <span class="ot">&lt;-</span> <span class="fu">length</span>(x)</span>
<span id="cb252-7"><a href="#cb252-7" aria-hidden="true" tabindex="-1"></a>    zest <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="fu">length</span>(x))</span>
<span id="cb252-8"><a href="#cb252-8" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> <span class="fu">rep</span>(w, <span class="at">length.out =</span> nx)</span>
<span id="cb252-9"><a href="#cb252-9" aria-hidden="true" tabindex="-1"></a>    ax <span class="ot">&lt;-</span> <span class="fu">abs</span>(x)</span>
<span id="cb252-10"><a href="#cb252-10" aria-hidden="true" tabindex="-1"></a>    j <span class="ot">&lt;-</span> (ax <span class="sc">&lt;</span> <span class="dv">20</span>)</span>
<span id="cb252-11"><a href="#cb252-11" aria-hidden="true" tabindex="-1"></a>    zest[<span class="sc">!</span>j] <span class="ot">&lt;-</span> ax[<span class="sc">!</span>j] <span class="sc">-</span> <span class="dv">2</span><span class="sc">/</span>ax[<span class="sc">!</span>j]</span>
<span id="cb252-12"><a href="#cb252-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">sum</span>(j) <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb252-13"><a href="#cb252-13" aria-hidden="true" tabindex="-1"></a>      zest[j] <span class="ot">&lt;-</span> <span class="fu">vecbinsolv</span>(<span class="at">zf =</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">sum</span>(j)), <span class="at">fun =</span> cauchy.medzero,</span>
<span id="cb252-14"><a href="#cb252-14" aria-hidden="true" tabindex="-1"></a>                                <span class="at">tlo =</span> <span class="dv">0</span>, <span class="at">thi =</span> <span class="fu">max</span>(ax[j]), <span class="at">z =</span> ax[j],</span>
<span id="cb252-15"><a href="#cb252-15" aria-hidden="true" tabindex="-1"></a>                                <span class="at">w =</span> w[j])</span>
<span id="cb252-16"><a href="#cb252-16" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb252-17"><a href="#cb252-17" aria-hidden="true" tabindex="-1"></a>    zest[zest <span class="sc">&lt;</span> <span class="fl">1e-007</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb252-18"><a href="#cb252-18" aria-hidden="true" tabindex="-1"></a>    zest <span class="ot">&lt;-</span> <span class="fu">sign</span>(x) <span class="sc">*</span> zest</span>
<span id="cb252-19"><a href="#cb252-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(zest)</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="09ce651c-8952-423e-80cc-18723c533745" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb253"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb253-1"><a href="#cb253-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmed_cauchy(x<span class="op">=</span>torch.tensor([<span class="fl">10.0</span>, <span class="fl">15.0</span>, <span class="fl">20.0</span>, <span class="fl">25.0</span>]), w<span class="op">=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([ 9.800643920898438, 14.866861343383789, 19.899999618530273,
        24.920000076293945])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb255"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb255-1"><a href="#cb255-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">postmed.cauchy</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">15</span>, <span class="dv">20</span>, <span class="dv">25</span>),<span class="at">w=</span><span class="fl">0.5</span>)</span>
<span id="cb255-2"><a href="#cb255-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>]  <span class="fl">9.800643</span> <span class="fl">14.866861</span> <span class="fl">19.900000</span> <span class="fl">24.920000</span></span></code></pre></div>
</section>
<section id="postmed_laplace" class="level1">
<h1>postmed_laplace</h1>
<div id="f485fb8a-31fb-4bb4-882c-2becec986d39" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb256"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb256-1"><a href="#cb256-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>])</span>
<span id="cb256-2"><a href="#cb256-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb256-3"><a href="#cb256-3" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb256-4"><a href="#cb256-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="752bbe0f-99e2-484c-a983-09da2213bcc9" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb257"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb257-1"><a href="#cb257-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="bu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb257-2"><a href="#cb257-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>0.5</code></pre>
</div>
</div>
<div id="9079596f-82df-4cd6-b9a7-c314fdfd3d08" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb259"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb259-1"><a href="#cb259-1" aria-hidden="true" tabindex="-1"></a>sx <span class="op">=</span> torch.sign(x)</span>
<span id="cb259-2"><a href="#cb259-2" aria-hidden="true" tabindex="-1"></a>sx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([1., 1., 1.])</code></pre>
</div>
</div>
<div id="d8b8c65d-39d5-48d4-9486-401188dce551" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb261"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb261-1"><a href="#cb261-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.<span class="bu">abs</span>(x)</span>
<span id="cb261-2"><a href="#cb261-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([1.500000000000000, 2.500000000000000, 3.500000000000000])</code></pre>
</div>
</div>
<div id="2b460c56-9d4b-411f-8167-f13075b6153e" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb263"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb263-1"><a href="#cb263-1" aria-hidden="true" tabindex="-1"></a>xma <span class="op">=</span> x <span class="op">/</span> s <span class="op">-</span> s <span class="op">*</span> a</span>
<span id="cb263-2"><a href="#cb263-2" aria-hidden="true" tabindex="-1"></a>xma</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor([1., 2., 3.])</code></pre>
</div>
</div>
<div id="d76cdd6f-6d87-4ea6-9394-2ab1c8626e2b" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb265"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb265-1"><a href="#cb265-1" aria-hidden="true" tabindex="-1"></a>zz <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> a <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> s <span class="op">*</span> torch.tensor(norm.pdf(xma, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))) <span class="op">*</span> (<span class="dv">1</span> <span class="op">/</span> w <span class="op">+</span> ebayesthresh_torch.beta_laplace(x, s, a))</span>
<span id="cb265-2"><a href="#cb265-2" aria-hidden="true" tabindex="-1"></a>zz</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="42">
<pre><code>tensor([0.955593330923010, 0.604829429361236, 0.508713151551759],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="26b4f2f6-0311-4a7b-b03e-56c650996404" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb268"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb268-1"><a href="#cb268-1" aria-hidden="true" tabindex="-1"></a>zz[xma <span class="op">&gt;</span> <span class="dv">25</span>] <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb268-2"><a href="#cb268-2" aria-hidden="true" tabindex="-1"></a>zz</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>tensor([0.955593330923010, 0.604829429361236, 0.508713151551759],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="c1edf1f3-c47e-44fb-818f-3033232ca524" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb270"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb270-1"><a href="#cb270-1" aria-hidden="true" tabindex="-1"></a>mucor <span class="op">=</span> torch.tensor(norm.ppf(torch.minimum(zz, torch.tensor(<span class="dv">1</span>))))</span>
<span id="cb270-2"><a href="#cb270-2" aria-hidden="true" tabindex="-1"></a>mucor</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([1.701690841545193, 0.265867648643529, 0.021842368709067],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="9a3bf836-03b1-440b-b5d8-7fcaade58174" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb272"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb272-1"><a href="#cb272-1" aria-hidden="true" tabindex="-1"></a>muhat <span class="op">=</span> sx <span class="op">*</span> torch.maximum(torch.tensor(<span class="dv">0</span>), xma <span class="op">-</span> mucor) <span class="op">*</span> s</span>
<span id="cb272-2"><a href="#cb272-2" aria-hidden="true" tabindex="-1"></a>muhat</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>tensor([0.000000000000000, 1.734132351356471, 2.978157631290933],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb274"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb274-1"><a href="#cb274-1" aria-hidden="true" tabindex="-1"></a>postmed.laplace <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb274-2"><a href="#cb274-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb274-3"><a href="#cb274-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the posterior median for the Laplace prior for </span></span>
<span id="cb274-4"><a href="#cb274-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   given x (observations), s (sd), w and a.</span></span>
<span id="cb274-5"><a href="#cb274-5" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb274-6"><a href="#cb274-6" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb274-7"><a href="#cb274-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Only allow a &lt; 20 for input value</span></span>
<span id="cb274-8"><a href="#cb274-8" aria-hidden="true" tabindex="-1"></a>  a <span class="ot">&lt;-</span> <span class="fu">min</span>(a, <span class="dv">20</span>)</span>
<span id="cb274-9"><a href="#cb274-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb274-10"><a href="#cb274-10" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Work with the absolute value of x, and for x &gt; 25 use the approximation</span></span>
<span id="cb274-11"><a href="#cb274-11" aria-hidden="true" tabindex="-1"></a>  <span class="co">#  to dnorm(x-a)*beta.laplace(x, a)</span></span>
<span id="cb274-12"><a href="#cb274-12" aria-hidden="true" tabindex="-1"></a>    sx <span class="ot">&lt;-</span> <span class="fu">sign</span>(x)</span>
<span id="cb274-13"><a href="#cb274-13" aria-hidden="true" tabindex="-1"></a>    x <span class="ot">&lt;-</span> <span class="fu">abs</span>(x)</span>
<span id="cb274-14"><a href="#cb274-14" aria-hidden="true" tabindex="-1"></a>    xma <span class="ot">&lt;-</span> x<span class="sc">/</span>s <span class="sc">-</span> s<span class="sc">*</span>a</span>
<span id="cb274-15"><a href="#cb274-15" aria-hidden="true" tabindex="-1"></a>    zz <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>a <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>s<span class="sc">*</span><span class="fu">dnorm</span>(xma)) <span class="sc">*</span> (<span class="dv">1</span><span class="sc">/</span>w <span class="sc">+</span> <span class="fu">beta.laplace</span>(x, s, a))</span>
<span id="cb274-16"><a href="#cb274-16" aria-hidden="true" tabindex="-1"></a>    zz[xma <span class="sc">&gt;</span> <span class="dv">25</span>] <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb274-17"><a href="#cb274-17" aria-hidden="true" tabindex="-1"></a>    mucor <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fu">pmin</span>(zz, <span class="dv">1</span>))</span>
<span id="cb274-18"><a href="#cb274-18" aria-hidden="true" tabindex="-1"></a>    muhat <span class="ot">&lt;-</span> sx <span class="sc">*</span> <span class="fu">pmax</span>(<span class="dv">0</span>, xma <span class="sc">-</span> mucor) <span class="sc">*</span> s</span>
<span id="cb274-19"><a href="#cb274-19" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(muhat)</span>
<span id="cb274-20"><a href="#cb274-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="cc0cb736-3192-4693-a946-6004a28f7b9f" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb275"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb275-1"><a href="#cb275-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.postmed_laplace(x <span class="op">=</span> torch.tensor([<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor([0.000000000000000, 1.734132351356471, 2.978157631290933],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb277"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb277-1"><a href="#cb277-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">postmed.laplace</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="fl">1.5</span>, <span class="fl">2.5</span>, <span class="fl">3.5</span>), <span class="at">s =</span> <span class="dv">1</span>, <span class="at">w =</span> <span class="fl">0.5</span>, <span class="at">a =</span> <span class="fl">0.5</span>)</span>
<span id="cb277-2"><a href="#cb277-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.000000</span> <span class="fl">1.734132</span> <span class="fl">2.978158</span></span></code></pre></div>
</section>
<section id="threshld" class="level1">
<h1>threshld</h1>
<blockquote class="blockquote">
<p>임계값 t를 이용해서 데이터 조정</p>
</blockquote>
<div id="216a09d4-da51-471d-be9b-f073944c71d2" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb278"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb278-1"><a href="#cb278-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor(<span class="bu">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>))</span>
<span id="cb278-2"><a href="#cb278-2" aria-hidden="true" tabindex="-1"></a>t<span class="op">=</span><span class="fl">1.4</span></span>
<span id="cb278-3"><a href="#cb278-3" aria-hidden="true" tabindex="-1"></a>hard<span class="op">=</span><span class="va">False</span></span></code></pre></div>
</div>
<div id="1898d591-06c0-4723-afda-a01f081ee379" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb279"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb279-1"><a href="#cb279-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> hard:</span>
<span id="cb279-2"><a href="#cb279-2" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> x <span class="op">*</span> (torch.<span class="bu">abs</span>(x) <span class="op">&gt;=</span> t)</span>
<span id="cb279-3"><a href="#cb279-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb279-4"><a href="#cb279-4" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.sign(x) <span class="op">*</span> torch.maximum(torch.tensor(<span class="fl">0.0</span>), torch.<span class="bu">abs</span>(x) <span class="op">-</span> t)</span></code></pre></div>
</div>
<div id="043604e6-2845-48fa-9630-c101da258b50" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb280"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb280-1"><a href="#cb280-1" aria-hidden="true" tabindex="-1"></a>z</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([-3.599999904632568, -2.599999904632568, -1.600000023841858,
        -0.600000023841858, -0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.600000023841858,  1.600000023841858,
         2.599999904632568])</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb282"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb282-1"><a href="#cb282-1" aria-hidden="true" tabindex="-1"></a>threshld <span class="ot">&lt;-</span> <span class="cf">function</span>(x, t, <span class="at">hard =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb282-2"><a href="#cb282-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb282-3"><a href="#cb282-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  threshold the data x using threshold t</span></span>
<span id="cb282-4"><a href="#cb282-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  if hard=TRUE use hard thresholding</span></span>
<span id="cb282-5"><a href="#cb282-5" aria-hidden="true" tabindex="-1"></a><span class="co">#  if hard=FALSE use soft thresholding</span></span>
<span id="cb282-6"><a href="#cb282-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(hard) z <span class="ot">&lt;-</span> x <span class="sc">*</span> (<span class="fu">abs</span>(x) <span class="sc">&gt;=</span> t) <span class="cf">else</span> {</span>
<span id="cb282-7"><a href="#cb282-7" aria-hidden="true" tabindex="-1"></a>        z <span class="ot">&lt;-</span> <span class="fu">sign</span>(x) <span class="sc">*</span> <span class="fu">pmax</span>(<span class="dv">0</span>, <span class="fu">abs</span>(x) <span class="sc">-</span> t)</span>
<span id="cb282-8"><a href="#cb282-8" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb282-9"><a href="#cb282-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(z)</span>
<span id="cb282-10"><a href="#cb282-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="0207eaa7-ba48-48ac-abef-b0bf0ddccd0c" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb283"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb283-1"><a href="#cb283-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.threshld(torch.tensor(<span class="bu">range</span>(<span class="op">-</span><span class="dv">5</span>,<span class="dv">5</span>)), t<span class="op">=</span><span class="fl">1.4</span>, hard<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([-3.599999904632568, -2.599999904632568, -1.600000023841858,
        -0.600000023841858, -0.000000000000000,  0.000000000000000,
         0.000000000000000,  0.600000023841858,  1.600000023841858,
         2.599999904632568])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb285"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb285-1"><a href="#cb285-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">threshld</span>(<span class="fu">as.array</span>(<span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>)), <span class="at">t=</span><span class="fl">1.4</span>, <span class="at">hard=</span><span class="cn">FALSE</span>)</span>
<span id="cb285-2"><a href="#cb285-2" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="sc">-</span><span class="fl">3.6</span> <span class="sc">-</span><span class="fl">2.6</span> <span class="sc">-</span><span class="fl">1.6</span> <span class="sc">-</span><span class="fl">0.6</span>  <span class="fl">0.0</span>  <span class="fl">0.0</span>  <span class="fl">0.0</span>  <span class="fl">0.6</span>  <span class="fl">1.6</span>  <span class="fl">2.6</span>  <span class="fl">3.6</span></span></code></pre></div>
</section>
<section id="wandafromx" class="level1">
<h1>wandafromx</h1>
<blockquote class="blockquote">
<p>Given a vector of data and a single value or vector of sampling standard deviations, find the marginal maximum likelihood choice of both weight and scale factor under the Laplace prior</p>
</blockquote>
<div id="a4fa125f-fd39-40df-ba23-57465d12e44e" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb286"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb286-1"><a href="#cb286-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>], dtype<span class="op">=</span><span class="bu">float</span>)</span>
<span id="cb286-2"><a href="#cb286-2" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb286-3"><a href="#cb286-3" aria-hidden="true" tabindex="-1"></a>universalthresh <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<div id="7e3238e2-e904-4fc7-8839-b2adf0ad3f0a" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb287"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb287-1"><a href="#cb287-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> universalthresh:</span>
<span id="cb287-2"><a href="#cb287-2" aria-hidden="true" tabindex="-1"></a>    thi <span class="op">=</span> torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(<span class="bu">len</span>(x)))) <span class="op">*</span> s</span>
<span id="cb287-3"><a href="#cb287-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb287-4"><a href="#cb287-4" aria-hidden="true" tabindex="-1"></a>    thi <span class="op">=</span> torch.inf</span></code></pre></div>
</div>
<div id="c216dbab-0e8c-42d3-9863-b07b725b9c78" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb288"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb288-1"><a href="#cb288-1" aria-hidden="true" tabindex="-1"></a>thi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor(1.794122576713562)</code></pre>
</div>
</div>
<div id="cce71525-16f8-4d55-b8a0-e66576b86a87" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb290"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb290-1"><a href="#cb290-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(s, <span class="bu">int</span>):</span>
<span id="cb290-2"><a href="#cb290-2" aria-hidden="true" tabindex="-1"></a>    tlo <span class="op">=</span> torch.zeros(<span class="bu">len</span>(<span class="bu">str</span>(s)))</span>
<span id="cb290-3"><a href="#cb290-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb290-4"><a href="#cb290-4" aria-hidden="true" tabindex="-1"></a>    tlo <span class="op">=</span> torch.zeros(<span class="bu">len</span>(s))</span></code></pre></div>
</div>
<div id="707b65ee-17ad-4728-b4de-c890809831b7" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb291"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb291-1"><a href="#cb291-1" aria-hidden="true" tabindex="-1"></a>tlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor([0.])</code></pre>
</div>
</div>
<div id="aff5dc4d-18fc-4f8e-b8b5-48ff4345fa7e" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb293"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb293-1"><a href="#cb293-1" aria-hidden="true" tabindex="-1"></a>lo <span class="op">=</span> torch.tensor([<span class="dv">0</span>, <span class="fl">0.04</span>])</span>
<span id="cb293-2"><a href="#cb293-2" aria-hidden="true" tabindex="-1"></a>lo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="47">
<pre><code>tensor([0.000000000000000, 0.039999999105930])</code></pre>
</div>
</div>
<div id="254942b8-ea01-4690-ba94-93059e7de381" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb295"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb295-1"><a href="#cb295-1" aria-hidden="true" tabindex="-1"></a>hi <span class="op">=</span> torch.tensor([<span class="dv">1</span>, <span class="dv">3</span>])</span>
<span id="cb295-2"><a href="#cb295-2" aria-hidden="true" tabindex="-1"></a>hi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([1, 3])</code></pre>
</div>
</div>
<div id="501f23f2-ded1-4f88-ba65-63f569e25e68" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb297"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb297-1"><a href="#cb297-1" aria-hidden="true" tabindex="-1"></a>startpar <span class="op">=</span> torch.tensor([<span class="fl">0.5</span>, <span class="fl">0.5</span>])</span>
<span id="cb297-2"><a href="#cb297-2" aria-hidden="true" tabindex="-1"></a>startpar</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>tensor([0.500000000000000, 0.500000000000000])</code></pre>
</div>
</div>
<div id="ca8d507d-6f28-40f9-a93d-012722318759" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb299"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb299-1"><a href="#cb299-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="st">'optim'</span> <span class="kw">in</span> <span class="bu">globals</span>():</span>
<span id="cb299-2"><a href="#cb299-2" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> minimize(ebayesthresh_torch.negloglik_laplace, startpar, method<span class="op">=</span><span class="st">'L-BFGS-B'</span>, bounds<span class="op">=</span>[(lo[<span class="dv">0</span>], hi[<span class="dv">0</span>]), (lo[<span class="dv">1</span>], hi[<span class="dv">1</span>])], args<span class="op">=</span>(x, s, tlo, thi))</span>
<span id="cb299-3"><a href="#cb299-3" aria-hidden="true" tabindex="-1"></a>    uu <span class="op">=</span> result.x</span>
<span id="cb299-4"><a href="#cb299-4" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb299-5"><a href="#cb299-5" aria-hidden="true" tabindex="-1"></a>    result <span class="op">=</span> minimize(ebayesthresh_torch.negloglik_laplace, startpar, bounds<span class="op">=</span>[(lo[<span class="dv">0</span>], hi[<span class="dv">0</span>]), (lo[<span class="dv">1</span>], hi[<span class="dv">1</span>])], args<span class="op">=</span>(x, s, tlo, thi))</span>
<span id="cb299-6"><a href="#cb299-6" aria-hidden="true" tabindex="-1"></a>    uu <span class="op">=</span> result.x</span></code></pre></div>
</div>
<div id="c2078b68-3a38-4110-ab7f-6ab8a1c73193" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb300"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb300-1"><a href="#cb300-1" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> uu[<span class="dv">1</span>]</span>
<span id="cb300-2"><a href="#cb300-2" aria-hidden="true" tabindex="-1"></a>a</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>0.30010822252477337</code></pre>
</div>
</div>
<div id="2920d7e7-9fb5-4109-b8a2-29d17772b3bc" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb302"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb302-1"><a href="#cb302-1" aria-hidden="true" tabindex="-1"></a>wlo <span class="op">=</span> ebayesthresh_torch.wfromt(thi, s, a<span class="op">=</span>a)</span>
<span id="cb302-2"><a href="#cb302-2" aria-hidden="true" tabindex="-1"></a>wlo</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor(0.497624103823530, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="2abe8d5a-4f63-4e7c-b5d2-d404cfc782c6" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb305"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb305-1"><a href="#cb305-1" aria-hidden="true" tabindex="-1"></a>whi <span class="op">=</span> ebayesthresh_torch.wfromt(tlo, s, a<span class="op">=</span>a)</span>
<span id="cb305-2"><a href="#cb305-2" aria-hidden="true" tabindex="-1"></a>whi</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>tensor([1.], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="a6fa31cc-0444-4c2a-be58-3a62df0f7959" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb308"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb308-1"><a href="#cb308-1" aria-hidden="true" tabindex="-1"></a>wlo <span class="op">=</span> torch.<span class="bu">max</span>(wlo)</span>
<span id="cb308-2"><a href="#cb308-2" aria-hidden="true" tabindex="-1"></a>wlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>tensor(0.497624103823530, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="33ba010f-71e3-413e-8e88-ba3f6a1a7f29" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb310"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb310-1"><a href="#cb310-1" aria-hidden="true" tabindex="-1"></a>whi <span class="op">=</span> torch.<span class="bu">min</span>(whi)</span>
<span id="cb310-2"><a href="#cb310-2" aria-hidden="true" tabindex="-1"></a>whi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor(1., dtype=torch.float64)</code></pre>
</div>
</div>
<div id="ec7940ed-4b74-4b02-a7f3-985969881764" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb312"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb312-1"><a href="#cb312-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> uu[<span class="dv">0</span>] <span class="op">*</span> (whi <span class="op">-</span> wlo) <span class="op">+</span> wlo</span>
<span id="cb312-2"><a href="#cb312-2" aria-hidden="true" tabindex="-1"></a>w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>tensor(0.846681050730532, dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="#cb314-1" aria-hidden="true" tabindex="-1"></a>wandafromx <span class="ot">&lt;-</span> <span class="cf">function</span>(x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">universalthresh =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb314-2"><a href="#cb314-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb314-3"><a href="#cb314-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the marginal max lik estimators of w and a given standard</span></span>
<span id="cb314-4"><a href="#cb314-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   deviation s, using a bivariate optimization;</span></span>
<span id="cb314-5"><a href="#cb314-5" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb314-6"><a href="#cb314-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  If universalthresh=TRUE, the thresholds will be upper bounded by</span></span>
<span id="cb314-7"><a href="#cb314-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   universal threshold adjusted by standard deviation. The threshold</span></span>
<span id="cb314-8"><a href="#cb314-8" aria-hidden="true" tabindex="-1"></a><span class="co">#   is constrained to lie between 0 and sqrt ( 2 log (n)) *</span></span>
<span id="cb314-9"><a href="#cb314-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   s. Otherwise, threshold can take any nonnegative value;</span></span>
<span id="cb314-10"><a href="#cb314-10" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb314-11"><a href="#cb314-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  If running R, the routine optim is used; in S-PLUS the routine is</span></span>
<span id="cb314-12"><a href="#cb314-12" aria-hidden="true" tabindex="-1"></a><span class="co">#   nlminb.</span></span>
<span id="cb314-13"><a href="#cb314-13" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb314-14"><a href="#cb314-14" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb314-15"><a href="#cb314-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Range for thresholds</span></span>
<span id="cb314-16"><a href="#cb314-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span>(universalthresh) {</span>
<span id="cb314-17"><a href="#cb314-17" aria-hidden="true" tabindex="-1"></a>    thi <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">length</span>(x))) <span class="sc">*</span> s</span>
<span id="cb314-18"><a href="#cb314-18" aria-hidden="true" tabindex="-1"></a>  } <span class="cf">else</span>{</span>
<span id="cb314-19"><a href="#cb314-19" aria-hidden="true" tabindex="-1"></a>    thi <span class="ot">&lt;-</span> <span class="cn">Inf</span></span>
<span id="cb314-20"><a href="#cb314-20" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb314-21"><a href="#cb314-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb314-22"><a href="#cb314-22" aria-hidden="true" tabindex="-1"></a>    tlo <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(s))</span>
<span id="cb314-23"><a href="#cb314-23" aria-hidden="true" tabindex="-1"></a>    lo  <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">0.04</span>)</span>
<span id="cb314-24"><a href="#cb314-24" aria-hidden="true" tabindex="-1"></a>    hi  <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)</span>
<span id="cb314-25"><a href="#cb314-25" aria-hidden="true" tabindex="-1"></a>    startpar  <span class="ot">&lt;-</span>  <span class="fu">c</span>(<span class="fl">0.5</span>,<span class="fl">0.5</span>)</span>
<span id="cb314-26"><a href="#cb314-26" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">exists</span>(<span class="st">"optim"</span>)) {</span>
<span id="cb314-27"><a href="#cb314-27" aria-hidden="true" tabindex="-1"></a>      uu <span class="ot">&lt;-</span> <span class="fu">optim</span>(startpar, negloglik.laplace, <span class="at">method=</span><span class="st">"L-BFGS-B"</span>,</span>
<span id="cb314-28"><a href="#cb314-28" aria-hidden="true" tabindex="-1"></a>                      <span class="at">lower =</span> lo, <span class="at">upper =</span> hi, <span class="at">xx =</span> x, <span class="at">ss =</span> s, <span class="at">thi =</span> thi,</span>
<span id="cb314-29"><a href="#cb314-29" aria-hidden="true" tabindex="-1"></a>                      <span class="at">tlo =</span> tlo)</span>
<span id="cb314-30"><a href="#cb314-30" aria-hidden="true" tabindex="-1"></a>          uu <span class="ot">&lt;-</span> uu<span class="sc">$</span>par</span>
<span id="cb314-31"><a href="#cb314-31" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb314-32"><a href="#cb314-32" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> {</span>
<span id="cb314-33"><a href="#cb314-33" aria-hidden="true" tabindex="-1"></a>          uu <span class="ot">&lt;-</span> <span class="fu">nlminb</span>(startpar, negloglik.laplace, <span class="at">lower =</span> lo,</span>
<span id="cb314-34"><a href="#cb314-34" aria-hidden="true" tabindex="-1"></a>                       <span class="at">upper =</span> hi, <span class="at">xx =</span> x, <span class="at">ss =</span> s, <span class="at">thi =</span> thi, <span class="at">tlo =</span> tlo)</span>
<span id="cb314-35"><a href="#cb314-35" aria-hidden="true" tabindex="-1"></a>          uu <span class="ot">&lt;-</span> uu<span class="sc">$</span>parameters</span>
<span id="cb314-36"><a href="#cb314-36" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb314-37"><a href="#cb314-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb314-38"><a href="#cb314-38" aria-hidden="true" tabindex="-1"></a>    a <span class="ot">&lt;-</span> uu[<span class="dv">2</span>]</span>
<span id="cb314-39"><a href="#cb314-39" aria-hidden="true" tabindex="-1"></a>    wlo <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(thi, s, <span class="at">a =</span> a)</span>
<span id="cb314-40"><a href="#cb314-40" aria-hidden="true" tabindex="-1"></a>    whi <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(tlo, s, <span class="at">a =</span> a)</span>
<span id="cb314-41"><a href="#cb314-41" aria-hidden="true" tabindex="-1"></a>    wlo <span class="ot">&lt;-</span> <span class="fu">max</span>(wlo)</span>
<span id="cb314-42"><a href="#cb314-42" aria-hidden="true" tabindex="-1"></a>    whi <span class="ot">&lt;-</span> <span class="fu">min</span>(whi)</span>
<span id="cb314-43"><a href="#cb314-43" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> uu[<span class="dv">1</span>]<span class="sc">*</span>(whi <span class="sc">-</span> wlo) <span class="sc">+</span> wlo</span>
<span id="cb314-44"><a href="#cb314-44" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">w=</span>w, <span class="at">a=</span>a))</span>
<span id="cb314-45"><a href="#cb314-45" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Pythom</li>
</ul>
<div id="a7131cbd-1729-4ec7-a77d-6906a49c29f2" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb315"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb315-1"><a href="#cb315-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wandafromx(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>], dtype<span class="op">=</span><span class="bu">float</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>{'w': tensor(1., dtype=torch.float64), 'a': 0.41641347740360435}</code></pre>
</div>
</div>
<div id="71589270-c5b6-4144-83e1-6b7108cdfc36" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb317"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb317-1"><a href="#cb317-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wandafromx(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>], dtype<span class="op">=</span><span class="bu">float</span>))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>{'w': tensor(0.846681050730532, dtype=torch.float64), 'a': 0.30010822252477337}</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wandafromx</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>))</span>
<span id="cb319-2"><a href="#cb319-2" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>w</span>
<span id="cb319-3"><a href="#cb319-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb319-4"><a href="#cb319-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-5"><a href="#cb319-5" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>a</span>
<span id="cb319-6"><a href="#cb319-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.4163946</span></span>
<span id="cb319-7"><a href="#cb319-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wandafromx</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>))</span>
<span id="cb319-8"><a href="#cb319-8" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>w</span>
<span id="cb319-9"><a href="#cb319-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.8466808</span></span>
<span id="cb319-10"><a href="#cb319-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-11"><a href="#cb319-11" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>a</span>
<span id="cb319-12"><a href="#cb319-12" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.3001091</span></span></code></pre></div>
</section>
<section id="madmedian-absolute-deviation" class="level1">
<h1>Mad(Median Absolute Deviation)</h1>
<blockquote class="blockquote">
<p>중앙값 절대 편차, 분산이나 퍼진 정도 확인 가능</p>
</blockquote>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="96c83ff1-b6fa-412a-abea-7dd9726c7431" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb320"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb320-1"><a href="#cb320-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.mad(torch.tensor([<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="fl">5.5</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="fl">6.5</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="fl">7.5</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">12</span>, <span class="dv">52</span>, <span class="dv">90</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor(2.965199947357178)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">mad</span>(<span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">3</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">4</span>, <span class="dv">5</span>, <span class="fl">5.5</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="fl">6.5</span>, <span class="dv">7</span>, <span class="dv">7</span>, <span class="fl">7.5</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">12</span>, <span class="dv">52</span>, <span class="dv">90</span>))</span>
<span id="cb322-2"><a href="#cb322-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">2.9652</span></span></code></pre></div>
</section>
<section id="wfromt" class="level1">
<h1>wfromt</h1>
<p>Description</p>
<blockquote class="blockquote">
<p>Given a value or vector of thresholds and sampling standard deviations (sd equals 1 for Cauchy prior), find the mixing weight for which this is(these are) the threshold(s) of the posterior median estimator. If a vector of threshold values is provided, the vector of corresponding weights is returned.</p>
</blockquote>
<p><em>주어진 임계값과 표준편차에 대해, posterior median estimator에서 이 임계값이 나오도록 하는 혼합 가중치를 계산하는 함수가 제공된다.</em></p>
<div id="75b9fdf5-3249-4c43-8b3f-7af41d8a1736" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb323"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb323-1"><a href="#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tt = np.array([2,3,5])</span></span>
<span id="cb323-2"><a href="#cb323-2" aria-hidden="true" tabindex="-1"></a>tt <span class="op">=</span> torch.tensor(<span class="fl">2.14</span>, dtype<span class="op">=</span>torch.float64)</span>
<span id="cb323-3"><a href="#cb323-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb323-4"><a href="#cb323-4" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">'laplace"'</span></span>
<span id="cb323-5"><a href="#cb323-5" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="6376718e-39ce-463a-8286-e9e8466e5226" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb324"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb324-1"><a href="#cb324-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb324-2"><a href="#cb324-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="9e88262a-9e92-4d81-82b0-72b4d420feb7" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb326"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb326-1"><a href="#cb326-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb326-2"><a href="#cb326-2" aria-hidden="true" tabindex="-1"></a>    tma <span class="op">=</span> torch.tensor(tt <span class="op">/</span> s <span class="op">-</span> s <span class="op">*</span> a)</span>
<span id="cb326-3"><a href="#cb326-3" aria-hidden="true" tabindex="-1"></a>    wi <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> torch.<span class="bu">abs</span>(tma)</span>
<span id="cb326-4"><a href="#cb326-4" aria-hidden="true" tabindex="-1"></a>    wi[tma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>] <span class="op">=</span> torch.tensor(norm.cdf(tma[tma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)<span class="op">/</span>norm.pdf(tma[tma <span class="op">&gt;</span> <span class="op">-</span><span class="dv">35</span>], loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb326-5"><a href="#cb326-5" aria-hidden="true" tabindex="-1"></a>    wi <span class="op">=</span> a <span class="op">*</span> s <span class="op">*</span> wi <span class="op">-</span> ebayesthresh_torch.beta_laplace(tt, s, a)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)</code></pre>
</div>
</div>
<div id="25b853af-e0b3-439a-ab71-271949a11bc7" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb328"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb328-1"><a href="#cb328-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb328-2"><a href="#cb328-2" aria-hidden="true" tabindex="-1"></a>    dnz <span class="op">=</span> norm.pdf(tt, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb328-3"><a href="#cb328-3" aria-hidden="true" tabindex="-1"></a>    wi <span class="op">=</span> <span class="dv">1</span> <span class="op">+</span> (torch.tensor(norm.cdf(tt, loc<span class="op">=</span><span class="dv">0</span>, scale<span class="op">=</span><span class="dv">1</span>)) <span class="op">-</span> tt <span class="op">*</span> dnz <span class="op">-</span> <span class="dv">1</span><span class="op">/</span><span class="dv">2</span>) <span class="op">/</span> (torch.sqrt(torch.tensor(torch.pi<span class="op">/</span><span class="dv">2</span>)) <span class="op">*</span> dnz <span class="op">*</span> tt<span class="op">**</span><span class="dv">2</span>)</span>
<span id="cb328-4"><a href="#cb328-4" aria-hidden="true" tabindex="-1"></a>    wi[<span class="op">~</span>torch.isfinite(wi)] <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="a6d9bc89-e3a6-4a0e-9dbb-df6eaa23fce1" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb329"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb329-1"><a href="#cb329-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="op">/</span> wi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor(0.312639310177825, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R코드</li>
</ul>
<div class="sourceCode" id="cb331"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb331-1"><a href="#cb331-1" aria-hidden="true" tabindex="-1"></a>wfromt <span class="ot">&lt;-</span> <span class="cf">function</span>(tt, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb331-2"><a href="#cb331-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb331-3"><a href="#cb331-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#  Find the weight that has posterior median threshold tt, </span></span>
<span id="cb331-4"><a href="#cb331-4" aria-hidden="true" tabindex="-1"></a>  <span class="co">#   given s (sd) and a.</span></span>
<span id="cb331-5"><a href="#cb331-5" aria-hidden="true" tabindex="-1"></a>  <span class="co">#</span></span>
<span id="cb331-6"><a href="#cb331-6" aria-hidden="true" tabindex="-1"></a>pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb331-7"><a href="#cb331-7" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>){</span>
<span id="cb331-8"><a href="#cb331-8" aria-hidden="true" tabindex="-1"></a>  tma <span class="ot">&lt;-</span> tt<span class="sc">/</span>s <span class="sc">-</span> s<span class="sc">*</span>a</span>
<span id="cb331-9"><a href="#cb331-9" aria-hidden="true" tabindex="-1"></a>  wi <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="fu">abs</span>(tma)</span>
<span id="cb331-10"><a href="#cb331-10" aria-hidden="true" tabindex="-1"></a>  wi[tma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>] <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(tma[tma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>])<span class="sc">/</span><span class="fu">dnorm</span>(tma[tma <span class="sc">&gt;</span> <span class="sc">-</span><span class="dv">35</span>])</span>
<span id="cb331-11"><a href="#cb331-11" aria-hidden="true" tabindex="-1"></a>  wi <span class="ot">&lt;-</span> a <span class="sc">*</span> s <span class="sc">*</span> wi <span class="sc">-</span> <span class="fu">beta.laplace</span>(tt, s, a)</span>
<span id="cb331-12"><a href="#cb331-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb331-13"><a href="#cb331-13" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>) {</span>
<span id="cb331-14"><a href="#cb331-14" aria-hidden="true" tabindex="-1"></a>  dnz <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(tt)</span>
<span id="cb331-15"><a href="#cb331-15" aria-hidden="true" tabindex="-1"></a>  wi <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> (<span class="fu">pnorm</span>(tt) <span class="sc">-</span> tt <span class="sc">*</span> dnz <span class="sc">-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span>)<span class="sc">/</span></span>
<span id="cb331-16"><a href="#cb331-16" aria-hidden="true" tabindex="-1"></a>    (<span class="fu">sqrt</span>(pi<span class="sc">/</span><span class="dv">2</span>) <span class="sc">*</span> dnz <span class="sc">*</span> tt<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb331-17"><a href="#cb331-17" aria-hidden="true" tabindex="-1"></a>  wi[<span class="sc">!</span><span class="fu">is.finite</span>(wi)] <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb331-18"><a href="#cb331-18" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb331-19"><a href="#cb331-19" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">/</span>wi</span>
<span id="cb331-20"><a href="#cb331-20" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="73b44642-ca91-4f3a-a22b-1e8e52944e63" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb332"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb332-1"><a href="#cb332-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wfromt(torch.tensor([<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>]),prior<span class="op">=</span><span class="st">'cachy'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([4.229634032914113e-01, 9.337993365820978e-02, 9.315908844505263e-05],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="fb88ee73-ae38-4d45-8644-261900e07228" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb334"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb334-1"><a href="#cb334-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wfromt(torch.tensor(<span class="dv">2</span>),prior<span class="op">=</span><span class="st">'cachy'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor(0.422963400115950, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="7eb4748a-a1f0-4865-afeb-020e91bcfa4c" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb336"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb336-1"><a href="#cb336-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wfromt(torch.tensor(<span class="dv">2</span>),prior<span class="op">=</span><span class="st">'laplace'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="18">
<pre><code>tensor(0.368633767549335, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb338"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb338-1"><a href="#cb338-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wfromt</span>(<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>),<span class="at">prior=</span><span class="st">'cachy'</span>)</span>
<span id="cb338-2"><a href="#cb338-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">4.229634e-01</span> <span class="fl">9.337993e-02</span> <span class="fl">9.315909e-05</span></span>
<span id="cb338-3"><a href="#cb338-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wfromt</span>(<span class="dv">2</span>,<span class="at">prior=</span><span class="st">'cachy'</span>)</span>
<span id="cb338-4"><a href="#cb338-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.4229634</span></span>
<span id="cb338-5"><a href="#cb338-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wfromt</span>(<span class="dv">2</span>,<span class="at">prior=</span><span class="st">'laplace'</span>)</span>
<span id="cb338-6"><a href="#cb338-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.3686338</span></span></code></pre></div>
</section>
<section id="wfromx" class="level1">
<h1>wfromx</h1>
<p>Description</p>
<blockquote class="blockquote">
<p>The weight is found by marginal maximum likelihood. The search is over weights corresponding to threshold <span class="math inline">\(t_i\)</span> in the range <span class="math inline">\([0, s_i \sqrt{2 log n}]\)</span> if universalthresh=TRUE, where n is the length of the data vector and <span class="math inline">\((s_1, ..., s_n\)</span>) (<span class="math inline">\(s_i\)</span> is <span class="math inline">\(1\)</span> for Cauchy prior) is the vector of sampling standard deviation of data (<span class="math inline">\(x_1, ..., x_n\)</span>); otherwise, the search is over <span class="math inline">\([0, 1]\)</span>. The search is by binary search for a solution to the equation <span class="math inline">\(S(w) = 0\)</span>, where <span class="math inline">\(S\)</span> is the derivative of the log likelihood. The binary search is on a logarithmic scale in <span class="math inline">\(w\)</span>. If the Laplace prior is used, the scale parameter is fixed at the value given for <span class="math inline">\(a\)</span>, and defaults to <span class="math inline">\(0.5\)</span> if no value is provided. To estimate a as well as <span class="math inline">\(w\)</span> by marginal maximum likelihood, use the routine wandafromx.</p>
</blockquote>
<blockquote class="blockquote">
<p>Suppose the vector <span class="math inline">\((x_1, \cdots, x_n)\)</span> is such that <span class="math inline">\(x_i\)</span> is drawn independently from a normal distribution with mean <span class="math inline">\(\theta_i\)</span> and standard deviation <span class="math inline">\(s_i\)</span> (<span class="math inline">\(s_i\)</span> equals <span class="math inline">\(1\)</span> for Cauchy prior). The prior distribution of the <span class="math inline">\(\theta_i\)</span> is a mixture with probability <span class="math inline">\(1 − w\)</span> of zero and probability <span class="math inline">\(w\)</span> of a given symmetric heavy-tailed distribution. This routine finds the marginal maximum likelihood estimate of the parameter <span class="math inline">\(w\)</span>.</p>
</blockquote>
<p><em>주어진 정규 분포 데이터에 대해 <span class="math inline">\(\theta_𝑖\)</span>의 사전 분포가 주어진 상황에서, 모수 <span class="math inline">\(w\)</span>의 최대우도 추정치를 계산하는 방법을 제공한다</em></p>
<div id="d910390e-7884-4f2d-824d-64a7ab927ae6" class="cell">
<div class="sourceCode cell-code" id="cb339"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb339-1"><a href="#cb339-1" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> torch.tensor([<span class="dv">0</span>]<span class="op">*</span><span class="dv">90</span> <span class="op">+</span> [<span class="dv">5</span>]<span class="op">*</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.<span class="bu">float</span>)</span>
<span id="cb339-2"><a href="#cb339-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.normal(mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span>s)</span>
<span id="cb339-3"><a href="#cb339-3" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">"cauchy"</span></span>
<span id="cb339-4"><a href="#cb339-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb339-5"><a href="#cb339-5" aria-hidden="true" tabindex="-1"></a>universalthresh <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<div id="e819cb92-4080-4fd4-813e-bc3304909bdf" class="cell">
<div class="sourceCode cell-code" id="cb340"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb340-1"><a href="#cb340-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb340-2"><a href="#cb340-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="96">
<pre><code>'c'</code></pre>
</div>
</div>
<div id="ff558a6d-ecb5-4760-af49-56c3d14f8b02" class="cell">
<div class="sourceCode cell-code" id="cb342"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb342-1"><a href="#cb342-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb342-2"><a href="#cb342-2" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="8b919edc-925a-45d4-af7e-8eb57c5dc8b8" class="cell">
<div class="sourceCode cell-code" id="cb343"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb343-1"><a href="#cb343-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> universalthresh:</span>
<span id="cb343-2"><a href="#cb343-2" aria-hidden="true" tabindex="-1"></a>    tuniv <span class="op">=</span> torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(<span class="bu">len</span>(x)))) <span class="op">*</span> s</span>
<span id="cb343-3"><a href="#cb343-3" aria-hidden="true" tabindex="-1"></a>    wlo <span class="op">=</span> ebayesthresh_torch.wfromt(tuniv, s, prior, a)</span>
<span id="cb343-4"><a href="#cb343-4" aria-hidden="true" tabindex="-1"></a>    wlo <span class="op">=</span> torch.<span class="bu">max</span>(wlo)</span>
<span id="cb343-5"><a href="#cb343-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb343-6"><a href="#cb343-6" aria-hidden="true" tabindex="-1"></a>    wlo <span class="op">=</span> <span class="dv">0</span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="1ed46a55-1872-407f-8947-a1ab3ac89aae" class="cell">
<div class="sourceCode cell-code" id="cb345"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb345-1"><a href="#cb345-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb345-2"><a href="#cb345-2" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_laplace(x, s, a)</span>
<span id="cb345-3"><a href="#cb345-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb345-4"><a href="#cb345-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_cauchy(x)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x,dtype=torch.float64)</code></pre>
</div>
</div>
<div id="40b14a37-93b6-4ea9-8305-c74a09f5eff0" class="cell">
<div class="sourceCode cell-code" id="cb347"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb347-1"><a href="#cb347-1" aria-hidden="true" tabindex="-1"></a>whi <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb347-2"><a href="#cb347-2" aria-hidden="true" tabindex="-1"></a>beta <span class="op">=</span> torch.minimum(beta, torch.tensor(<span class="fl">1e20</span>))</span>
<span id="cb347-3"><a href="#cb347-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb347-4"><a href="#cb347-4" aria-hidden="true" tabindex="-1"></a>shi <span class="op">=</span> torch.<span class="bu">sum</span>(beta <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> beta))</span></code></pre></div>
</div>
<div id="bd425b93-84eb-4b74-843c-80b07ea8a3ec" class="cell">
<div class="sourceCode cell-code" id="cb348"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb348-1"><a href="#cb348-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> shi <span class="op">&gt;=</span> <span class="dv">0</span>:</span>
<span id="cb348-2"><a href="#cb348-2" aria-hidden="true" tabindex="-1"></a>    shi <span class="op">=</span>  <span class="dv">1</span></span></code></pre></div>
</div>
<div id="2bda427d-b7f4-4f17-95ca-e2b8c0b421c5" class="cell">
<div class="sourceCode cell-code" id="cb349"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb349-1"><a href="#cb349-1" aria-hidden="true" tabindex="-1"></a>slo <span class="op">=</span> torch.<span class="bu">sum</span>(beta <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> wlo <span class="op">*</span> beta))</span></code></pre></div>
</div>
<div id="bcd6c356-619f-48fb-a0c6-2e9db261aadd" class="cell">
<div class="sourceCode cell-code" id="cb350"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb350-1"><a href="#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> slo <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb350-2"><a href="#cb350-2" aria-hidden="true" tabindex="-1"></a>    slo <span class="op">=</span> wlo</span></code></pre></div>
</div>
<div id="e9b8bf5f-152e-428f-9d38-e5be0cc34ba1" class="cell">
<div class="sourceCode cell-code" id="cb351"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb351-1"><a href="#cb351-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">31</span>):</span>
<span id="cb351-2"><a href="#cb351-2" aria-hidden="true" tabindex="-1"></a>    wmid <span class="op">=</span> torch.sqrt(wlo <span class="op">*</span> whi)</span>
<span id="cb351-3"><a href="#cb351-3" aria-hidden="true" tabindex="-1"></a>    smid <span class="op">=</span> torch.<span class="bu">sum</span>(beta <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> wmid <span class="op">*</span> beta))</span>
<span id="cb351-4"><a href="#cb351-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> smid <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb351-5"><a href="#cb351-5" aria-hidden="true" tabindex="-1"></a>        smid <span class="op">=</span> wmid</span>
<span id="cb351-6"><a href="#cb351-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> smid <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb351-7"><a href="#cb351-7" aria-hidden="true" tabindex="-1"></a>        wlo <span class="op">=</span> wmid</span>
<span id="cb351-8"><a href="#cb351-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb351-9"><a href="#cb351-9" aria-hidden="true" tabindex="-1"></a>        whi <span class="op">=</span> wmid</span></code></pre></div>
</div>
<div id="1a967f88-bb8d-441d-97d8-3fd021c36eb9" class="cell">
<div class="sourceCode cell-code" id="cb352"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb352-1"><a href="#cb352-1" aria-hidden="true" tabindex="-1"></a>torch.sqrt(wlo <span class="op">*</span> whi)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="110">
<pre><code>tensor(0.146079566903307, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R코드</li>
</ul>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="#cb354-1" aria-hidden="true" tabindex="-1"></a>wfromx <span class="ot">&lt;-</span> <span class="cf">function</span> (x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>,</span>
<span id="cb354-2"><a href="#cb354-2" aria-hidden="true" tabindex="-1"></a>                    <span class="at">universalthresh =</span> <span class="cn">TRUE</span>) {</span>
<span id="cb354-3"><a href="#cb354-3" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb354-4"><a href="#cb354-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  Given the vector of data x and s (sd),</span></span>
<span id="cb354-5"><a href="#cb354-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   find the value of w that zeroes S(w) in the</span></span>
<span id="cb354-6"><a href="#cb354-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   range by successive bisection, carrying out nits harmonic bisections</span></span>
<span id="cb354-7"><a href="#cb354-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   of the original interval between wlo and 1.  </span></span>
<span id="cb354-8"><a href="#cb354-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  </span></span>
<span id="cb354-9"><a href="#cb354-9" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb354-10"><a href="#cb354-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb354-11"><a href="#cb354-11" aria-hidden="true" tabindex="-1"></a>          s <span class="ot">=</span> <span class="dv">1</span></span>
<span id="cb354-12"><a href="#cb354-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(universalthresh) {</span>
<span id="cb354-13"><a href="#cb354-13" aria-hidden="true" tabindex="-1"></a>          tuniv <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">length</span>(x))) <span class="sc">*</span> s</span>
<span id="cb354-14"><a href="#cb354-14" aria-hidden="true" tabindex="-1"></a>          wlo <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(tuniv, s, prior, a)</span>
<span id="cb354-15"><a href="#cb354-15" aria-hidden="true" tabindex="-1"></a>          wlo <span class="ot">&lt;-</span> <span class="fu">max</span>(wlo)</span>
<span id="cb354-16"><a href="#cb354-16" aria-hidden="true" tabindex="-1"></a>    } <span class="cf">else</span> </span>
<span id="cb354-17"><a href="#cb354-17" aria-hidden="true" tabindex="-1"></a>          wlo <span class="ot">=</span> <span class="dv">0</span></span>
<span id="cb354-18"><a href="#cb354-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>)</span>
<span id="cb354-19"><a href="#cb354-19" aria-hidden="true" tabindex="-1"></a>      beta <span class="ot">&lt;-</span> <span class="fu">beta.laplace</span>(x, s, a)</span>
<span id="cb354-20"><a href="#cb354-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb354-21"><a href="#cb354-21" aria-hidden="true" tabindex="-1"></a>      beta <span class="ot">&lt;-</span> <span class="fu">beta.cauchy</span>(x)</span>
<span id="cb354-22"><a href="#cb354-22" aria-hidden="true" tabindex="-1"></a>    whi  <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb354-23"><a href="#cb354-23" aria-hidden="true" tabindex="-1"></a>    beta <span class="ot">&lt;-</span> <span class="fu">pmin</span>(beta, <span class="fl">1e20</span>) </span>
<span id="cb354-24"><a href="#cb354-24" aria-hidden="true" tabindex="-1"></a>    shi  <span class="ot">&lt;-</span> <span class="fu">sum</span>(beta<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> beta))</span>
<span id="cb354-25"><a href="#cb354-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(shi <span class="sc">&gt;=</span> <span class="dv">0</span>)</span>
<span id="cb354-26"><a href="#cb354-26" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(<span class="dv">1</span>)</span>
<span id="cb354-27"><a href="#cb354-27" aria-hidden="true" tabindex="-1"></a>    slo <span class="ot">&lt;-</span> <span class="fu">sum</span>(beta<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> wlo <span class="sc">*</span> beta))</span>
<span id="cb354-28"><a href="#cb354-28" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(slo <span class="sc">&lt;=</span> <span class="dv">0</span>)</span>
<span id="cb354-29"><a href="#cb354-29" aria-hidden="true" tabindex="-1"></a>      <span class="fu">return</span>(wlo)</span>
<span id="cb354-30"><a href="#cb354-30" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>)) {</span>
<span id="cb354-31"><a href="#cb354-31" aria-hidden="true" tabindex="-1"></a>      wmid <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(wlo <span class="sc">*</span> whi)</span>
<span id="cb354-32"><a href="#cb354-32" aria-hidden="true" tabindex="-1"></a>      smid <span class="ot">&lt;-</span> <span class="fu">sum</span>(beta<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> wmid <span class="sc">*</span> beta))</span>
<span id="cb354-33"><a href="#cb354-33" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(smid <span class="sc">==</span> <span class="dv">0</span>)</span>
<span id="cb354-34"><a href="#cb354-34" aria-hidden="true" tabindex="-1"></a>        <span class="fu">return</span>(wmid)</span>
<span id="cb354-35"><a href="#cb354-35" aria-hidden="true" tabindex="-1"></a>      <span class="cf">if</span>(smid <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb354-36"><a href="#cb354-36" aria-hidden="true" tabindex="-1"></a>        wlo <span class="ot">&lt;-</span> wmid</span>
<span id="cb354-37"><a href="#cb354-37" aria-hidden="true" tabindex="-1"></a>      <span class="cf">else</span></span>
<span id="cb354-38"><a href="#cb354-38" aria-hidden="true" tabindex="-1"></a>        whi <span class="ot">&lt;-</span> wmid</span>
<span id="cb354-39"><a href="#cb354-39" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb354-40"><a href="#cb354-40" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">sqrt</span>(wlo <span class="sc">*</span> whi))</span>
<span id="cb354-41"><a href="#cb354-41" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="fc57fdd3-8daf-4885-8e93-6d2b0a9a2bda" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb355"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb355-1"><a href="#cb355-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wfromx(x <span class="op">=</span> torch.normal(mean<span class="op">=</span><span class="dv">0</span>, std<span class="op">=</span>torch.tensor([<span class="dv">0</span>]<span class="op">*</span><span class="dv">90</span> <span class="op">+</span> [<span class="dv">5</span>]<span class="op">*</span><span class="dv">10</span>, dtype<span class="op">=</span>torch.<span class="bu">float</span>)), prior <span class="op">=</span> <span class="st">"cauchy"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor(0.123532880018559, dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wfromx</span>(<span class="at">x =</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">s =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">0</span>,<span class="dv">90</span>),<span class="fu">rep</span>(<span class="dv">5</span>,<span class="dv">10</span>))), <span class="at">prior =</span> <span class="st">"cauchy"</span>)</span>
<span id="cb357-2"><a href="#cb357-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.116067</span></span></code></pre></div>
</section>
<section id="wmonfromx" class="level1">
<h1>wmonfromx</h1>
<blockquote class="blockquote">
<p>Given a vector of data, find the marginal maximum likelihood choice of weight sequence subject to the constraints that the weights are monotone decreasing</p>
</blockquote>
<p><em>데이터에 대해 가중치 시퀀스를 선택하는 과정에서 조건이 주어지는데, 이 가중치 시퀀스는 각각의 가중치 값이 단조 감소해야 하며, 주어진 데이터에 대한 최대 우도를 갖도록 선택되어야 함.</em></p>
<div id="3aa2177c-5d49-41f7-8de1-03ad794876fb" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb358"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb358-1"><a href="#cb358-1" aria-hidden="true" tabindex="-1"></a>xd <span class="op">=</span> torch.randn(<span class="dv">10</span>)</span>
<span id="cb358-2"><a href="#cb358-2" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">"laplace"</span></span>
<span id="cb358-3"><a href="#cb358-3" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb358-4"><a href="#cb358-4" aria-hidden="true" tabindex="-1"></a>tol <span class="op">=</span> <span class="fl">1e-08</span></span>
<span id="cb358-5"><a href="#cb358-5" aria-hidden="true" tabindex="-1"></a>maxits <span class="op">=</span> <span class="dv">20</span></span></code></pre></div>
</div>
<div id="001fbe8c-ff43-4a1b-9dec-37f68d8c8ec2" class="cell">
<div class="sourceCode cell-code" id="cb359"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb359-1"><a href="#cb359-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb359-2"><a href="#cb359-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="b5465c74-ce75-4766-8336-3cdac24f412b" class="cell">
<div class="sourceCode cell-code" id="cb361"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb361-1"><a href="#cb361-1" aria-hidden="true" tabindex="-1"></a>nx <span class="op">=</span> <span class="bu">len</span>(xd)</span>
<span id="cb361-2"><a href="#cb361-2" aria-hidden="true" tabindex="-1"></a>nx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>10</code></pre>
</div>
</div>
<div id="432b7102-4761-4e74-92fe-cb3fdf506c66" class="cell">
<div class="sourceCode cell-code" id="cb363"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb363-1"><a href="#cb363-1" aria-hidden="true" tabindex="-1"></a>wmin <span class="op">=</span> ebayesthresh_torch.wfromt(torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(<span class="bu">len</span>(xd)))), prior<span class="op">=</span>prior, a<span class="op">=</span>a)</span>
<span id="cb363-2"><a href="#cb363-2" aria-hidden="true" tabindex="-1"></a>wmin</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="34">
<pre><code>tensor(0.310296798704717, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="efbff82a-6850-4c50-bab5-eca5c437e9cd" class="cell">
<div class="sourceCode cell-code" id="cb366"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb366-1"><a href="#cb366-1" aria-hidden="true" tabindex="-1"></a>winit <span class="op">=</span> torch.tensor(<span class="dv">1</span>)</span>
<span id="cb366-2"><a href="#cb366-2" aria-hidden="true" tabindex="-1"></a>winit</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor(1)</code></pre>
</div>
</div>
<div id="212aeb05-8200-4fa8-acb2-a40d05bd2764" class="cell">
<div class="sourceCode cell-code" id="cb368"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb368-1"><a href="#cb368-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb368-2"><a href="#cb368-2" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_laplace(xd, a<span class="op">=</span>a)</span>
<span id="cb368-3"><a href="#cb368-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb368-4"><a href="#cb368-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_cauchy(xd)</span></code></pre></div>
</div>
<div id="413dc397-1929-426c-b009-5aa31042e5b2" class="cell">
<div class="sourceCode cell-code" id="cb369"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb369-1"><a href="#cb369-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> winit.repeat_interleave(<span class="bu">len</span>(beta))</span>
<span id="cb369-2"><a href="#cb369-2" aria-hidden="true" tabindex="-1"></a>w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])</code></pre>
</div>
</div>
<div id="462512a3-e114-4c03-bf83-28abd61791ac" class="cell">
<div class="sourceCode cell-code" id="cb371"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb371-1"><a href="#cb371-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(maxits):</span>
<span id="cb371-2"><a href="#cb371-2" aria-hidden="true" tabindex="-1"></a>    aa <span class="op">=</span> w <span class="op">+</span> <span class="dv">1</span> <span class="op">/</span> beta</span>
<span id="cb371-3"><a href="#cb371-3" aria-hidden="true" tabindex="-1"></a>    ps <span class="op">=</span> w <span class="op">+</span> aa</span>
<span id="cb371-4"><a href="#cb371-4" aria-hidden="true" tabindex="-1"></a>    ww <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> aa <span class="op">**</span> <span class="dv">2</span></span>
<span id="cb371-5"><a href="#cb371-5" aria-hidden="true" tabindex="-1"></a>    wnew <span class="op">=</span> torch.tensor(ebayesthresh_torch.isotone(ps, ww, increasing<span class="op">=</span><span class="va">False</span>))</span>
<span id="cb371-6"><a href="#cb371-6" aria-hidden="true" tabindex="-1"></a>    wnew <span class="op">=</span> torch.maximum(wmin, wnew)</span>
<span id="cb371-7"><a href="#cb371-7" aria-hidden="true" tabindex="-1"></a>    wnew <span class="op">=</span> torch.minimum(torch.tensor(<span class="dv">1</span>), wnew)</span>
<span id="cb371-8"><a href="#cb371-8" aria-hidden="true" tabindex="-1"></a>    zinc <span class="op">=</span> torch.<span class="bu">max</span>(torch.<span class="bu">abs</span>(torch.diff(wnew)))</span>
<span id="cb371-9"><a href="#cb371-9" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> wnew</span>
<span id="cb371-10"><a href="#cb371-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if zinc &lt; tol:</span></span>
<span id="cb371-11"><a href="#cb371-11" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     return w</span></span></code></pre></div>
</div>
<div id="2496f0ea-5005-467b-9e0a-0669d7d2eb28" class="cell" data-execution_count="176">
<div class="sourceCode cell-code" id="cb372"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb372-1"><a href="#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="co"># warnings.filterwarnings("More iterations required to achieve convergence")</span></span></code></pre></div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="#cb373-1" aria-hidden="true" tabindex="-1"></a>wmonfromx <span class="ot">&lt;-</span> <span class="cf">function</span> (xd, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>,</span>
<span id="cb373-2"><a href="#cb373-2" aria-hidden="true" tabindex="-1"></a>                       <span class="at">tol =</span> <span class="fl">1e-08</span>, <span class="at">maxits =</span> <span class="dv">20</span>) {</span>
<span id="cb373-3"><a href="#cb373-3" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb373-4"><a href="#cb373-4" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the monotone marginal maximum likelihood estimate of the</span></span>
<span id="cb373-5"><a href="#cb373-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   mixing weights for the Laplace prior with parameter a.  It is</span></span>
<span id="cb373-6"><a href="#cb373-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   assumed that the noise variance is equal to one.</span></span>
<span id="cb373-7"><a href="#cb373-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb373-8"><a href="#cb373-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the beta values and the minimum weight</span></span>
<span id="cb373-9"><a href="#cb373-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  </span></span>
<span id="cb373-10"><a href="#cb373-10" aria-hidden="true" tabindex="-1"></a><span class="co">#  Current version allows for standard deviation of 1 only.</span></span>
<span id="cb373-11"><a href="#cb373-11" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb373-12"><a href="#cb373-12" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb373-13"><a href="#cb373-13" aria-hidden="true" tabindex="-1"></a>    nx <span class="ot">&lt;-</span> <span class="fu">length</span>(xd)</span>
<span id="cb373-14"><a href="#cb373-14" aria-hidden="true" tabindex="-1"></a>    wmin <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(<span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">length</span>(xd))), <span class="at">prior=</span>prior, <span class="at">a=</span>a)</span>
<span id="cb373-15"><a href="#cb373-15" aria-hidden="true" tabindex="-1"></a>    winit <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb373-16"><a href="#cb373-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>)</span>
<span id="cb373-17"><a href="#cb373-17" aria-hidden="true" tabindex="-1"></a>      beta <span class="ot">&lt;-</span> <span class="fu">beta.laplace</span>(xd, <span class="at">a=</span>a)</span>
<span id="cb373-18"><a href="#cb373-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb373-19"><a href="#cb373-19" aria-hidden="true" tabindex="-1"></a>           beta <span class="ot">&lt;-</span> <span class="fu">beta.cauchy</span>(xd)</span>
<span id="cb373-20"><a href="#cb373-20" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb373-21"><a href="#cb373-21" aria-hidden="true" tabindex="-1"></a><span class="co">#   now conduct iterated weighted least squares isotone regression</span></span>
<span id="cb373-22"><a href="#cb373-22" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb373-23"><a href="#cb373-23" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> <span class="fu">rep</span>(winit, <span class="fu">length</span>(beta))</span>
<span id="cb373-24"><a href="#cb373-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span>maxits)) {</span>
<span id="cb373-25"><a href="#cb373-25" aria-hidden="true" tabindex="-1"></a>        aa <span class="ot">&lt;-</span> w <span class="sc">+</span> <span class="dv">1</span><span class="sc">/</span>beta</span>
<span id="cb373-26"><a href="#cb373-26" aria-hidden="true" tabindex="-1"></a>        ps <span class="ot">&lt;-</span> w <span class="sc">+</span> aa</span>
<span id="cb373-27"><a href="#cb373-27" aria-hidden="true" tabindex="-1"></a>        ww <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>aa<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb373-28"><a href="#cb373-28" aria-hidden="true" tabindex="-1"></a>        wnew <span class="ot">&lt;-</span> <span class="fu">isotone</span>(ps, ww, <span class="at">increasing =</span> <span class="cn">FALSE</span>)</span>
<span id="cb373-29"><a href="#cb373-29" aria-hidden="true" tabindex="-1"></a>        wnew <span class="ot">&lt;-</span> <span class="fu">pmax</span>(wmin, wnew)</span>
<span id="cb373-30"><a href="#cb373-30" aria-hidden="true" tabindex="-1"></a>        wnew <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">1</span>, wnew)</span>
<span id="cb373-31"><a href="#cb373-31" aria-hidden="true" tabindex="-1"></a>        zinc <span class="ot">&lt;-</span> <span class="fu">max</span>(<span class="fu">abs</span>(<span class="fu">range</span>(wnew <span class="sc">-</span> w)))</span>
<span id="cb373-32"><a href="#cb373-32" aria-hidden="true" tabindex="-1"></a>        w <span class="ot">&lt;-</span> wnew</span>
<span id="cb373-33"><a href="#cb373-33" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(zinc <span class="sc">&lt;</span> tol)</span>
<span id="cb373-34"><a href="#cb373-34" aria-hidden="true" tabindex="-1"></a>          <span class="fu">return</span>(w)</span>
<span id="cb373-35"><a href="#cb373-35" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb373-36"><a href="#cb373-36" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb373-37"><a href="#cb373-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">warning</span>(<span class="st">"More iterations required to achieve convergence"</span>)</span>
<span id="cb373-38"><a href="#cb373-38" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(w)</span>
<span id="cb373-39"><a href="#cb373-39" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="97c98c4a-4cd9-454c-877d-5f6a381ca9c4" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb374"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb374-1"><a href="#cb374-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wmonfromx(xd <span class="op">=</span> torch.randn(<span class="dv">10</span>), prior <span class="op">=</span> <span class="st">"laplace"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor([0.310296803712845, 0.310296803712845, 0.310296803712845,
        0.310296803712845, 0.310296803712845, 0.310296803712845,
        0.310296803712845, 0.310296803712845, 0.310296803712845,
        0.310296803712845])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="#cb376-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">wmonfromx</span>(xd <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">10</span>,<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">prior =</span> <span class="st">"laplace"</span>)</span>
<span id="cb376-2"><a href="#cb376-2" aria-hidden="true" tabindex="-1"></a> [<span class="dv">1</span>] <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span> <span class="fl">0.3102968</span></span></code></pre></div>
<blockquote class="blockquote">
<p>wmonfromx(xd=rnorm(5, s = 1), prior = “laplace”, a = 0.5, tol = 1e-08, maxits = 20) [1] 0.9363989 0.9363989 0.9363989 0.4522184 0.4522184</p>
</blockquote>
</section>
<section id="vecbinsolv" class="level1">
<h1>vecbinsolv</h1>
<div id="30bd5963-4e82-45fe-ae69-1801eef6c02c" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb377"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb377-1"><a href="#cb377-1" aria-hidden="true" tabindex="-1"></a>zf <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>])</span>
<span id="cb377-2"><a href="#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="co"># zf = 0</span></span>
<span id="cb377-3"><a href="#cb377-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fun(t, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb377-4"><a href="#cb377-4" aria-hidden="true" tabindex="-1"></a>    c <span class="op">=</span> kwargs.get(<span class="st">'c'</span>, <span class="dv">0</span>)</span>
<span id="cb377-5"><a href="#cb377-5" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.tensor(t, dtype<span class="op">=</span>torch.float32)  </span>
<span id="cb377-6"><a href="#cb377-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t<span class="op">**</span><span class="dv">2</span> <span class="op">+</span> c</span>
<span id="cb377-7"><a href="#cb377-7" aria-hidden="true" tabindex="-1"></a>tlo <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb377-8"><a href="#cb377-8" aria-hidden="true" tabindex="-1"></a>thi <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb377-9"><a href="#cb377-9" aria-hidden="true" tabindex="-1"></a>nits <span class="op">=</span> <span class="dv">30</span></span></code></pre></div>
</div>
<div id="48e8e0d2-5612-4a41-9e85-4e8981f48d16" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb378"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb378-1"><a href="#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">isinstance</span>(zf, (<span class="bu">int</span>, <span class="bu">float</span>, <span class="bu">str</span>, <span class="bu">bool</span>)) :</span>
<span id="cb378-2"><a href="#cb378-2" aria-hidden="true" tabindex="-1"></a>        nz <span class="op">=</span> <span class="bu">len</span>(<span class="bu">str</span>(zf))</span>
<span id="cb378-3"><a href="#cb378-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span> : nz <span class="op">=</span> zf.shape[<span class="dv">0</span>]</span></code></pre></div>
</div>
<div id="a92d20b3-4bcd-4217-bc67-e2043f96f32e" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb379"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb379-1"><a href="#cb379-1" aria-hidden="true" tabindex="-1"></a>tlo <span class="op">=</span> torch.full((nz,), tlo, dtype<span class="op">=</span>torch.float32)</span></code></pre></div>
</div>
<div id="f47ba0a9-6b4c-48cf-8ca4-dfa3eee0de9c" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb380"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb380-1"><a href="#cb380-1" aria-hidden="true" tabindex="-1"></a>tlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>tensor([0., 0., 0.])</code></pre>
</div>
</div>
<div id="94f3af35-6844-465d-a213-dd7814bf0583" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb382"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb382-1"><a href="#cb382-1" aria-hidden="true" tabindex="-1"></a>thi <span class="op">=</span> torch.full((nz,), thi, dtype<span class="op">=</span>torch.float32)</span></code></pre></div>
</div>
<div id="cb8ffa82-05d9-4bed-8880-77ff50cba9ce" class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb383"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb383-1"><a href="#cb383-1" aria-hidden="true" tabindex="-1"></a>thi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>tensor([10., 10., 10.])</code></pre>
</div>
</div>
<div id="86d25047-bc4b-4f0b-92d5-806ef53ade90" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb385"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb385-1"><a href="#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> tlo.numel() <span class="op">!=</span> nz:</span>
<span id="cb385-2"><a href="#cb385-2" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Lower constraint has to be homogeneous or have the same length as the number of functions."</span>)</span>
<span id="cb385-3"><a href="#cb385-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> thi.numel() <span class="op">!=</span> nz:</span>
<span id="cb385-4"><a href="#cb385-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">raise</span> <span class="pp">ValueError</span>(<span class="st">"Upper constraint has to be homogeneous or have the same length as the number of functions."</span>)</span></code></pre></div>
</div>
<div id="28a3e935-335d-4005-bba2-6d73d9dccf62" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb386"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb386-1"><a href="#cb386-1" aria-hidden="true" tabindex="-1"></a>c<span class="op">=</span><span class="dv">2</span></span>
<span id="cb386-2"><a href="#cb386-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb386-3"><a href="#cb386-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(nits):</span>
<span id="cb386-4"><a href="#cb386-4" aria-hidden="true" tabindex="-1"></a>    tmid <span class="op">=</span> (tlo <span class="op">+</span> thi) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb386-5"><a href="#cb386-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> fun <span class="op">==</span> ebayesthresh_torch.cauchy_threshzero:</span>
<span id="cb386-6"><a href="#cb386-6" aria-hidden="true" tabindex="-1"></a>        fmid <span class="op">=</span> fun(tmid, w<span class="op">=</span>w)</span>
<span id="cb386-7"><a href="#cb386-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> fun <span class="op">==</span> ebayesthresh_torch.laplace_threshzero:</span>
<span id="cb386-8"><a href="#cb386-8" aria-hidden="true" tabindex="-1"></a>        fmid <span class="op">=</span> fun(tmid, s<span class="op">=</span>s,w<span class="op">=</span>w,a<span class="op">=</span>a)</span>
<span id="cb386-9"><a href="#cb386-9" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> fun <span class="op">==</span> ebayesthresh_torch.beta_cauchy:</span>
<span id="cb386-10"><a href="#cb386-10" aria-hidden="true" tabindex="-1"></a>        fmid <span class="op">=</span> fun(tmid)</span>
<span id="cb386-11"><a href="#cb386-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> fun <span class="op">==</span> ebayesthresh_torch.beta_laplace:</span>
<span id="cb386-12"><a href="#cb386-12" aria-hidden="true" tabindex="-1"></a>        fmid <span class="op">=</span> fun(tmid, z<span class="op">=</span>z,w<span class="op">=</span>w)</span>
<span id="cb386-13"><a href="#cb386-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb386-14"><a href="#cb386-14" aria-hidden="true" tabindex="-1"></a>        fmid <span class="op">=</span> fun(tmid)</span>
<span id="cb386-15"><a href="#cb386-15" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb386-16"><a href="#cb386-16" aria-hidden="true" tabindex="-1"></a>    indt <span class="op">=</span> fmid <span class="op">&lt;=</span> zf</span>
<span id="cb386-17"><a href="#cb386-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb386-18"><a href="#cb386-18" aria-hidden="true" tabindex="-1"></a>    tlo <span class="op">=</span> torch.where(indt, tmid, tlo)</span>
<span id="cb386-19"><a href="#cb386-19" aria-hidden="true" tabindex="-1"></a>    thi <span class="op">=</span> torch.where(<span class="op">~</span>indt, tmid, thi)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  t = torch.tensor(t, dtype=torch.float32)</code></pre>
</div>
</div>
<div id="719a350b-31ae-4b62-817e-c432adce8f23" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb388"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb388-1"><a href="#cb388-1" aria-hidden="true" tabindex="-1"></a>tmid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([1.000000000000000, 1.414213657379150, 1.732050895690918])</code></pre>
</div>
</div>
<div id="d1eafbcb-96d8-4a64-b4c0-f13da4635ab6" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb390"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb390-1"><a href="#cb390-1" aria-hidden="true" tabindex="-1"></a>fmid</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="13">
<pre><code>tensor([1.000000000000000, 2.000000238418579, 3.000000238418579])</code></pre>
</div>
</div>
<div id="59a9e806-a2f8-4d42-ac82-369d63f81794" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb392"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb392-1"><a href="#cb392-1" aria-hidden="true" tabindex="-1"></a>indt</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>tensor([ True, False, False])</code></pre>
</div>
</div>
<div id="a3db3cef-bf60-4d1c-ac78-15da61bfc958" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb394"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb394-1"><a href="#cb394-1" aria-hidden="true" tabindex="-1"></a>tlo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="15">
<pre><code>tensor([1.000000000000000, 1.414213538169861, 1.732050776481628])</code></pre>
</div>
</div>
<div id="faac9dbc-acd3-4f99-9e69-74ba8550ee15" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb396"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb396-1"><a href="#cb396-1" aria-hidden="true" tabindex="-1"></a>thi</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([1.000000119209290, 1.414213657379150, 1.732050895690918])</code></pre>
</div>
</div>
<div id="30f4432c-f4bb-4ff4-8e39-612b40168553" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb398"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb398-1"><a href="#cb398-1" aria-hidden="true" tabindex="-1"></a>tsol <span class="op">=</span> (tlo <span class="op">+</span> thi) <span class="op">/</span> <span class="dv">2</span></span>
<span id="cb398-2"><a href="#cb398-2" aria-hidden="true" tabindex="-1"></a>tsol</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([1.000000000000000, 1.414213657379150, 1.732050895690918])</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb400"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb400-1"><a href="#cb400-1" aria-hidden="true" tabindex="-1"></a>vecbinsolv <span class="ot">&lt;-</span> <span class="cf">function</span>(zf, fun, tlo, thi, <span class="at">nits =</span> <span class="dv">30</span>, ...) {</span>
<span id="cb400-2"><a href="#cb400-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-3"><a href="#cb400-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Given a monotone function fun, and a vector of values</span></span>
<span id="cb400-4"><a href="#cb400-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   zf find a vector of numbers t such that f(t) = zf.</span></span>
<span id="cb400-5"><a href="#cb400-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   The solution is constrained to lie on the interval (tlo, thi)</span></span>
<span id="cb400-6"><a href="#cb400-6" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-7"><a href="#cb400-7" aria-hidden="true" tabindex="-1"></a><span class="co">#  The function fun may be a vector of increasing functions </span></span>
<span id="cb400-8"><a href="#cb400-8" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-9"><a href="#cb400-9" aria-hidden="true" tabindex="-1"></a><span class="co">#  Present version is inefficient because separate calculations</span></span>
<span id="cb400-10"><a href="#cb400-10" aria-hidden="true" tabindex="-1"></a><span class="co">#   are done for each element of z, and because bisections are done even</span></span>
<span id="cb400-11"><a href="#cb400-11" aria-hidden="true" tabindex="-1"></a><span class="co">#   if the solution is outside the range supplied</span></span>
<span id="cb400-12"><a href="#cb400-12" aria-hidden="true" tabindex="-1"></a><span class="co">#    </span></span>
<span id="cb400-13"><a href="#cb400-13" aria-hidden="true" tabindex="-1"></a><span class="co">#  It is important that fun should work for vector arguments.</span></span>
<span id="cb400-14"><a href="#cb400-14" aria-hidden="true" tabindex="-1"></a><span class="co">#   Additional arguments to fun can be passed through ...</span></span>
<span id="cb400-15"><a href="#cb400-15" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-16"><a href="#cb400-16" aria-hidden="true" tabindex="-1"></a><span class="co">#  Works by successive bisection, carrying out nits harmonic bisections</span></span>
<span id="cb400-17"><a href="#cb400-17" aria-hidden="true" tabindex="-1"></a><span class="co">#   of the interval between tlo and thi</span></span>
<span id="cb400-18"><a href="#cb400-18" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-19"><a href="#cb400-19" aria-hidden="true" tabindex="-1"></a>    nz <span class="ot">&lt;-</span> <span class="fu">length</span>(zf)</span>
<span id="cb400-20"><a href="#cb400-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">length</span>(tlo)<span class="sc">==</span><span class="dv">1</span>) tlo <span class="ot">&lt;-</span> <span class="fu">rep</span>(tlo, nz)</span>
<span id="cb400-21"><a href="#cb400-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">length</span>(tlo)<span class="sc">!=</span>nz)</span>
<span id="cb400-22"><a href="#cb400-22" aria-hidden="true" tabindex="-1"></a>          <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Lower constraint has to be homogeneous"</span>,</span>
<span id="cb400-23"><a href="#cb400-23" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"or has the same length as #functions."</span>))</span>
<span id="cb400-24"><a href="#cb400-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">length</span>(thi)<span class="sc">==</span><span class="dv">1</span>) thi <span class="ot">&lt;-</span> <span class="fu">rep</span>(thi, nz)</span>
<span id="cb400-25"><a href="#cb400-25" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(<span class="fu">length</span>(thi)<span class="sc">!=</span>nz)</span>
<span id="cb400-26"><a href="#cb400-26" aria-hidden="true" tabindex="-1"></a>          <span class="fu">stop</span>(<span class="fu">paste</span>(<span class="st">"Upper constraint has to be homogeneous"</span>,</span>
<span id="cb400-27"><a href="#cb400-27" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"or has the same length as #functions."</span>))</span>
<span id="cb400-28"><a href="#cb400-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb400-29"><a href="#cb400-29" aria-hidden="true" tabindex="-1"></a><span class="co">#  carry out nits bisections</span></span>
<span id="cb400-30"><a href="#cb400-30" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb400-31"><a href="#cb400-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(jj <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span>nits)) {</span>
<span id="cb400-32"><a href="#cb400-32" aria-hidden="true" tabindex="-1"></a>        tmid <span class="ot">&lt;-</span> (tlo <span class="sc">+</span> thi)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb400-33"><a href="#cb400-33" aria-hidden="true" tabindex="-1"></a>        fmid <span class="ot">&lt;-</span> <span class="fu">fun</span>(tmid, ...)</span>
<span id="cb400-34"><a href="#cb400-34" aria-hidden="true" tabindex="-1"></a>        indt <span class="ot">&lt;-</span> (fmid <span class="sc">&lt;=</span> zf)</span>
<span id="cb400-35"><a href="#cb400-35" aria-hidden="true" tabindex="-1"></a>        tlo[indt] <span class="ot">&lt;-</span> tmid[indt]</span>
<span id="cb400-36"><a href="#cb400-36" aria-hidden="true" tabindex="-1"></a>        thi[<span class="sc">!</span>indt] <span class="ot">&lt;-</span> tmid[<span class="sc">!</span>indt]</span>
<span id="cb400-37"><a href="#cb400-37" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb400-38"><a href="#cb400-38" aria-hidden="true" tabindex="-1"></a>    tsol <span class="ot">&lt;-</span> (tlo <span class="sc">+</span> thi)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb400-39"><a href="#cb400-39" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(tsol)</span>
<span id="cb400-40"><a href="#cb400-40" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="76d5c14d-e588-4e10-9f34-de24a985f6de" class="cell" data-execution_count="88">
<div class="sourceCode cell-code" id="cb401"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb401-1"><a href="#cb401-1" aria-hidden="true" tabindex="-1"></a>zf <span class="op">=</span> torch.tensor([<span class="fl">1.0</span>, <span class="fl">2.0</span>, <span class="fl">3.0</span>])</span>
<span id="cb401-2"><a href="#cb401-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fun(t, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb401-3"><a href="#cb401-3" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.tensor(t, dtype<span class="op">=</span>torch.float32)  </span>
<span id="cb401-4"><a href="#cb401-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="dv">2</span><span class="op">*</span>t </span>
<span id="cb401-5"><a href="#cb401-5" aria-hidden="true" tabindex="-1"></a>tlo <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb401-6"><a href="#cb401-6" aria-hidden="true" tabindex="-1"></a>thi <span class="op">=</span> <span class="dv">10</span></span>
<span id="cb401-7"><a href="#cb401-7" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.vecbinsolv(zf, fun, tlo, thi)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  t = torch.tensor(t, dtype=torch.float32)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="88">
<pre><code>tensor([0.500000000000000, 1.000000000000000, 1.500000000000000])</code></pre>
</div>
</div>
<div id="cf82d855-f17c-4cba-9fdc-8665f15b6c9b" class="cell" data-execution_count="89">
<div class="sourceCode cell-code" id="cb404"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb404-1"><a href="#cb404-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> fun(t, <span class="op">*</span>args, <span class="op">**</span>kwargs):</span>
<span id="cb404-2"><a href="#cb404-2" aria-hidden="true" tabindex="-1"></a>    t <span class="op">=</span> torch.tensor(t, dtype<span class="op">=</span>torch.float32)  </span>
<span id="cb404-3"><a href="#cb404-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> t<span class="op">**</span><span class="dv">2</span></span>
<span id="cb404-4"><a href="#cb404-4" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.vecbinsolv(zf, fun, tlo, thi)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  t = torch.tensor(t, dtype=torch.float32)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="89">
<pre><code>tensor([1.000000000000000, 1.414213657379150, 1.732050895690918])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb407"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb407-1"><a href="#cb407-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> zf <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb407-2"><a href="#cb407-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fun <span class="ot">&lt;-</span> <span class="cf">function</span>(x) <span class="dv">2</span><span class="sc">*</span>x</span>
<span id="cb407-3"><a href="#cb407-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> tlo <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb407-4"><a href="#cb407-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> thi <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb407-5"><a href="#cb407-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">vecbinsolv</span>(zf, fun, tlo, thi)</span>
<span id="cb407-6"><a href="#cb407-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.5</span> <span class="fl">1.0</span> <span class="fl">1.5</span></span>
<span id="cb407-7"><a href="#cb407-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> fun <span class="ot">&lt;-</span> <span class="cf">function</span>(x) x<span class="sc">**</span><span class="dv">2</span></span>
<span id="cb407-8"><a href="#cb407-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">vecbinsolv</span>(zf, fun, tlo, thi)</span>
<span id="cb407-9"><a href="#cb407-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">1.000000</span> <span class="fl">1.414214</span> <span class="fl">1.732051</span></span></code></pre></div>
</section>
<section id="tfromw" class="level1">
<h1>tfromw</h1>
<blockquote class="blockquote">
<p>Given a single value or a vector of weights (i.e.&nbsp;prior probabilities that the parameter is nonzero) and sampling standard deviations (sd equals 1 for Cauchy prior), find the corresponding threshold(s) under the specified prior.</p>
</blockquote>
<p>주어진 가중치 벡터 w와 s(표준 편차)에 대해 지정된 사전 분포를 사용하여 임계값 또는 해당 가중치에 대한 임계값 벡터 찾기. 만약 bayesfac=True이면 베이즈 요인 임계값을 찾고, 그렇지 않으면 사후 중앙값 임계값을 찾음. 만약 Laplace 사전 분포를 사용하는 경우, a는 역 스케일(즉, rate) 매개변수의 값 나옴.</p>
<p>Parameters:</p>
<ul>
<li>w (array-like): 가중치 벡터</li>
<li>s (float): 표준 편차(default: 1)</li>
<li>prior (str): 사전 분포 (default: “laplace”)</li>
<li>bayesfac (bool): 베이즈 요인 임계값을 찾는지 여부 (default: False)</li>
<li>a (float): a &lt; 20인 입력 값 (default: 0.5)</li>
</ul>
<div id="ec94de7a-416d-4eed-9a4e-c56c7397f29c" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb408"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb408-1"><a href="#cb408-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.tensor([<span class="fl">0.05</span>, <span class="fl">0.1</span>])</span>
<span id="cb408-2"><a href="#cb408-2" aria-hidden="true" tabindex="-1"></a><span class="co"># w = 0.5</span></span>
<span id="cb408-3"><a href="#cb408-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb408-4"><a href="#cb408-4" aria-hidden="true" tabindex="-1"></a>prior <span class="op">=</span> <span class="st">"laplace"</span></span>
<span id="cb408-5"><a href="#cb408-5" aria-hidden="true" tabindex="-1"></a><span class="co"># prior = "c"</span></span>
<span id="cb408-6"><a href="#cb408-6" aria-hidden="true" tabindex="-1"></a>bayesfac <span class="op">=</span> <span class="va">False</span></span>
<span id="cb408-7"><a href="#cb408-7" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="8c675780-b0d8-4568-b6c3-83fbb1418e4f" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb409"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb409-1"><a href="#cb409-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb409-2"><a href="#cb409-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="5c7da948-d1a7-49df-817e-f835f6129d7b" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb411"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb411-1"><a href="#cb411-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(w, torch.Tensor):</span>
<span id="cb411-2"><a href="#cb411-2" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> torch.tensor(w)</span>
<span id="cb411-3"><a href="#cb411-3" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(s, torch.Tensor):</span>
<span id="cb411-4"><a href="#cb411-4" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> torch.tensor(s)</span>
<span id="cb411-5"><a href="#cb411-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> <span class="bu">isinstance</span>(a, torch.Tensor):</span>
<span id="cb411-6"><a href="#cb411-6" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> torch.tensor(a)</span>
<span id="cb411-7"><a href="#cb411-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb411-8"><a href="#cb411-8" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> bayesfac:</span>
<span id="cb411-9"><a href="#cb411-9" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> w <span class="op">-</span> <span class="dv">2</span></span>
<span id="cb411-10"><a href="#cb411-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb411-11"><a href="#cb411-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> w.dim() <span class="op">==</span> <span class="dv">0</span> <span class="kw">or</span> <span class="bu">len</span>(w) <span class="op">&gt;=</span> <span class="bu">len</span>(s):</span>
<span id="cb411-12"><a href="#cb411-12" aria-hidden="true" tabindex="-1"></a>            zz <span class="op">=</span> z</span>
<span id="cb411-13"><a href="#cb411-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb411-14"><a href="#cb411-14" aria-hidden="true" tabindex="-1"></a>            zz <span class="op">=</span> z.repeat(<span class="bu">len</span>(s))</span>
<span id="cb411-15"><a href="#cb411-15" aria-hidden="true" tabindex="-1"></a>        tt <span class="op">=</span> ebayesthresh_torch.vecbinsolv(zz, ebayesthresh_torch.beta_laplace, <span class="dv">0</span>, <span class="dv">10</span>, s<span class="op">=</span>s, a<span class="op">=</span>a)</span>
<span id="cb411-16"><a href="#cb411-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb411-17"><a href="#cb411-17" aria-hidden="true" tabindex="-1"></a>        tt <span class="op">=</span> ebayesthresh_torch.vecbinsolv(z, ebayesthresh_torch.beta_cauchy, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb411-18"><a href="#cb411-18" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb411-19"><a href="#cb411-19" aria-hidden="true" tabindex="-1"></a>    z <span class="op">=</span> torch.tensor(<span class="fl">0.0</span>)</span>
<span id="cb411-20"><a href="#cb411-20" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb411-21"><a href="#cb411-21" aria-hidden="true" tabindex="-1"></a>        zz <span class="op">=</span> torch.zeros(<span class="bu">max</span>(s.numel(), w.numel()))</span>
<span id="cb411-22"><a href="#cb411-22" aria-hidden="true" tabindex="-1"></a>        upper_bound <span class="op">=</span> s <span class="op">*</span> (<span class="dv">25</span> <span class="op">+</span> s <span class="op">*</span> a)</span>
<span id="cb411-23"><a href="#cb411-23" aria-hidden="true" tabindex="-1"></a>        tt <span class="op">=</span> ebayesthresh_torch.vecbinsolv(zz, ebayesthresh_torch.laplace_threshzero, <span class="dv">0</span>, upper_bound, s<span class="op">=</span>s, w<span class="op">=</span>w, a<span class="op">=</span>a)</span>
<span id="cb411-24"><a href="#cb411-24" aria-hidden="true" tabindex="-1"></a>    <span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb411-25"><a href="#cb411-25" aria-hidden="true" tabindex="-1"></a>        tt <span class="op">=</span> ebayesthresh_torch.vecbinsolv(z, ebayesthresh_torch.cauchy_threshzero, <span class="dv">0</span>, <span class="dv">10</span>, w<span class="op">=</span>w)</span></code></pre></div>
</div>
<div id="77c4a023-c639-40b7-aa4e-a9a505d602a7" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb412"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb412-1"><a href="#cb412-1" aria-hidden="true" tabindex="-1"></a><span class="co"># if bayesfac:</span></span>
<span id="cb412-2"><a href="#cb412-2" aria-hidden="true" tabindex="-1"></a><span class="co">#     z = 1 / w - 2</span></span>
<span id="cb412-3"><a href="#cb412-3" aria-hidden="true" tabindex="-1"></a><span class="co">#     if pr == "l":</span></span>
<span id="cb412-4"><a href="#cb412-4" aria-hidden="true" tabindex="-1"></a><span class="co">#         if isinstance(s, (int, float, str, bool)) and w.numel() &gt;= len(str(s)):</span></span>
<span id="cb412-5"><a href="#cb412-5" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = z</span></span>
<span id="cb412-6"><a href="#cb412-6" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif isinstance(s, (int, float, str, bool)) and w.numel() &lt; len(str(s)):</span></span>
<span id="cb412-7"><a href="#cb412-7" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.tensor([z] * len(str(s)))  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-8"><a href="#cb412-8" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif len(w) &gt;= len(s):</span></span>
<span id="cb412-9"><a href="#cb412-9" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = z</span></span>
<span id="cb412-10"><a href="#cb412-10" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif len(w) &lt; len(str(s)):</span></span>
<span id="cb412-11"><a href="#cb412-11" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.tensor([z] * len(s))  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-12"><a href="#cb412-12" aria-hidden="true" tabindex="-1"></a><span class="co">#         tt = ebayesthresh_torch.vecbinsolv(zz, ebayesthresh_torch.beta_laplace, 0, 10, 30, s=torch.tensor(s), w=torch.tensor(w), a=torch.tensor(a))</span></span>
<span id="cb412-13"><a href="#cb412-13" aria-hidden="true" tabindex="-1"></a><span class="co">#     elif pr == "c":</span></span>
<span id="cb412-14"><a href="#cb412-14" aria-hidden="true" tabindex="-1"></a><span class="co">#         tt = ebayesthresh_torch.vecbinsolv(z, ebayesthresh_torch.beta_cauchy, 0, 10, 30, w=torch.tensor(w))</span></span>
<span id="cb412-15"><a href="#cb412-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb412-16"><a href="#cb412-16" aria-hidden="true" tabindex="-1"></a><span class="co"># else:</span></span>
<span id="cb412-17"><a href="#cb412-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     z = 0</span></span>
<span id="cb412-18"><a href="#cb412-18" aria-hidden="true" tabindex="-1"></a><span class="co">#     if pr == "l":</span></span>
<span id="cb412-19"><a href="#cb412-19" aria-hidden="true" tabindex="-1"></a><span class="co">#         if isinstance(s, (int, float, str, bool)) and not isinstance(w, (int, float, str, bool)):</span></span>
<span id="cb412-20"><a href="#cb412-20" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.zeros(max(len(str(s)), w.numel()), dtype=torch.float)  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-21"><a href="#cb412-21" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif not isinstance(s, (int, float, str, bool)) and isinstance(w, (int, float, str, bool)):</span></span>
<span id="cb412-22"><a href="#cb412-22" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.zeros(max(len(s), len(str(w))), dtype=torch.float)  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-23"><a href="#cb412-23" aria-hidden="true" tabindex="-1"></a><span class="co">#         elif isinstance(s, (int, float, str, bool)) and isinstance(w, (int, float, str, bool)):</span></span>
<span id="cb412-24"><a href="#cb412-24" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.zeros(max(len(str(s)), len(str(w))), dtype=torch.float)  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-25"><a href="#cb412-25" aria-hidden="true" tabindex="-1"></a><span class="co">#         else:</span></span>
<span id="cb412-26"><a href="#cb412-26" aria-hidden="true" tabindex="-1"></a><span class="co">#             zz = torch.tensor([0] * max(len(s), w.numel()), dtype=torch.float)  # numpy 배열을 torch 텐서로 변환</span></span>
<span id="cb412-27"><a href="#cb412-27" aria-hidden="true" tabindex="-1"></a><span class="co">#         tt = ebayesthresh_torch.vecbinsolv(zz, ebayesthresh_torch.laplace_threshzero, 0, s * (25 + s * a), 30, s=torch.tensor(s), w=torch.tensor(w), a=torch.tensor(a))</span></span>
<span id="cb412-28"><a href="#cb412-28" aria-hidden="true" tabindex="-1"></a><span class="co">#     elif pr == "c":</span></span>
<span id="cb412-29"><a href="#cb412-29" aria-hidden="true" tabindex="-1"></a><span class="co">#         tt = ebayesthresh_torch.vecbinsolv(z, ebayesthresh_torch.cauchy_threshzero, 0, 10, 30, w=torch.tensor(w))</span></span></code></pre></div>
</div>
<div id="5406994f-3a88-4243-bea0-30f6afd32bbd" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb413"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb413-1"><a href="#cb413-1" aria-hidden="true" tabindex="-1"></a>tt</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([3.115211963653564, 2.816306114196777])</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb415"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb415-1"><a href="#cb415-1" aria-hidden="true" tabindex="-1"></a>tfromw <span class="ot">&lt;-</span> <span class="cf">function</span>(w, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">bayesfac =</span> <span class="cn">FALSE</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb415-2"><a href="#cb415-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb415-3"><a href="#cb415-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Given the vector of weights w and s (sd), find the threshold or</span></span>
<span id="cb415-4"><a href="#cb415-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   vector of thresholds corresponding to these weights, under the</span></span>
<span id="cb415-5"><a href="#cb415-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   specified prior.</span></span>
<span id="cb415-6"><a href="#cb415-6" aria-hidden="true" tabindex="-1"></a><span class="co">#  If bayesfac=TRUE the Bayes factor thresholds are found, otherwise</span></span>
<span id="cb415-7"><a href="#cb415-7" aria-hidden="true" tabindex="-1"></a><span class="co">#   the posterior median thresholds are found.</span></span>
<span id="cb415-8"><a href="#cb415-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  If the Laplace prior is used, a gives the value of the inverse scale</span></span>
<span id="cb415-9"><a href="#cb415-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   (i.e., rate) parameter</span></span>
<span id="cb415-10"><a href="#cb415-10" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb415-11"><a href="#cb415-11" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb415-12"><a href="#cb415-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(bayesfac) {</span>
<span id="cb415-13"><a href="#cb415-13" aria-hidden="true" tabindex="-1"></a>        z <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>w <span class="sc">-</span> <span class="dv">2</span></span>
<span id="cb415-14"><a href="#cb415-14" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>){ </span>
<span id="cb415-15"><a href="#cb415-15" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span>(<span class="fu">length</span>(w)<span class="sc">&gt;=</span><span class="fu">length</span>(s)) {</span>
<span id="cb415-16"><a href="#cb415-16" aria-hidden="true" tabindex="-1"></a>            zz <span class="ot">&lt;-</span> z</span>
<span id="cb415-17"><a href="#cb415-17" aria-hidden="true" tabindex="-1"></a>          } <span class="cf">else</span> { zz <span class="ot">&lt;-</span> <span class="fu">rep</span>(z, <span class="fu">length</span>(s)) }</span>
<span id="cb415-18"><a href="#cb415-18" aria-hidden="true" tabindex="-1"></a>          tt <span class="ot">&lt;-</span> <span class="fu">vecbinsolv</span>(zz, beta.laplace, <span class="dv">0</span>, <span class="dv">10</span>, <span class="at">s =</span> s, <span class="at">a =</span> a)</span>
<span id="cb415-19"><a href="#cb415-19" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb415-20"><a href="#cb415-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb415-21"><a href="#cb415-21" aria-hidden="true" tabindex="-1"></a>            tt <span class="ot">&lt;-</span> <span class="fu">vecbinsolv</span>(z, beta.cauchy, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb415-22"><a href="#cb415-22" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb415-23"><a href="#cb415-23" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span> {</span>
<span id="cb415-24"><a href="#cb415-24" aria-hidden="true" tabindex="-1"></a>      z <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb415-25"><a href="#cb415-25" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>){</span>
<span id="cb415-26"><a href="#cb415-26" aria-hidden="true" tabindex="-1"></a>          zz <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">max</span>(<span class="fu">length</span>(s), <span class="fu">length</span>(w)))</span>
<span id="cb415-27"><a href="#cb415-27" aria-hidden="true" tabindex="-1"></a>                  </span>
<span id="cb415-28"><a href="#cb415-28" aria-hidden="true" tabindex="-1"></a>          <span class="co"># When x/s-s*a&gt;25, laplace.threshzero has value</span></span>
<span id="cb415-29"><a href="#cb415-29" aria-hidden="true" tabindex="-1"></a>          <span class="co">#  close to 1/2; The boundary value of x can be</span></span>
<span id="cb415-30"><a href="#cb415-30" aria-hidden="true" tabindex="-1"></a>          <span class="co">#  treated as the upper bound for search.</span></span>
<span id="cb415-31"><a href="#cb415-31" aria-hidden="true" tabindex="-1"></a>          tt <span class="ot">&lt;-</span> <span class="fu">vecbinsolv</span>(zz, laplace.threshzero, <span class="dv">0</span>, s<span class="sc">*</span>(<span class="dv">25</span><span class="sc">+</span>s<span class="sc">*</span>a),</span>
<span id="cb415-32"><a href="#cb415-32" aria-hidden="true" tabindex="-1"></a>                                   <span class="at">s =</span> s, <span class="at">w =</span> w, <span class="at">a =</span> a)</span>
<span id="cb415-33"><a href="#cb415-33" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb415-34"><a href="#cb415-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>)</span>
<span id="cb415-35"><a href="#cb415-35" aria-hidden="true" tabindex="-1"></a>            tt <span class="ot">&lt;-</span> <span class="fu">vecbinsolv</span>(z, cauchy.threshzero, <span class="dv">0</span>, <span class="dv">10</span>, <span class="at">w =</span> w)</span>
<span id="cb415-36"><a href="#cb415-36" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb415-37"><a href="#cb415-37" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(tt)</span>
<span id="cb415-38"><a href="#cb415-38" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="d4b0444b-1034-4f31-82d1-802ca5b2aeb0" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb416"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb416-1"><a href="#cb416-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.tfromw(torch.tensor([<span class="fl">0.05</span>, <span class="fl">0.1</span>]), s <span class="op">=</span> <span class="dv">1</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>tensor([3.115211963653564, 2.816306114196777])</code></pre>
</div>
</div>
<div id="63474424-ddc0-46bb-8364-fd50bf75e62f" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb418"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb418-1"><a href="#cb418-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.tfromw(torch.tensor([<span class="fl">0.05</span>, <span class="fl">0.1</span>]), prior <span class="op">=</span> <span class="st">"cauchy"</span>, bayesfac <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  x = torch.tensor(x,dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>tensor([3.259634971618652, 2.959740638732910])</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb421"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb421-1"><a href="#cb421-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">tfromw</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.1</span>), <span class="at">s =</span> <span class="dv">1</span>)</span>
<span id="cb421-2"><a href="#cb421-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">3.115212</span> <span class="fl">2.816306</span></span>
<span id="cb421-3"><a href="#cb421-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">tfromw</span>(<span class="fu">c</span>(<span class="fl">0.05</span>, <span class="fl">0.1</span>), <span class="at">prior =</span> <span class="st">"cauchy"</span>, <span class="at">bayesfac =</span> <span class="cn">TRUE</span>)</span>
<span id="cb421-4"><a href="#cb421-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">3.259635</span> <span class="fl">2.959740</span></span></code></pre></div>
</section>
<section id="tfromx" class="level1">
<h1>tfromx</h1>
<blockquote class="blockquote">
<p>Given a vector of data and standard deviations (sd equals 1 for Cauchy prior), find the value or vector (heterogeneous sampling standard deviation with Laplace prior) of thresholds corresponding to the marginal maximum likelihood choice of weight.</p>
</blockquote>
<p><em>데이터가 주어졌을때, 가중치의 한계 최대 우도로 임계값 찾는 함수</em></p>
<div id="310b64a8-5a86-4de0-8320-c6b034e86223" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb422"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb422-1"><a href="#cb422-1" aria-hidden="true" tabindex="-1"></a>x<span class="op">=</span>torch.tensor([<span class="fl">0.05</span>,<span class="fl">0.1</span>])</span>
<span id="cb422-2"><a href="#cb422-2" aria-hidden="true" tabindex="-1"></a>s<span class="op">=</span><span class="dv">1</span></span>
<span id="cb422-3"><a href="#cb422-3" aria-hidden="true" tabindex="-1"></a>prior<span class="op">=</span><span class="st">"laplace"</span></span>
<span id="cb422-4"><a href="#cb422-4" aria-hidden="true" tabindex="-1"></a>bayesfac<span class="op">=</span><span class="va">False</span></span>
<span id="cb422-5"><a href="#cb422-5" aria-hidden="true" tabindex="-1"></a>a<span class="op">=</span>torch.tensor(<span class="fl">0.5</span>)</span>
<span id="cb422-6"><a href="#cb422-6" aria-hidden="true" tabindex="-1"></a>universalthresh<span class="op">=</span><span class="va">True</span></span></code></pre></div>
</div>
<div id="15879d8d-af17-4b65-97be-4f5783dc25ee" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb423"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb423-1"><a href="#cb423-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span></code></pre></div>
</div>
<div id="e91e1aa7-7949-496a-b647-d1f0e4ba25fb" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb424"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb424-1"><a href="#cb424-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb424-2"><a href="#cb424-2" aria-hidden="true" tabindex="-1"></a>    s <span class="op">=</span> <span class="dv">1</span></span></code></pre></div>
</div>
<div id="556fc367-b945-4bb0-93d4-4b8e84a466e3" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb425"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb425-1"><a href="#cb425-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span> <span class="kw">and</span> torch.isnan(a):</span>
<span id="cb425-2"><a href="#cb425-2" aria-hidden="true" tabindex="-1"></a>    wa <span class="op">=</span> ebayesthresh_torch.wandafromx(x, s, universalthresh)</span>
<span id="cb425-3"><a href="#cb425-3" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> wa[<span class="st">'w'</span>]</span>
<span id="cb425-4"><a href="#cb425-4" aria-hidden="true" tabindex="-1"></a>    a <span class="op">=</span> wa[<span class="st">'a'</span>]</span>
<span id="cb425-5"><a href="#cb425-5" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb425-6"><a href="#cb425-6" aria-hidden="true" tabindex="-1"></a>    w <span class="op">=</span> ebayesthresh_torch.wfromx(x, s, prior<span class="op">=</span>prior, a<span class="op">=</span>a)</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)</code></pre>
</div>
</div>
<div id="02cf5a6e-0cd0-4453-b1cf-c583e4da036a" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb427"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb427-1"><a href="#cb427-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.tfromw(w, s, prior<span class="op">=</span>prior, bayesfac<span class="op">=</span>bayesfac, a<span class="op">=</span>a)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([1.177409887313843])</code></pre>
</div>
</div>
<p>R코드</p>
<ul>
<li>Python</li>
</ul>
<div id="a41ad3ed-bba3-456c-84b7-065385208787" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb429"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb429-1"><a href="#cb429-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.tfromx(x<span class="op">=</span>torch.tensor([<span class="fl">0.05</span>,<span class="fl">0.1</span>]), s <span class="op">=</span> <span class="dv">1</span>, prior <span class="op">=</span> <span class="st">"laplace"</span>, bayesfac <span class="op">=</span> <span class="va">False</span>, a <span class="op">=</span> <span class="fl">0.5</span>, universalthresh <span class="op">=</span> <span class="va">True</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>tensor(1.177409887313843)</code></pre>
</div>
</div>
<div id="fd41ae58-e558-4edb-954e-8e30c4603399" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb431"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb431-1"><a href="#cb431-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.tfromx(x <span class="op">=</span> torch.cat((torch.randn(<span class="dv">90</span>), torch.randn(<span class="dv">10</span>) <span class="op">+</span> <span class="dv">5</span>), dim<span class="op">=</span><span class="dv">0</span>), prior <span class="op">=</span> <span class="st">"cauchy"</span>)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>tensor(2.158299446105957)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">tfromx</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="fl">0.05</span>,<span class="fl">0.1</span>), <span class="at">s =</span> <span class="dv">1</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">bayesfac =</span> <span class="cn">FALSE</span>, <span class="at">a =</span> <span class="fl">0.5</span>,<span class="at">universalthresh =</span> <span class="cn">TRUE</span>)</span>
<span id="cb433-2"><a href="#cb433-2" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">1.17741</span></span>
<span id="cb433-3"><a href="#cb433-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">tfromx</span>(<span class="at">x=</span><span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">90</span>, <span class="at">mean=</span><span class="dv">0</span>, <span class="at">sd=</span><span class="dv">1</span>), <span class="fu">rnorm</span>(<span class="dv">10</span>, <span class="at">mean=</span><span class="dv">5</span>, <span class="at">sd=</span><span class="dv">1</span>)), <span class="at">prior =</span> <span class="st">"cauchy"</span>)</span>
<span id="cb433-4"><a href="#cb433-4" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">2.301196</span></span></code></pre></div>
</section>
<section id="wpost_laplace" class="level1">
<h1>wpost_laplace</h1>
<blockquote class="blockquote">
<p>Calculate the posterior weight for non-zero effect</p>
</blockquote>
<ul>
<li>0이 아닌 효과에 대한 사후 가중치 계산</li>
</ul>
<div id="7a7f72af-2f77-4d52-a920-bc3ba542831b" class="cell" data-execution_count="61">
<div class="sourceCode cell-code" id="cb434"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb434-1"><a href="#cb434-1" aria-hidden="true" tabindex="-1"></a>w<span class="op">=</span> <span class="fl">0.5</span></span>
<span id="cb434-2"><a href="#cb434-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>])</span>
<span id="cb434-3"><a href="#cb434-3" aria-hidden="true" tabindex="-1"></a>s <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb434-4"><a href="#cb434-4" aria-hidden="true" tabindex="-1"></a>a <span class="op">=</span> <span class="fl">0.5</span></span></code></pre></div>
</div>
<div id="4da89605-18ee-4b80-970a-654875db9779" class="cell" data-execution_count="62">
<div class="sourceCode cell-code" id="cb435"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb435-1"><a href="#cb435-1" aria-hidden="true" tabindex="-1"></a>laplace_beta <span class="op">=</span> ebayesthresh_torch.beta_laplace(x, s, a)</span>
<span id="cb435-2"><a href="#cb435-2" aria-hidden="true" tabindex="-1"></a>laplace_beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="62">
<pre><code>tensor([ 8.898520296511427e-01, -3.800417166060107e-01, -5.618177717731538e-01,
         2.854594666723506e+02,  1.026980615772411e+12, 6.344539544172600e+265],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="c6e8bcee-8887-4576-bfaa-f2334aee3083" class="cell" data-execution_count="63">
<div class="sourceCode cell-code" id="cb437"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb437-1"><a href="#cb437-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="op">-</span> (<span class="dv">1</span> <span class="op">-</span> w) <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> w <span class="op">*</span> laplace_beta)</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="63">
<pre><code>tensor([0.653961521302972, 0.382700153299694, 0.304677821507423,
        0.996521248676984, 0.999999999999026, 1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<p>R코드</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="#cb439-1" aria-hidden="true" tabindex="-1"></a>wpost.laplace <span class="ot">&lt;-</span> <span class="cf">function</span>(w, x, <span class="at">s =</span> <span class="dv">1</span>, <span class="at">a =</span> <span class="fl">0.5</span>)</span>
<span id="cb439-2"><a href="#cb439-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb439-3"><a href="#cb439-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Calculate the posterior weight for non-zero effect</span></span>
<span id="cb439-4"><a href="#cb439-4" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb439-5"><a href="#cb439-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">-</span> (<span class="dv">1</span> <span class="sc">-</span> w)<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> w <span class="sc">*</span> <span class="fu">beta.laplace</span>(x, s, a))</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="def1cb56-68a3-4b8d-9b26-4f0b41967eb6" class="cell" data-execution_count="64">
<div class="sourceCode cell-code" id="cb440"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb440-1"><a href="#cb440-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.wpost_laplace(<span class="fl">0.5</span>,torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="64">
<pre><code>tensor([0.653961521302972, 0.382700153299694, 0.304677821507423,
        0.996521248676984, 0.999999999999026, 1.000000000000000],
       dtype=torch.float64)</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<p>이베이즈 깃헙에 있는데 R 패키지에는 없음.</p>
</section>
<section id="zetafromx" class="level1">
<h1>zetafromx</h1>
<p>Description</p>
<blockquote class="blockquote">
<p>Suppose a sequence of data has underlying mean vector with elements <span class="math inline">\(\theta_i\)</span>. Given the sequence of data, and a vector of scale factors cs and a lower limit pilo, this routine finds the marginal maximum likelihood estimate of the parameter zeta such that the prior probability of <span class="math inline">\(\theta_i\)</span> being nonzero is of the form median(pilo, zeta*cs, 1).</p>
</blockquote>
<p><em>파라메터 제타의 최대 우도 추정치 계산</em></p>
<div id="5b91e931-72bd-4852-bb53-9d5725b17699" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb442"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb442-1"><a href="#cb442-1" aria-hidden="true" tabindex="-1"></a>xd <span class="op">=</span> torch.tensor([<span class="op">-</span><span class="fl">2.0</span>,<span class="fl">1.0</span>,<span class="fl">0.0</span>,<span class="op">-</span><span class="fl">4.0</span>,<span class="fl">8.0</span>,<span class="fl">50.0</span>])</span>
<span id="cb442-2"><a href="#cb442-2" aria-hidden="true" tabindex="-1"></a>cs <span class="op">=</span> torch.tensor([<span class="fl">2.0</span>,<span class="fl">3.0</span>,<span class="fl">5.0</span>,<span class="fl">6.0</span>,<span class="fl">1.0</span>,<span class="op">-</span><span class="fl">1.0</span>])</span>
<span id="cb442-3"><a href="#cb442-3" aria-hidden="true" tabindex="-1"></a>pilo <span class="op">=</span> <span class="va">None</span></span>
<span id="cb442-4"><a href="#cb442-4" aria-hidden="true" tabindex="-1"></a>prior<span class="op">=</span><span class="st">"laplace"</span></span>
<span id="cb442-5"><a href="#cb442-5" aria-hidden="true" tabindex="-1"></a><span class="co"># priir="c"</span></span>
<span id="cb442-6"><a href="#cb442-6" aria-hidden="true" tabindex="-1"></a>a<span class="op">=</span>torch.tensor(<span class="fl">0.5</span>)</span></code></pre></div>
</div>
<div id="9c7f843e-f94c-4946-b7c7-afd88dd83479" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb443"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb443-1"><a href="#cb443-1" aria-hidden="true" tabindex="-1"></a>pr <span class="op">=</span> prior[<span class="dv">0</span>:<span class="dv">1</span>]</span>
<span id="cb443-2"><a href="#cb443-2" aria-hidden="true" tabindex="-1"></a>pr</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="23">
<pre><code>'l'</code></pre>
</div>
</div>
<div id="ef0df944-2d23-4cf5-a311-20f2cb094daa" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb445"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb445-1"><a href="#cb445-1" aria-hidden="true" tabindex="-1"></a>nx <span class="op">=</span> <span class="bu">len</span>(xd)</span>
<span id="cb445-2"><a href="#cb445-2" aria-hidden="true" tabindex="-1"></a>nx</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="24">
<pre><code>6</code></pre>
</div>
</div>
<div id="f8011590-91fc-4e61-aa41-99e0bcb2f453" class="cell" data-tags="[]" data-execution_count="25">
<div class="sourceCode cell-code" id="cb447"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb447-1"><a href="#cb447-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pilo <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb447-2"><a href="#cb447-2" aria-hidden="true" tabindex="-1"></a>    pilo <span class="op">=</span> ebayesthresh_torch.wfromt(torch.sqrt(<span class="dv">2</span> <span class="op">*</span> torch.log(torch.tensor(nx, dtype<span class="op">=</span>torch.<span class="bu">float</span>))), prior<span class="op">=</span>prior, a<span class="op">=</span>a)</span></code></pre></div>
</div>
<div id="7cd451ea-8d3f-4304-8bfd-f4dc90570c1b" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb448"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb448-1"><a href="#cb448-1" aria-hidden="true" tabindex="-1"></a>pilo</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="26">
<pre><code>tensor(0.412115022681705, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="fb5a583d-b92b-4547-9015-59239aba84df" class="cell" data-execution_count="27">
<div class="sourceCode cell-code" id="cb450"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb450-1"><a href="#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> pr <span class="op">==</span> <span class="st">"l"</span>:</span>
<span id="cb450-2"><a href="#cb450-2" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_laplace(xd, a<span class="op">=</span>a)</span>
<span id="cb450-3"><a href="#cb450-3" aria-hidden="true" tabindex="-1"></a><span class="cf">elif</span> pr <span class="op">==</span> <span class="st">"c"</span>:</span>
<span id="cb450-4"><a href="#cb450-4" aria-hidden="true" tabindex="-1"></a>    beta <span class="op">=</span> ebayesthresh_torch.beta_cauchy(xd)</span></code></pre></div>
</div>
<div id="5524b7e6-52dc-42f4-b214-af23583f33ed" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb451"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb451-1"><a href="#cb451-1" aria-hidden="true" tabindex="-1"></a>beta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="28">
<pre><code>tensor([ 8.898520296511427e-01, -3.800417166060107e-01, -5.618177717731538e-01,
         2.854594666723506e+02,  1.026980615772411e+12, 6.344539544172600e+265],
       dtype=torch.float64)</code></pre>
</div>
</div>
<div id="a0ca53c8-2197-477d-a635-43685654b340" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb453"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb453-1"><a href="#cb453-1" aria-hidden="true" tabindex="-1"></a>zs1 <span class="op">=</span> pilo <span class="op">/</span> cs</span>
<span id="cb453-2"><a href="#cb453-2" aria-hidden="true" tabindex="-1"></a>zs1</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="29">
<pre><code>tensor([ 0.206057518720627,  0.137371674180031,  0.082423008978367,
         0.068685837090015,  0.412115037441254, -0.412115037441254])</code></pre>
</div>
</div>
<div id="5de5a5d9-de9a-4d41-a743-3324cbf9b78e" class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb455"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb455-1"><a href="#cb455-1" aria-hidden="true" tabindex="-1"></a>zs2 <span class="op">=</span> <span class="dv">1</span> <span class="op">/</span> cs</span>
<span id="cb455-2"><a href="#cb455-2" aria-hidden="true" tabindex="-1"></a>zs2</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>tensor([ 0.500000000000000,  0.333333343267441,  0.200000002980232,
         0.166666671633720,  1.000000000000000, -1.000000000000000])</code></pre>
</div>
</div>
<div id="eeaaecd6-5fea-44eb-873f-3687eb53362e" class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb457"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb457-1"><a href="#cb457-1" aria-hidden="true" tabindex="-1"></a>zj <span class="op">=</span> torch.sort(torch.unique(torch.cat((zs1, zs2)))).values</span>
<span id="cb457-2"><a href="#cb457-2" aria-hidden="true" tabindex="-1"></a>zj</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([-1.000000000000000, -0.412115037441254,  0.068685837090015,
         0.082423008978367,  0.137371674180031,  0.166666671633720,
         0.200000002980232,  0.206057518720627,  0.333333343267441,
         0.412115037441254,  0.500000000000000,  1.000000000000000])</code></pre>
</div>
</div>
<div id="86681619-8e0f-4586-8783-04edcdbd25c6" class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb459"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb459-1"><a href="#cb459-1" aria-hidden="true" tabindex="-1"></a>cb <span class="op">=</span> cs <span class="op">*</span> beta</span>
<span id="cb459-2"><a href="#cb459-2" aria-hidden="true" tabindex="-1"></a>cb</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="32">
<pre><code>tensor([  1.779704059302285e+00,  -1.140125149818032e+00,
         -2.809088858865769e+00,   1.712756800034103e+03,
          1.026980615772411e+12, -6.344539544172600e+265], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="d272598a-fd8a-447e-a94a-53c7fc76b361" class="cell" data-execution_count="33">
<div class="sourceCode cell-code" id="cb461"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb461-1"><a href="#cb461-1" aria-hidden="true" tabindex="-1"></a>mz <span class="op">=</span> <span class="bu">len</span>(zj)</span>
<span id="cb461-2"><a href="#cb461-2" aria-hidden="true" tabindex="-1"></a>mz</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="33">
<pre><code>12</code></pre>
</div>
</div>
<div id="f1ded7f9-2df3-43a0-8fda-e4c8619d0192" class="cell" data-execution_count="34">
<div class="sourceCode cell-code" id="cb463"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb463-1"><a href="#cb463-1" aria-hidden="true" tabindex="-1"></a>zlmax <span class="op">=</span> <span class="va">None</span></span>
<span id="cb463-2"><a href="#cb463-2" aria-hidden="true" tabindex="-1"></a>zlmax</span></code></pre></div>
</div>
<div id="62284f9f-9c06-4faf-9ed4-e27aacdd3170" class="cell" data-execution_count="35">
<div class="sourceCode cell-code" id="cb464"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb464-1"><a href="#cb464-1" aria-hidden="true" tabindex="-1"></a>lmin <span class="op">=</span>  torch.zeros(mz, dtype<span class="op">=</span>torch.<span class="bu">bool</span>)</span>
<span id="cb464-2"><a href="#cb464-2" aria-hidden="true" tabindex="-1"></a>lmin</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<pre><code>tensor([False, False, False, False, False, False, False, False, False, False,
        False, False])</code></pre>
</div>
</div>
<div id="1b10107d-797b-4ed5-984f-8e331fd5775d" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb466"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb466-1"><a href="#cb466-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, mz <span class="op">-</span> <span class="dv">1</span>):</span>
<span id="cb466-2"><a href="#cb466-2" aria-hidden="true" tabindex="-1"></a>    ze <span class="op">=</span> zj[j]</span>
<span id="cb466-3"><a href="#cb466-3" aria-hidden="true" tabindex="-1"></a>    cbil <span class="op">=</span> cb[(ze <span class="op">&gt;</span> zs1) <span class="op">&amp;</span> (ze <span class="op">&lt;=</span> zs2)]</span>
<span id="cb466-4"><a href="#cb466-4" aria-hidden="true" tabindex="-1"></a>    ld <span class="op">=</span> torch.<span class="bu">sum</span>(cbil <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ze <span class="op">*</span> cbil))</span>
<span id="cb466-5"><a href="#cb466-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> ld <span class="op">&lt;=</span> <span class="dv">0</span>:</span>
<span id="cb466-6"><a href="#cb466-6" aria-hidden="true" tabindex="-1"></a>        cbir <span class="op">=</span> cb[(ze <span class="op">&gt;=</span> zs1) <span class="op">&amp;</span> (ze <span class="op">&lt;</span> zs2)]</span>
<span id="cb466-7"><a href="#cb466-7" aria-hidden="true" tabindex="-1"></a>        rd <span class="op">=</span> torch.<span class="bu">sum</span>(cbir <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ze <span class="op">*</span> cbir))</span>
<span id="cb466-8"><a href="#cb466-8" aria-hidden="true" tabindex="-1"></a>        lmin[j] <span class="op">=</span> rd <span class="op">&gt;=</span> <span class="dv">0</span></span></code></pre></div>
</div>
<div id="d804c933-5aef-4f82-ab83-3a7b9d1a8219" class="cell" data-execution_count="37">
<div class="sourceCode cell-code" id="cb467"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb467-1"><a href="#cb467-1" aria-hidden="true" tabindex="-1"></a>cbir</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="37">
<pre><code>tensor([1.779704059302285], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="659b45eb-4748-4719-8515-d56772118273" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb469"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb469-1"><a href="#cb469-1" aria-hidden="true" tabindex="-1"></a>rd</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="38">
<pre><code>tensor(1.117038220864095, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="3ea03e5b-1536-4a1e-a2e6-7582b2d7677b" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb471"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb471-1"><a href="#cb471-1" aria-hidden="true" tabindex="-1"></a>lmin</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="39">
<pre><code>tensor([False,  True,  True, False, False, False, False, False,  True, False,
        False, False])</code></pre>
</div>
</div>
<div id="efbe827d-a278-4d92-be0e-ddc915800c86" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb473"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb473-1"><a href="#cb473-1" aria-hidden="true" tabindex="-1"></a>cbir <span class="op">=</span> cb[zj[<span class="dv">0</span>] <span class="op">==</span> zs1]</span>
<span id="cb473-2"><a href="#cb473-2" aria-hidden="true" tabindex="-1"></a>cbir</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="40">
<pre><code>tensor([], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="7917d593-1d8f-4b3e-a345-465d578d6354" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb475"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb475-1"><a href="#cb475-1" aria-hidden="true" tabindex="-1"></a>rd <span class="op">=</span> torch.<span class="bu">sum</span>(cbir <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> zj[<span class="dv">0</span>] <span class="op">*</span> cbir))</span>
<span id="cb475-2"><a href="#cb475-2" aria-hidden="true" tabindex="-1"></a>rd</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="41">
<pre><code>tensor(0., dtype=torch.float64)</code></pre>
</div>
</div>
<div id="eac943be-ca28-4cf0-9c22-7d1a23d85684" class="cell" data-execution_count="42">
<div class="sourceCode cell-code" id="cb477"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb477-1"><a href="#cb477-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> rd <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb477-2"><a href="#cb477-2" aria-hidden="true" tabindex="-1"></a>    lmin[<span class="dv">0</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb477-3"><a href="#cb477-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb477-4"><a href="#cb477-4" aria-hidden="true" tabindex="-1"></a>    zlmax <span class="op">=</span> zj[<span class="dv">0</span>].tolist()</span></code></pre></div>
</div>
<div id="1c668306-e080-4262-b997-ca1452b41aed" class="cell" data-execution_count="43">
<div class="sourceCode cell-code" id="cb478"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb478-1"><a href="#cb478-1" aria-hidden="true" tabindex="-1"></a>zlmax</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="43">
<pre><code>-1.0</code></pre>
</div>
</div>
<div id="b79af5d9-a6f6-4514-bfe0-84c2b00f5361" class="cell" data-execution_count="44">
<div class="sourceCode cell-code" id="cb480"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb480-1"><a href="#cb480-1" aria-hidden="true" tabindex="-1"></a>cbil <span class="op">=</span> cb[zj[mz <span class="op">-</span> <span class="dv">1</span>] <span class="op">==</span> zs2]</span>
<span id="cb480-2"><a href="#cb480-2" aria-hidden="true" tabindex="-1"></a>cbil</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="44">
<pre><code>tensor([1.026980615772411e+12], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="b154d550-81b3-4d78-aeac-baa536df5211" class="cell" data-execution_count="45">
<div class="sourceCode cell-code" id="cb482"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb482-1"><a href="#cb482-1" aria-hidden="true" tabindex="-1"></a>cbil <span class="op">=</span> cb[zj[mz <span class="op">-</span> <span class="dv">1</span>] <span class="op">==</span> zs2]</span>
<span id="cb482-2"><a href="#cb482-2" aria-hidden="true" tabindex="-1"></a>cbil</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="45">
<pre><code>tensor([1.026980615772411e+12], dtype=torch.float64)</code></pre>
</div>
</div>
<div id="88ec8228-9c2c-4b38-b674-6f3d1cd260f9" class="cell" data-execution_count="46">
<div class="sourceCode cell-code" id="cb484"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb484-1"><a href="#cb484-1" aria-hidden="true" tabindex="-1"></a>ld <span class="op">=</span> torch.<span class="bu">sum</span>(cbil <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> zj[mz <span class="op">-</span> <span class="dv">1</span>] <span class="op">*</span> cbil))</span>
<span id="cb484-2"><a href="#cb484-2" aria-hidden="true" tabindex="-1"></a>ld</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="46">
<pre><code>tensor(0.999999999999026, dtype=torch.float64)</code></pre>
</div>
</div>
<div id="cf4bc128-4408-4ac2-9c80-b66fffba688b" class="cell" data-execution_count="47">
<div class="sourceCode cell-code" id="cb486"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb486-1"><a href="#cb486-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> ld <span class="op">&lt;</span> <span class="dv">0</span>:</span>
<span id="cb486-2"><a href="#cb486-2" aria-hidden="true" tabindex="-1"></a>    lmin[mz <span class="op">-</span> <span class="dv">1</span>] <span class="op">=</span> <span class="va">True</span></span>
<span id="cb486-3"><a href="#cb486-3" aria-hidden="true" tabindex="-1"></a><span class="cf">else</span>:</span>
<span id="cb486-4"><a href="#cb486-4" aria-hidden="true" tabindex="-1"></a>    zlmax <span class="op">=</span> [(zj[mz <span class="op">-</span> <span class="dv">1</span>]).tolist()]</span></code></pre></div>
</div>
<div id="7126b557-118a-4182-9cb6-c42a5d8d819a" class="cell" data-execution_count="48">
<div class="sourceCode cell-code" id="cb487"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb487-1"><a href="#cb487-1" aria-hidden="true" tabindex="-1"></a>zlmin <span class="op">=</span> zj[lmin]</span>
<span id="cb487-2"><a href="#cb487-2" aria-hidden="true" tabindex="-1"></a>zlmin</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="48">
<pre><code>tensor([-0.412115037441254,  0.068685837090015,  0.333333343267441])</code></pre>
</div>
</div>
<div id="f4f11400-8560-492f-b435-2fc56c4ea487" class="cell" data-execution_count="49">
<div class="sourceCode cell-code" id="cb489"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb489-1"><a href="#cb489-1" aria-hidden="true" tabindex="-1"></a>nlmin <span class="op">=</span> <span class="bu">len</span>(zlmin)</span>
<span id="cb489-2"><a href="#cb489-2" aria-hidden="true" tabindex="-1"></a>nlmin</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="49">
<pre><code>3</code></pre>
</div>
</div>
<div id="dc6ab330-20e8-4cff-9633-bca373b23ca9" class="cell" data-execution_count="50">
<div class="sourceCode cell-code" id="cb491"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb491-1"><a href="#cb491-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, nlmin):</span>
<span id="cb491-2"><a href="#cb491-2" aria-hidden="true" tabindex="-1"></a>    zlo <span class="op">=</span> zlmin[j <span class="op">-</span> <span class="dv">1</span>]</span>
<span id="cb491-3"><a href="#cb491-3" aria-hidden="true" tabindex="-1"></a>    zhi <span class="op">=</span> zlmin[j]</span>
<span id="cb491-4"><a href="#cb491-4" aria-hidden="true" tabindex="-1"></a>    ze <span class="op">=</span> (zlo <span class="op">+</span> zhi) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb491-5"><a href="#cb491-5" aria-hidden="true" tabindex="-1"></a>    zstep <span class="op">=</span> (zhi <span class="op">-</span> zlo) <span class="op">/</span> <span class="fl">2.0</span></span>
<span id="cb491-6"><a href="#cb491-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> nit <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>,<span class="dv">11</span>):</span>
<span id="cb491-7"><a href="#cb491-7" aria-hidden="true" tabindex="-1"></a>        cbi <span class="op">=</span> cb[(ze <span class="op">&gt;=</span> zs1) <span class="op">&amp;</span> (ze <span class="op">&lt;=</span> zs2)]</span>
<span id="cb491-8"><a href="#cb491-8" aria-hidden="true" tabindex="-1"></a>        likd <span class="op">=</span> torch.<span class="bu">sum</span>(cbi <span class="op">/</span> (<span class="dv">1</span> <span class="op">+</span> ze <span class="op">*</span> cbi))</span>
<span id="cb491-9"><a href="#cb491-9" aria-hidden="true" tabindex="-1"></a>        zstep <span class="op">/=</span> <span class="fl">2.0</span></span>
<span id="cb491-10"><a href="#cb491-10" aria-hidden="true" tabindex="-1"></a>        ze <span class="op">+=</span> zstep <span class="op">*</span> torch.sign(likd)</span>
<span id="cb491-11"><a href="#cb491-11" aria-hidden="true" tabindex="-1"></a>    zlmax.append(ze.item())</span></code></pre></div>
</div>
<div id="07f7e29e-8070-42d2-aeda-1f1db424decd" class="cell" data-execution_count="51">
<div class="sourceCode cell-code" id="cb492"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb492-1"><a href="#cb492-1" aria-hidden="true" tabindex="-1"></a>zlmax <span class="op">=</span> torch.tensor(zlmax)</span>
<span id="cb492-2"><a href="#cb492-2" aria-hidden="true" tabindex="-1"></a>zlmax</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="51">
<pre><code>tensor([ 1.000000000000000, -0.171714603900909,  0.155910953879356])</code></pre>
</div>
</div>
<div id="169849aa-adf7-49c8-ae06-e90e025edc4a" class="cell" data-execution_count="52">
<div class="sourceCode cell-code" id="cb494"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb494-1"><a href="#cb494-1" aria-hidden="true" tabindex="-1"></a>zm <span class="op">=</span> torch.full((<span class="bu">len</span>(zlmax),), <span class="bu">float</span>(<span class="st">'nan'</span>))</span>
<span id="cb494-2"><a href="#cb494-2" aria-hidden="true" tabindex="-1"></a>zm</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="52">
<pre><code>tensor([nan, nan, nan])</code></pre>
</div>
</div>
<div id="e82a0663-c04f-4a60-858f-c829d906f856" class="cell" data-execution_count="53">
<div class="sourceCode cell-code" id="cb496"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb496-1"><a href="#cb496-1" aria-hidden="true" tabindex="-1"></a>zlmax</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="53">
<pre><code>tensor([ 1.000000000000000, -0.171714603900909,  0.155910953879356])</code></pre>
</div>
</div>
<div id="b433c266-d1a0-4b41-9428-9b07212fdb23" class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb498"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb498-1"><a href="#cb498-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(<span class="bu">len</span>(zlmax)):</span>
<span id="cb498-2"><a href="#cb498-2" aria-hidden="true" tabindex="-1"></a>    pz <span class="op">=</span> torch.maximum(zs1, torch.<span class="bu">min</span>(zlmax[j],zs2))</span>
<span id="cb498-3"><a href="#cb498-3" aria-hidden="true" tabindex="-1"></a>    zm[j] <span class="op">=</span> torch.<span class="bu">sum</span>(torch.log(<span class="dv">1</span> <span class="op">+</span> cb <span class="op">*</span> pz))</span></code></pre></div>
</div>
<div id="1dbf4015-f214-4172-b310-e3f97f1ad1ee" class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb499"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb499-1"><a href="#cb499-1" aria-hidden="true" tabindex="-1"></a>pz</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>tensor([ 0.206057518720627,  0.155910953879356,  0.155910953879356,
         0.155910953879356,  0.412115037441254, -0.412115037441254])</code></pre>
</div>
</div>
<div id="92f1ea15-0ec1-4f15-b1d3-5fadc929a4bc" class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb501"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb501-1"><a href="#cb501-1" aria-hidden="true" tabindex="-1"></a>zm</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([643.794677734375000, 642.572204589843750, 643.049011230468750])</code></pre>
</div>
</div>
<div id="9be69d5d-f4c4-45cc-ad97-bc9e00bed4f8" class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb503"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb503-1"><a href="#cb503-1" aria-hidden="true" tabindex="-1"></a>zeta_candidates <span class="op">=</span> zlmax[zm <span class="op">==</span> torch.<span class="bu">max</span>(zm)]</span>
<span id="cb503-2"><a href="#cb503-2" aria-hidden="true" tabindex="-1"></a>zeta_candidates</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>tensor([1.])</code></pre>
</div>
</div>
<div id="225f2b93-45ab-4c06-9224-3f04339f236e" class="cell" data-execution_count="58">
<div class="sourceCode cell-code" id="cb505"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb505-1"><a href="#cb505-1" aria-hidden="true" tabindex="-1"></a>zeta <span class="op">=</span> torch.<span class="bu">min</span>(zeta_candidates)</span>
<span id="cb505-2"><a href="#cb505-2" aria-hidden="true" tabindex="-1"></a>zeta</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="58">
<pre><code>tensor(1.)</code></pre>
</div>
</div>
<div id="4b244ca9-359f-426e-bd48-f64214f459ce" class="cell" data-execution_count="59">
<div class="sourceCode cell-code" id="cb507"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb507-1"><a href="#cb507-1" aria-hidden="true" tabindex="-1"></a>w <span class="op">=</span> torch.clamp(torch.<span class="bu">min</span>(torch.tensor([<span class="fl">1.0</span>], dtype<span class="op">=</span>torch.<span class="bu">float</span>), torch.<span class="bu">max</span>(zeta <span class="op">*</span> cs, pilo)), <span class="bu">min</span><span class="op">=</span><span class="fl">0.0</span>, <span class="bu">max</span><span class="op">=</span><span class="fl">1.0</span>)</span>
<span id="cb507-2"><a href="#cb507-2" aria-hidden="true" tabindex="-1"></a>w</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="59">
<pre><code>tensor([1.000000000000000, 1.000000000000000, 1.000000000000000,
        1.000000000000000, 1.000000000000000, 0.412115037441254])</code></pre>
</div>
</div>
<p>R 코드</p>
<div class="sourceCode" id="cb509"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb509-1"><a href="#cb509-1" aria-hidden="true" tabindex="-1"></a>zetafromx <span class="ot">&lt;-</span> <span class="cf">function</span>(xd, cs, <span class="at">pilo =</span> <span class="cn">NA</span>, <span class="at">prior =</span> <span class="st">"laplace"</span>, <span class="at">a =</span> <span class="fl">0.5</span>) {</span>
<span id="cb509-2"><a href="#cb509-2" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-3"><a href="#cb509-3" aria-hidden="true" tabindex="-1"></a><span class="co">#  Given a sequence xd, a vector of scale factors cs and</span></span>
<span id="cb509-4"><a href="#cb509-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   a lower limit pilo, find the marginal maximum likelihood</span></span>
<span id="cb509-5"><a href="#cb509-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   estimate of the parameter zeta such that the prior prob</span></span>
<span id="cb509-6"><a href="#cb509-6" aria-hidden="true" tabindex="-1"></a><span class="co">#   is of the form median( pilo, zeta*cs, 1)</span></span>
<span id="cb509-7"><a href="#cb509-7" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-8"><a href="#cb509-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  If pilo=NA then it is calculated according to the sample size</span></span>
<span id="cb509-9"><a href="#cb509-9" aria-hidden="true" tabindex="-1"></a><span class="co">#   to corrrespond to the universal threshold</span></span>
<span id="cb509-10"><a href="#cb509-10" aria-hidden="true" tabindex="-1"></a><span class="co">#  </span></span>
<span id="cb509-11"><a href="#cb509-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find the beta values and the minimum weight if necessary</span></span>
<span id="cb509-12"><a href="#cb509-12" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-13"><a href="#cb509-13" aria-hidden="true" tabindex="-1"></a><span class="co">#  Current version allows for standard deviation of 1 only.</span></span>
<span id="cb509-14"><a href="#cb509-14" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-15"><a href="#cb509-15" aria-hidden="true" tabindex="-1"></a>    pr <span class="ot">&lt;-</span> <span class="fu">substring</span>(prior, <span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb509-16"><a href="#cb509-16" aria-hidden="true" tabindex="-1"></a>    nx <span class="ot">&lt;-</span> <span class="fu">length</span>(xd)</span>
<span id="cb509-17"><a href="#cb509-17" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> (<span class="fu">is.na</span>(pilo))</span>
<span id="cb509-18"><a href="#cb509-18" aria-hidden="true" tabindex="-1"></a>          pilo <span class="ot">&lt;-</span> <span class="fu">wfromt</span>(<span class="fu">sqrt</span>(<span class="dv">2</span> <span class="sc">*</span> <span class="fu">log</span>(<span class="fu">length</span>(xd))), <span class="at">prior=</span>prior, <span class="at">a=</span>a)</span>
<span id="cb509-19"><a href="#cb509-19" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"l"</span>)</span>
<span id="cb509-20"><a href="#cb509-20" aria-hidden="true" tabindex="-1"></a>      beta <span class="ot">&lt;-</span> <span class="fu">beta.laplace</span>(xd, <span class="at">a=</span>a)</span>
<span id="cb509-21"><a href="#cb509-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(pr <span class="sc">==</span> <span class="st">"c"</span>) beta <span class="ot">&lt;-</span> <span class="fu">beta.cauchy</span>(xd)</span>
<span id="cb509-22"><a href="#cb509-22" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-23"><a href="#cb509-23" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find jump points zj in derivative of log likelihood as function</span></span>
<span id="cb509-24"><a href="#cb509-24" aria-hidden="true" tabindex="-1"></a><span class="co">#    of z, and other preliminary calculations</span></span>
<span id="cb509-25"><a href="#cb509-25" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-26"><a href="#cb509-26" aria-hidden="true" tabindex="-1"></a>    zs1 <span class="ot">&lt;-</span> pilo<span class="sc">/</span>cs</span>
<span id="cb509-27"><a href="#cb509-27" aria-hidden="true" tabindex="-1"></a>    zs2 <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span>cs</span>
<span id="cb509-28"><a href="#cb509-28" aria-hidden="true" tabindex="-1"></a>    zj <span class="ot">&lt;-</span> <span class="fu">sort</span>(<span class="fu">unique</span>(<span class="fu">c</span>(zs1, zs2)))</span>
<span id="cb509-29"><a href="#cb509-29" aria-hidden="true" tabindex="-1"></a>    cb <span class="ot">&lt;-</span> cs <span class="sc">*</span> beta</span>
<span id="cb509-30"><a href="#cb509-30" aria-hidden="true" tabindex="-1"></a>    mz <span class="ot">&lt;-</span> <span class="fu">length</span>(zj)</span>
<span id="cb509-31"><a href="#cb509-31" aria-hidden="true" tabindex="-1"></a>    zlmax <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb509-32"><a href="#cb509-32" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb509-33"><a href="#cb509-33" aria-hidden="true" tabindex="-1"></a><span class="co">#  Find left and right derivatives at each zj and check which are</span></span>
<span id="cb509-34"><a href="#cb509-34" aria-hidden="true" tabindex="-1"></a><span class="co">#  local minima Check internal zj first</span></span>
<span id="cb509-35"><a href="#cb509-35" aria-hidden="true" tabindex="-1"></a>    lmin <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">FALSE</span>, mz)</span>
<span id="cb509-36"><a href="#cb509-36" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j <span class="cf">in</span> (<span class="dv">2</span><span class="sc">:</span>(mz <span class="sc">-</span> <span class="dv">1</span>))) {</span>
<span id="cb509-37"><a href="#cb509-37" aria-hidden="true" tabindex="-1"></a>        ze <span class="ot">&lt;-</span> zj[j]</span>
<span id="cb509-38"><a href="#cb509-38" aria-hidden="true" tabindex="-1"></a>        cbil <span class="ot">&lt;-</span> cb[(ze <span class="sc">&gt;</span> zs1) <span class="sc">&amp;</span> (ze <span class="sc">&lt;=</span> zs2)]</span>
<span id="cb509-39"><a href="#cb509-39" aria-hidden="true" tabindex="-1"></a>        ld <span class="ot">&lt;-</span> <span class="fu">sum</span>(cbil<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> ze <span class="sc">*</span> cbil))</span>
<span id="cb509-40"><a href="#cb509-40" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span>(ld <span class="sc">&lt;=</span> <span class="dv">0</span>) {</span>
<span id="cb509-41"><a href="#cb509-41" aria-hidden="true" tabindex="-1"></a>            cbir <span class="ot">&lt;-</span> cb[(ze <span class="sc">&gt;=</span> zs1) <span class="sc">&amp;</span> (ze <span class="sc">&lt;</span> zs2)]</span>
<span id="cb509-42"><a href="#cb509-42" aria-hidden="true" tabindex="-1"></a>            rd <span class="ot">&lt;-</span> <span class="fu">sum</span>(cbir<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> ze <span class="sc">*</span> cbir))</span>
<span id="cb509-43"><a href="#cb509-43" aria-hidden="true" tabindex="-1"></a>            lmin[j] <span class="ot">&lt;-</span> (rd <span class="sc">&gt;=</span> <span class="dv">0</span>)</span>
<span id="cb509-44"><a href="#cb509-44" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb509-45"><a href="#cb509-45" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb509-46"><a href="#cb509-46" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-47"><a href="#cb509-47" aria-hidden="true" tabindex="-1"></a><span class="co">#  Deal with the two end points in turn, finding right deriv</span></span>
<span id="cb509-48"><a href="#cb509-48" aria-hidden="true" tabindex="-1"></a><span class="co">#   at lower end and left deriv at upper</span></span>
<span id="cb509-49"><a href="#cb509-49" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-50"><a href="#cb509-50" aria-hidden="true" tabindex="-1"></a><span class="co">#  In each case the corresponding end point is either a local min</span></span>
<span id="cb509-51"><a href="#cb509-51" aria-hidden="true" tabindex="-1"></a><span class="co">#   or a local max depending on the sign of the relevant deriv</span></span>
<span id="cb509-52"><a href="#cb509-52" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-53"><a href="#cb509-53" aria-hidden="true" tabindex="-1"></a>    cbir <span class="ot">&lt;-</span> cb[zj[<span class="dv">1</span>] <span class="sc">==</span> zs1]</span>
<span id="cb509-54"><a href="#cb509-54" aria-hidden="true" tabindex="-1"></a>    rd <span class="ot">&lt;-</span> <span class="fu">sum</span>(cbir<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> zj[<span class="dv">1</span>] <span class="sc">*</span> cbir))</span>
<span id="cb509-55"><a href="#cb509-55" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(rd <span class="sc">&gt;</span> <span class="dv">0</span>) lmin[<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="cn">TRUE</span> <span class="cf">else</span> zlmax <span class="ot">&lt;-</span> zj[<span class="dv">1</span>]</span>
<span id="cb509-56"><a href="#cb509-56" aria-hidden="true" tabindex="-1"></a>    cbil <span class="ot">&lt;-</span> cb[zj[mz] <span class="sc">==</span> zs2]</span>
<span id="cb509-57"><a href="#cb509-57" aria-hidden="true" tabindex="-1"></a>    ld <span class="ot">&lt;-</span> <span class="fu">sum</span>(cbil<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> zj[mz] <span class="sc">*</span> cbil))</span>
<span id="cb509-58"><a href="#cb509-58" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(ld <span class="sc">&lt;</span> <span class="dv">0</span>) lmin[mz] <span class="ot">&lt;-</span> <span class="cn">TRUE</span> <span class="cf">else</span> zlmax <span class="ot">&lt;-</span> zj[mz]</span>
<span id="cb509-59"><a href="#cb509-59" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb509-60"><a href="#cb509-60" aria-hidden="true" tabindex="-1"></a><span class="co">#  Flag all local minima and do a binary search between them to find</span></span>
<span id="cb509-61"><a href="#cb509-61" aria-hidden="true" tabindex="-1"></a><span class="co">#  the local maxima</span></span>
<span id="cb509-62"><a href="#cb509-62" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-63"><a href="#cb509-63" aria-hidden="true" tabindex="-1"></a>    zlmin <span class="ot">&lt;-</span> zj[lmin]</span>
<span id="cb509-64"><a href="#cb509-64" aria-hidden="true" tabindex="-1"></a>    nlmin <span class="ot">&lt;-</span> <span class="fu">length</span>(zlmin)</span>
<span id="cb509-65"><a href="#cb509-65" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span>(nlmin <span class="sc">&gt;=</span> <span class="dv">2</span>) <span class="cf">for</span>(j <span class="cf">in</span> (<span class="dv">2</span><span class="sc">:</span>nlmin)) {</span>
<span id="cb509-66"><a href="#cb509-66" aria-hidden="true" tabindex="-1"></a>            zlo <span class="ot">&lt;-</span> zlmin[j <span class="sc">-</span> <span class="dv">1</span>]</span>
<span id="cb509-67"><a href="#cb509-67" aria-hidden="true" tabindex="-1"></a>            zhi <span class="ot">&lt;-</span> zlmin[j]</span>
<span id="cb509-68"><a href="#cb509-68" aria-hidden="true" tabindex="-1"></a>            ze <span class="ot">&lt;-</span> (zlo <span class="sc">+</span> zhi)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb509-69"><a href="#cb509-69" aria-hidden="true" tabindex="-1"></a>            zstep <span class="ot">&lt;-</span> (zhi <span class="sc">-</span> zlo)<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb509-70"><a href="#cb509-70" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span>(nit <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">10</span>)) {</span>
<span id="cb509-71"><a href="#cb509-71" aria-hidden="true" tabindex="-1"></a>                cbi <span class="ot">&lt;-</span> cb[(ze <span class="sc">&gt;=</span> zs1) <span class="sc">&amp;</span> (ze <span class="sc">&lt;=</span> zs2)]</span>
<span id="cb509-72"><a href="#cb509-72" aria-hidden="true" tabindex="-1"></a>                likd <span class="ot">&lt;-</span> <span class="fu">sum</span>(cbi<span class="sc">/</span>(<span class="dv">1</span> <span class="sc">+</span> ze <span class="sc">*</span> cbi))</span>
<span id="cb509-73"><a href="#cb509-73" aria-hidden="true" tabindex="-1"></a>                zstep <span class="ot">&lt;-</span> zstep<span class="sc">/</span><span class="dv">2</span></span>
<span id="cb509-74"><a href="#cb509-74" aria-hidden="true" tabindex="-1"></a>                ze <span class="ot">&lt;-</span> ze <span class="sc">+</span> zstep <span class="sc">*</span> <span class="fu">sign</span>(likd)</span>
<span id="cb509-75"><a href="#cb509-75" aria-hidden="true" tabindex="-1"></a>            }</span>
<span id="cb509-76"><a href="#cb509-76" aria-hidden="true" tabindex="-1"></a>            zlmax <span class="ot">&lt;-</span> <span class="fu">c</span>(zlmax, ze)</span>
<span id="cb509-77"><a href="#cb509-77" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb509-78"><a href="#cb509-78" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-79"><a href="#cb509-79" aria-hidden="true" tabindex="-1"></a><span class="co">#  Evaluate all local maxima and find global max; use smaller value</span></span>
<span id="cb509-80"><a href="#cb509-80" aria-hidden="true" tabindex="-1"></a><span class="co">#   if there is an exact tie for the global maximum.</span></span>
<span id="cb509-81"><a href="#cb509-81" aria-hidden="true" tabindex="-1"></a><span class="co">#</span></span>
<span id="cb509-82"><a href="#cb509-82" aria-hidden="true" tabindex="-1"></a>    nlmax <span class="ot">&lt;-</span> <span class="fu">length</span>(zlmax)</span>
<span id="cb509-83"><a href="#cb509-83" aria-hidden="true" tabindex="-1"></a>    zm <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, nlmax)</span>
<span id="cb509-84"><a href="#cb509-84" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span>(j <span class="cf">in</span> (<span class="dv">1</span><span class="sc">:</span>nlmax)) {</span>
<span id="cb509-85"><a href="#cb509-85" aria-hidden="true" tabindex="-1"></a>        pz <span class="ot">&lt;-</span> <span class="fu">pmax</span>(zs1, <span class="fu">pmin</span>(zlmax[j], zs2))</span>
<span id="cb509-86"><a href="#cb509-86" aria-hidden="true" tabindex="-1"></a>        zm[j] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="dv">1</span> <span class="sc">+</span> cb <span class="sc">*</span> pz))</span>
<span id="cb509-87"><a href="#cb509-87" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb509-88"><a href="#cb509-88" aria-hidden="true" tabindex="-1"></a>    zeta <span class="ot">&lt;-</span> zlmax[zm <span class="sc">==</span> <span class="fu">max</span>(zm)]</span>
<span id="cb509-89"><a href="#cb509-89" aria-hidden="true" tabindex="-1"></a>    zeta <span class="ot">&lt;-</span> <span class="fu">min</span>(zeta)</span>
<span id="cb509-90"><a href="#cb509-90" aria-hidden="true" tabindex="-1"></a>    w <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">1</span>, <span class="fu">pmax</span>(zeta<span class="sc">*</span>cs, pilo)) </span>
<span id="cb509-91"><a href="#cb509-91" aria-hidden="true" tabindex="-1"></a>    <span class="fu">return</span>(<span class="fu">list</span>(<span class="at">zeta=</span>zeta, <span class="at">w=</span>w, <span class="at">cs=</span>cs, <span class="at">pilo=</span>pilo))</span>
<span id="cb509-92"><a href="#cb509-92" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>결과</p>
<ul>
<li>Python</li>
</ul>
<div id="e056ec31-2f03-4ee7-8f6b-0b2262608d98" class="cell" data-execution_count="60">
<div class="sourceCode cell-code" id="cb510"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb510-1"><a href="#cb510-1" aria-hidden="true" tabindex="-1"></a>ebayesthresh_torch.zetafromx(torch.tensor([<span class="op">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="op">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>]),torch.tensor([<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">1</span>,<span class="op">-</span><span class="dv">1</span>]))</span></code></pre></div>
<div class="cell-output cell-output-display" data-execution_count="60">
<pre><code>{'zeta': 1.0,
 'w': tensor([1.000000000000000, 1.000000000000000, 1.000000000000000,
         1.000000000000000, 1.000000000000000, 0.412115037441254]),
 'cs': tensor([ 2,  3,  5,  6,  1, -1]),
 'pilo': tensor(0.412115022681705, dtype=torch.float64)}</code></pre>
</div>
</div>
<ul>
<li>R</li>
</ul>
<div class="sourceCode" id="cb512"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb512-1"><a href="#cb512-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">zetafromx</span>(<span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>,<span class="sc">-</span><span class="dv">4</span>,<span class="dv">8</span>,<span class="dv">50</span>),<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">1</span>,<span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb512-2"><a href="#cb512-2" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>zeta</span>
<span id="cb512-3"><a href="#cb512-3" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="dv">1</span></span>
<span id="cb512-4"><a href="#cb512-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb512-5"><a href="#cb512-5" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>w</span>
<span id="cb512-6"><a href="#cb512-6" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">1.000000</span> <span class="fl">1.000000</span> <span class="fl">1.000000</span> <span class="fl">1.000000</span> <span class="fl">1.000000</span> <span class="fl">0.412115</span></span>
<span id="cb512-7"><a href="#cb512-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb512-8"><a href="#cb512-8" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>cs</span>
<span id="cb512-9"><a href="#cb512-9" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>]  <span class="dv">2</span>  <span class="dv">3</span>  <span class="dv">5</span>  <span class="dv">6</span>  <span class="dv">1</span> <span class="sc">-</span><span class="dv">1</span></span>
<span id="cb512-10"><a href="#cb512-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb512-11"><a href="#cb512-11" aria-hidden="true" tabindex="-1"></a><span class="sc">$</span>pilo</span>
<span id="cb512-12"><a href="#cb512-12" aria-hidden="true" tabindex="-1"></a>[<span class="dv">1</span>] <span class="fl">0.412115</span></span></code></pre></div>
<hr>
</section>
<section id="layer" class="level1">
<h1>Layer</h1>
<div id="792b3741-240a-460f-9626-5d496d46839d" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb513"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb513-1"><a href="#cb513-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb513-2"><a href="#cb513-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb513-3"><a href="#cb513-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb513-4"><a href="#cb513-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span></code></pre></div>
</div>
<div id="a35b6538-891e-4dd1-b279-deae4cbd7710" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb514"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb514-1"><a href="#cb514-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> make_Psi(T):</span>
<span id="cb514-2"><a href="#cb514-2" aria-hidden="true" tabindex="-1"></a>    W <span class="op">=</span> torch.zeros((T,T))</span>
<span id="cb514-3"><a href="#cb514-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb514-4"><a href="#cb514-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> j <span class="kw">in</span> <span class="bu">range</span>(T):</span>
<span id="cb514-5"><a href="#cb514-5" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i<span class="op">==</span>j :</span>
<span id="cb514-6"><a href="#cb514-6" aria-hidden="true" tabindex="-1"></a>                W[i,j] <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb514-7"><a href="#cb514-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">elif</span> torch.<span class="bu">abs</span>(torch.tensor(i <span class="op">-</span> j)) <span class="op">&lt;=</span> <span class="dv">1</span> : </span>
<span id="cb514-8"><a href="#cb514-8" aria-hidden="true" tabindex="-1"></a>                W[i,j] <span class="op">=</span> <span class="dv">1</span></span>
<span id="cb514-9"><a href="#cb514-9" aria-hidden="true" tabindex="-1"></a>    d <span class="op">=</span> torch.tensor(W.<span class="bu">sum</span>(dim<span class="op">=</span><span class="dv">1</span>))</span>
<span id="cb514-10"><a href="#cb514-10" aria-hidden="true" tabindex="-1"></a>    D <span class="op">=</span> torch.diag(d)</span>
<span id="cb514-11"><a href="#cb514-11" aria-hidden="true" tabindex="-1"></a>    L <span class="op">=</span> torch.diag(<span class="dv">1</span><span class="op">/</span>torch.sqrt(d)) <span class="op">@</span> (D<span class="op">-</span>W) <span class="op">@</span> torch.diag(<span class="dv">1</span><span class="op">/</span>torch.sqrt(d))</span>
<span id="cb514-12"><a href="#cb514-12" aria-hidden="true" tabindex="-1"></a>    lamb, Psi <span class="op">=</span> torch.linalg.eigh(L)</span>
<span id="cb514-13"><a href="#cb514-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> Psi</span></code></pre></div>
</div>
<div id="68c6ae49-e2c8-4e9a-ae5e-bd7e9d0832bb" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb515"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb515-1"><a href="#cb515-1" aria-hidden="true" tabindex="-1"></a>T <span class="op">=</span> <span class="dv">100</span></span>
<span id="cb515-2"><a href="#cb515-2" aria-hidden="true" tabindex="-1"></a>t <span class="op">=</span> torch.arange(T)<span class="op">/</span>T <span class="op">*</span> <span class="dv">10</span></span>
<span id="cb515-3"><a href="#cb515-3" aria-hidden="true" tabindex="-1"></a>y_true <span class="op">=</span> <span class="dv">3</span><span class="op">*</span>torch.sin(<span class="fl">0.5</span><span class="op">*</span>t) <span class="op">+</span> <span class="fl">1.2</span><span class="op">*</span>torch.sin(<span class="fl">1.0</span><span class="op">*</span>t) <span class="op">+</span> <span class="fl">0.5</span><span class="op">*</span>torch.sin(<span class="fl">1.2</span><span class="op">*</span>t) </span>
<span id="cb515-4"><a href="#cb515-4" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> y_true <span class="op">+</span> torch.randn(T)</span>
<span id="cb515-5"><a href="#cb515-5" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb515-6"><a href="#cb515-6" aria-hidden="true" tabindex="-1"></a>plt.plot(t,y_true)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-267-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="76f4e9de-3bd3-48fa-8692-3e074788526b" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb516"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb516-1"><a href="#cb516-1" aria-hidden="true" tabindex="-1"></a>plt.plot(t,y,<span class="st">'o'</span>)</span>
<span id="cb516-2"><a href="#cb516-2" aria-hidden="true" tabindex="-1"></a>plt.plot(t,y_true,<span class="st">'--'</span>)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-268-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="4e61d9cf-4665-44e6-9abd-de41aada06cb" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb517"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb517-1"><a href="#cb517-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> torch.tensor(y)</span>
<span id="cb517-2"><a href="#cb517-2" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="bu">len</span>(f.shape)<span class="op">==</span><span class="dv">1</span>: f <span class="op">=</span> f.reshape(<span class="op">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb517-3"><a href="#cb517-3" aria-hidden="true" tabindex="-1"></a>T,N <span class="op">=</span> f.shape</span>
<span id="cb517-4"><a href="#cb517-4" aria-hidden="true" tabindex="-1"></a>Psi <span class="op">=</span> make_Psi(T)</span>
<span id="cb517-5"><a href="#cb517-5" aria-hidden="true" tabindex="-1"></a>fbar <span class="op">=</span> Psi.T <span class="op">@</span> f <span class="co"># apply dft </span></span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  f = torch.tensor(y)
&lt;ipython-input-19-cc3dd6c135ce&gt;:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  d = torch.tensor(W.sum(dim=1))</code></pre>
</div>
</div>
<div id="dbcab11e-3834-4388-9dbe-ebba699b5170" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb519"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb519-1"><a href="#cb519-1" aria-hidden="true" tabindex="-1"></a>plt.plot(t,fbar<span class="op">**</span><span class="dv">2</span>) <span class="co"># periodogram </span></span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-270-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="89fcd9dc-bfaa-4e54-bd14-5134fd2ef70f" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb520"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb520-1"><a href="#cb520-1" aria-hidden="true" tabindex="-1"></a>fbar_threshed <span class="op">=</span> ebayesthresh_torch.ebayesthresh(fbar[:,<span class="dv">0</span>])</span></code></pre></div>
</div>
<div id="d1b529f6-aac6-444f-8ad0-d912dee7779d" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb521"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb521-1"><a href="#cb521-1" aria-hidden="true" tabindex="-1"></a><span class="co"># fbar_threshed = np.stack([ebayesthresh(FloatVector(fbar[:,i])) for i in range(N)],axis=1)</span></span>
<span id="cb521-2"><a href="#cb521-2" aria-hidden="true" tabindex="-1"></a>plt.plot((fbar<span class="op">**</span><span class="dv">2</span>)) <span class="co"># periodogram </span></span>
<span id="cb521-3"><a href="#cb521-3" aria-hidden="true" tabindex="-1"></a>plt.plot((fbar_threshed<span class="op">**</span><span class="dv">2</span>)) </span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-272-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="b413e3e9-0976-497a-bb23-4e66b4fd06ff" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb522"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb522-1"><a href="#cb522-1" aria-hidden="true" tabindex="-1"></a>plt.plot((fbar<span class="op">**</span><span class="dv">2</span>)[<span class="dv">20</span>:<span class="dv">80</span>]) <span class="co"># periodogram </span></span>
<span id="cb522-2"><a href="#cb522-2" aria-hidden="true" tabindex="-1"></a>plt.plot((fbar_threshed<span class="op">**</span><span class="dv">2</span>)[<span class="dv">20</span>:<span class="dv">80</span>]) </span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-273-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="80db53fc-8399-49d7-bea0-675fd81e1b01" class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb523"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb523-1"><a href="#cb523-1" aria-hidden="true" tabindex="-1"></a>yhat <span class="op">=</span> Psi <span class="op">@</span> fbar_threshed.<span class="bu">float</span>() <span class="co"># inverse dft</span></span>
<span id="cb523-2"><a href="#cb523-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>,<span class="dv">6</span>))</span>
<span id="cb523-3"><a href="#cb523-3" aria-hidden="true" tabindex="-1"></a>plt.plot(t,y,<span class="st">'.'</span>)</span>
<span id="cb523-4"><a href="#cb523-4" aria-hidden="true" tabindex="-1"></a>plt.plot(t,y_true,<span class="st">'--'</span>)</span>
<span id="cb523-5"><a href="#cb523-5" aria-hidden="true" tabindex="-1"></a>plt.plot(t,yhat)</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-274-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="499d301e-35e6-4c6f-a75c-67440f1a76bc" class="cell" data-execution_count="38">
<div class="sourceCode cell-code" id="cb524"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb524-1"><a href="#cb524-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ebayesthresh_nn(torch.nn.Module):</span>
<span id="cb524-2"><a href="#cb524-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb524-3"><a href="#cb524-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb524-4"><a href="#cb524-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>,<span class="bu">input</span>):</span>
<span id="cb524-5"><a href="#cb524-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> ebayesthresh_torch.ebayesthresh(<span class="bu">input</span>)</span></code></pre></div>
</div>
<div id="0f247663-39e8-4a79-9d13-201e5d6f0bc1" class="cell" data-execution_count="39">
<div class="sourceCode cell-code" id="cb525"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb525-1"><a href="#cb525-1" aria-hidden="true" tabindex="-1"></a>thresh_layer <span class="op">=</span> ebayesthresh_nn()</span></code></pre></div>
</div>
<div id="10c15875-a5de-4349-8254-73e075490218" class="cell" data-execution_count="40">
<div class="sourceCode cell-code" id="cb526"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb526-1"><a href="#cb526-1" aria-hidden="true" tabindex="-1"></a>plt.plot(fbar[:,<span class="dv">0</span>])</span></code></pre></div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-277-output-1.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>
<div id="e4010662-d50d-48ba-a870-00cf52dafeb2" class="cell" data-execution_count="41">
<div class="sourceCode cell-code" id="cb527"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb527-1"><a href="#cb527-1" aria-hidden="true" tabindex="-1"></a>plt.plot(thresh_layer(fbar[:,<span class="dv">0</span>]))</span></code></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:70: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  if torch.isnan(torch.tensor(sdev)):
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:584: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  s = torch.tensor(s, dtype=torch.float)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:552: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tt = torch.tensor(tt, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:556: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tma = torch.tensor(tt / s - s * a)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:47: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat1 = torch.tensor(1 / xpa, dtype=torch.float64)
/home/csy/Dropbox/sy_hub/posts/1_Note/ebayesthresh_torch/utils.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  rat2 = torch.tensor(1 / torch.abs(xma), dtype=torch.float64)</code></pre>
</div>
<div class="cell-output cell-output-display">
<div>
<figure class="figure">
<p><img src="2024-07-31-EbayesThresh_Torch_files/figure-html/cell-278-output-2.png" class="img-fluid figure-img"></p>
</figure>
</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="seoyeonc/sy_hub" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->




</body></html>